"""
Browser Use Worker v0.13
====================================
åŸºäº browser-use 0.11.9 SDKï¼Œä½œä¸º Worker è´Ÿè´£å¤æ‚ã€å›°éš¾çš„æœç´¢ä¸ä¿¡æ¯æå–ä»»åŠ¡ã€‚

å®ç° BaseWorker æ¥å£ï¼Œsearch() è¿”å›ç»Ÿä¸€çš„ WorkerResultã€‚

å®šä½ï¼š
    - å¿«é€Ÿæœç´¢ â†’ ç”¨ WebSearchWorkerï¼ˆweb_search_worker.pyï¼‰
    - æ·±åº¦æœç´¢ â†’ ç”¨æœ¬ Workerï¼ˆbrowser_use_worker.pyï¼‰
      ä¾‹å¦‚ï¼šéœ€è¦å¤šæ­¥éª¤ç¿»é¡µã€åçˆ¬ç»•è¿‡ã€PDF æå–ã€æ”¿åºœç½‘ç«™æ·±åº¦é‡‡é›†ç­‰åœºæ™¯

ç”¨æ³•ï¼š
    # ä½œä¸º Worker ä½¿ç”¨ï¼ˆæ¨èï¼‰
    from browser_use_worker import BrowserUseWorker
    worker = BrowserUseWorker()
    result = worker.search("ä¸Šæµ·å…‰é€šä¿¡äº§ä¸šæ‰¶æŒæ”¿ç­–")  # â†’ WorkerResult

    # ç›´æ¥è°ƒç”¨ä½çº§ API
    from browser_use_worker import run_browser_task
    result = await run_browser_task("ä»»åŠ¡æè¿°")

ç¯å¢ƒå˜é‡ï¼ˆä» .env åŠ è½½ï¼‰ï¼š
    AZURE_OPENAI_ENDPOINT    â€” Azure OpenAI ç«¯ç‚¹
    AZURE_OPENAI_API_KEY     â€” Azure OpenAI API Key
"""

import asyncio
import json
import re
import sys
import os
from typing import Optional
from datetime import datetime

from dotenv import load_dotenv
from pydantic import BaseModel

load_dotenv()

from models import BaseWorker, WorkerResult, PolicyItem


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SearchResult(BaseModel):
    """æœç´¢ç»“æœ"""
    title: str
    url: str
    snippet: str = ""

class SearchResults(BaseModel):
    """å¤šæ¡æœç´¢ç»“æœ"""
    query: str
    results: list[SearchResult]

class PolicyInfo(BaseModel):
    """å•æ¡æ”¿ç­–ä¿¡æ¯"""
    policy_title: str
    source: str = ""
    url: str = ""
    pdf_url: str = ""
    summary: str = ""
    publish_date: str = ""
    applicable_industry: str = ""
    key_support: str = ""       # æ”¯æŒå†…å®¹æ‘˜è¦ï¼ˆèµ„é‡‘é¢åº¦ã€è¡¥è´´æ¯”ä¾‹ç­‰ï¼‰

class PolicySearchResult(BaseModel):
    """æ”¿ç­–æœç´¢ç»“æœ"""
    search_query: str = ""
    target_industry: str = ""
    target_region: str = ""
    policies: list[PolicyInfo] = []
    search_notes: str = ""

class PageContent(BaseModel):
    """é¡µé¢å†…å®¹æå–"""
    title: str = ""
    url: str = ""
    main_content: str = ""
    pdf_links: list[str] = []
    related_links: list[str] = []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¸‹è½½ç›®å½•
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DOWNLOAD_DIR = "/tmp/downloads"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ ¸å¿ƒï¼šåˆ›å»º LLM å’Œ Browser
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_azure_llm(model: str):
    """åˆ›å»º Azure OpenAI LLM å®ä¾‹ï¼ˆé€šç”¨å·¥å‚ï¼‰"""
    from browser_use import ChatAzureOpenAI
    return ChatAzureOpenAI(
        model=model,
        api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", ""),
        api_key=os.getenv("AZURE_OPENAI_API_KEY", ""),
    )


def create_llm():
    """ä¸»åŠ› LLMï¼šo3ï¼ˆå¼ºæ¨ç†ï¼Œè´µï¼‰"""
    return _create_azure_llm(os.getenv("AZURE_OPENAI_MODEL", "o3"))


def create_fallback_llm():
    """
    å¤‡ç”¨ LLMï¼šo4-miniï¼ˆä¾¿å®œã€å¿«ï¼Œæ¨ç†èƒ½åŠ›å¤Ÿç”¨ï¼‰
    
    è§¦å‘æ¡ä»¶ï¼šä¸»åŠ› o3 è€—å°½é‡è¯•åä»å¤±è´¥ï¼ˆ429/500/502/503/504ï¼‰
    ä¸€æ—¦åˆ‡æ¢ï¼Œå‰©ä½™æ­¥éª¤å…¨éƒ¨ä½¿ç”¨ fallbackã€‚
    """
    return _create_azure_llm(os.getenv("AZURE_OPENAI_FALLBACK_MODEL", "o4-mini"))


def create_extraction_llm():
    """
    é¡µé¢æå–ä¸“ç”¨ LLMï¼šgpt-4oï¼ˆä¾¿å®œã€å¿«ï¼Œåªéœ€æå–æ–‡æœ¬ï¼‰
    
    ç”¨äº extract action çš„å†…å®¹æå–ï¼Œä¸éœ€è¦æ¨ç†èƒ½åŠ›ï¼Œçœ token è´¹ç”¨ã€‚
    o3 æå–ä¸€æ¬¡é¡µé¢ ~5000 tokenï¼Œgpt-4o åªéœ€ ~500 tokenã€‚
    """
    return _create_azure_llm(os.getenv("AZURE_OPENAI_EXTRACT_MODEL", "gpt-4o"))


def create_browser_profile(headless: bool = True):
    """
    åˆ›å»ºæµè§ˆå™¨é…ç½®ï¼ˆBrowserProfileï¼‰ã€‚
    
    å…³é”®è®¾ç½®ï¼š
    - è§†è§‰å‹å¥½çš„çª—å£å°ºå¯¸ï¼ˆ1920x1080ï¼‰
    - PDF è‡ªåŠ¨ä¸‹è½½
    - ç¦ç”¨å®‰å…¨é™åˆ¶ä»¥è®¿é—®å„ç±»ç½‘ç«™
    - ä¸­æ–‡è¯­è¨€ç¯å¢ƒ
    """
    from browser_use.browser.profile import BrowserProfile

    os.makedirs(DOWNLOAD_DIR, exist_ok=True)

    profile = BrowserProfile(
        # æµè§ˆå™¨å¯æ‰§è¡Œæ–‡ä»¶ â€” ä½¿ç”¨ç³»ç»Ÿ Chrome
        executable_path="/usr/bin/google-chrome-stable",
        headless=headless,
        
        # å¯åŠ¨å‚æ•°
        args=[
            "--no-sandbox",
            "--disable-dev-shm-usage",
            "--lang=zh-CN",
            "--disable-gpu",
            "--disable-blink-features=AutomationControlled",  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            "--disable-features=IsolateOrigins,site-per-process",  # å…è®¸è·¨åŸŸiframe
            f"--window-size=1920,1080",
        ],
        chromium_sandbox=False,
        enable_default_extensions=False,
        
        # PDF â€” ä¸è¦è‡ªåŠ¨ä¸‹è½½ï¼ˆä¼šè§¦å‘ DownloadsWatchdog è¶…æ—¶ï¼‰
        # agent å¯ä»¥é€šè¿‡ navigate åˆ° PDF URL æ¥è¯»å–å†…å®¹
        auto_download_pdfs=False,
        downloads_path=DOWNLOAD_DIR,
        
        # å®‰å…¨ â€” æ”¾å®½é™åˆ¶ï¼Œèƒ½è®¿é—®æ›´å¤šç½‘ç«™
        disable_security=True,
        
        # é¡µé¢ç­‰å¾…
        minimum_wait_page_load_time=0.5,
        wait_for_network_idle_page_load_time=1.0,
        wait_between_actions=0.3,
        
        # DOM é«˜äº®ï¼ˆå¸®åŠ©è§†è§‰æ¨¡å¼ç†è§£äº¤äº’å…ƒç´ ï¼‰
        highlight_elements=True,
    )
    return profile


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç³»ç»Ÿæç¤ºæ¨¡æ¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT_CN = """ä½ åœ¨ä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒè¿è¡Œã€‚è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š

ã€æœç´¢å¼•æ“ã€‘
- ä½¿ç”¨ç™¾åº¦(baidu.com)æœç´¢ï¼Œä¸è¦ä½¿ç”¨ Google
- ç™¾åº¦å·²è‡ªåŠ¨æ‰“å¼€ï¼Œç›´æ¥åœ¨æœç´¢æ¡†ä¸­è¾“å…¥å…³é”®è¯å³å¯
- ä¸è¦ç›´æ¥åœ¨URLæ æ„é€ æœç´¢URL
- site:gov.cn æ˜¯ç™¾åº¦æœç´¢è¯­æ³•ï¼Œä¸æ˜¯ç½‘ç«™åœ°å€ï¼ä¸è¦å°è¯•ç›´æ¥è®¿é—® gov.cn

ã€åçˆ¬ç­–ç•¥ â€” æœ€é‡è¦ã€‘
- å¦‚æœé‡åˆ°éªŒè¯ç é¡µé¢ï¼ˆçœ‹åˆ°æ»‘å—ã€å›¾ç‰‡éªŒè¯ã€"è¯·éªŒè¯æ‚¨æ˜¯äººç±»"ç­‰ï¼‰ï¼Œç«‹å³æ‰§è¡Œ go_back è¿”å›ä¸Šä¸€é¡µï¼Œæ¢ä¸€ä¸ªé“¾æ¥æˆ–æ¢ä¸€ç§æœç´¢è¯
- ç»å¯¹ä¸è¦åœ¨éªŒè¯ç é¡µé¢ä¸Šåå¤å°è¯•ï¼Œæµªè´¹æ­¥æ•°ã€‚ä¸€æ—¦çœ‹åˆ°éªŒè¯ç ï¼Œé©¬ä¸Šç¦»å¼€
- ä»¥ä¸‹ç½‘ç«™ä¼šæ‹¦æˆªçˆ¬è™«ï¼Œç›´æ¥è·³è¿‡ä¸è¦å°è¯•è¿›å…¥ï¼š
  * ä¼æŸ¥æŸ¥ qichacha.com
  * å¤©çœ¼æŸ¥ tianyancha.com
  * æœç‹—å¾®ä¿¡ weixin.sogou.com
  * çˆ±ä¼æŸ¥ aiqicha.comï¼ˆç™¾åº¦éªŒè¯ç ä¿æŠ¤ï¼‰
- ä¼˜å…ˆè®¿é—®æ”¿åºœå®˜ç½‘(.gov.cn)ï¼Œè¿™äº›ç½‘ç«™é€šå¸¸ä¸ä¼šæ‹¦æˆª

ã€é«˜æ•ˆæµè§ˆã€‘
- æ¯æ¬¡åªæ“ä½œä¸€ä¸ªæ ‡ç­¾é¡µ
- å¦‚æœé¡µé¢3ç§’å†…æ— å“åº”ï¼Œæ‰§è¡Œ go_back æ¢ä¸‹ä¸€ä¸ª
- ä»æœç´¢ç»“æœæ‘˜è¦ä¸­å°±èƒ½æå–åˆ°çš„ä¿¡æ¯ï¼Œä¸éœ€è¦ç‚¹è¿›å»
- æ”¿åºœç½‘ç«™(.gov.cn)ä¼˜å…ˆçº§æœ€é«˜ï¼Œç›´æ¥è¿›å…¥æå–å…¨æ–‡
- æå–é¡µé¢å†…å®¹æ—¶ï¼Œä½¿ç”¨ extract è€Œä¸æ˜¯åå¤ find_elements
- ç™¾åº¦æœç´¢ç»“æœçš„é“¾æ¥æ˜¯è·³è½¬ URLï¼Œä¸æ˜¯ç›´æ¥çš„ .gov.cn é“¾æ¥ã€‚ç›´æ¥ç‚¹å‡»æ ‡é¢˜æ–‡æœ¬å³å¯ï¼Œä¸è¦ç”¨ find_elements æ‰¾ href åŒ¹é… .gov.cn

ã€è¾“å‡ºã€‘
- æ‰€æœ‰è¾“å‡ºä½¿ç”¨ä¸­æ–‡
- è¿”å›åˆæ³•çš„ JSON å­—ç¬¦ä¸²
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ ¸å¿ƒï¼šè¿è¡Œ browser-use ä»»åŠ¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def run_browser_task(
    task: str,
    output_model=None,
    max_steps: int = 20,
    use_vision: str = "auto",
    headless: bool = True,
    system_prompt: str = None,
) -> dict:
    """
    æ‰§è¡Œ browser-use ä»»åŠ¡ã€‚

    å‚æ•°ï¼š
        task:          ä»»åŠ¡æè¿°ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        output_model:  Pydantic æ¨¡å‹ç±»ï¼ˆå¯é€‰ï¼Œè¿”å›ç»“æ„åŒ– JSONï¼‰
        max_steps:     æœ€å¤§æ­¥æ•°
        use_vision:    è§†è§‰æ¨¡å¼ â€” "auto"ï¼ˆSDKè‡ªåŠ¨å†³å®šï¼‰| Trueï¼ˆæ¯æ­¥æˆªå›¾ï¼‰| Falseï¼ˆå…³é—­ï¼‰
        headless:      æ— å¤´æ¨¡å¼ï¼Œé»˜è®¤ True
        system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºï¼ˆé»˜è®¤ä½¿ç”¨ä¸­å›½ç½‘ç»œé€‚é…æç¤ºï¼‰

    è¿”å›ï¼š
        {
            "result": æœ€ç»ˆç»“æœï¼ˆæ–‡æœ¬æˆ–ç»“æ„åŒ–dictï¼‰,
            "urls": ["è®¿é—®è¿‡çš„URL"],
            "steps": æ­¥æ•°,
            "duration": è€—æ—¶ç§’æ•°,
            "extracted": ["æ¯æ­¥æå–çš„å†…å®¹"],
            "success": True/False,
            "downloads": ["ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„"],
        }
    """
    from browser_use import Agent
    from browser_use.browser.session import BrowserSession

    llm = create_llm()
    fallback = create_fallback_llm()
    extraction = create_extraction_llm()
    profile = create_browser_profile(headless=headless)
    browser_session = BrowserSession(browser_profile=profile)

    if system_prompt is None:
        system_prompt = SYSTEM_PROMPT_CN

    # æ„å»º Agent
    agent_kwargs = dict(
        task=task,
        llm=llm,
        browser_session=browser_session,
        max_failures=5,
        extend_system_message=system_prompt,
        use_vision=use_vision,
        
        # å¤‡ç”¨ LLM â€” o3 æŒ‚äº†è‡ªåŠ¨åˆ‡åˆ° o4-miniï¼ˆ429/500/502/503/504ï¼‰
        fallback_llm=fallback,
        
        # é¡µé¢æå–ä¸“ç”¨ LLM â€” gpt-4oï¼ˆä¾¿å®œã€å¿«ï¼Œåªåšæ–‡æœ¬æå–ï¼‰
        page_extraction_llm=extraction,
        
        # è§†è§‰ä¼˜åŒ– â€” auto æ¨¡å¼ä¸‹ SDK è‡ªè¡Œå†³å®šä½•æ—¶æˆªå›¾ï¼›æˆªå›¾æ—¶ä½¿ç”¨ä½åˆ†è¾¨ç‡çœ token
        vision_detail_level="low",
        
        # å…³é—­ judge â€” é¿å… judge verdict æ±¡æŸ“ final_result
        use_judge=False,
        
        # è§„åˆ’ â€” é‡åˆ°åœæ»æ—¶é‡æ–°è§„åˆ’
        enable_planning=True,
        planning_replan_on_stall=2,
        
        # å¾ªç¯æ£€æµ‹ â€” æ›´ç§¯æåœ°è·³å‡ºå¾ªç¯
        loop_detection_enabled=True,
        loop_detection_window=10,
        
        # æ­¥éª¤è¶…æ—¶
        step_timeout=120,
        
        # æ–‡ä»¶ç³»ç»Ÿè·¯å¾„ï¼ˆPDFä¸‹è½½ç›®å½•ï¼‰
        file_system_path=DOWNLOAD_DIR,
        
        # æ¯æ­¥æœ€å¤šæ‰§è¡Œçš„åŠ¨ä½œæ•°ï¼ˆå®˜æ–¹é»˜è®¤ 4ï¼Œå…è®¸ agent ä¸€æ­¥å®Œæˆå¤šä¸ªæ“ä½œï¼‰
        max_actions_per_step=4,
        
        # é¢„æ“ä½œ â€” ç›´æ¥æ‰“å¼€ç™¾åº¦ï¼Œçœå» LLM "æ‰“å¼€ç™¾åº¦" çš„æ­¥éª¤ï¼ˆèŠ‚çœ 1-2 æ­¥ + tokenï¼‰
        initial_actions=[
            {'navigate': {'url': 'https://www.baidu.com'}},
        ],
    )
    if output_model:
        agent_kwargs["output_model_schema"] = output_model

    agent = Agent(**agent_kwargs)

    # æ‰§è¡Œ
    start = datetime.now()
    try:
        history = await agent.run(max_steps=max_steps)
    except Exception as e:
        duration = (datetime.now() - start).total_seconds()
        return {
            "success": False,
            "result": None,
            "error": str(e),
            "urls": [],
            "steps": 0,
            "duration": round(duration, 1),
            "extracted": [],
            "downloads": [],
        }
    duration = (datetime.now() - start).total_seconds()

    # æå–ç»“æœ
    final_text = history.final_result()

    result = {
        "success": history.is_done() and final_text is not None and len(str(final_text).strip()) > 0,
        "result": final_text,
        "urls": history.urls(),
        "steps": history.number_of_steps(),
        "duration": round(duration, 1),
        "extracted": history.extracted_content(),
        "downloads": _list_downloads(),
    }

    # ç»“æ„åŒ–è§£æ â€” ä¼˜å…ˆä½¿ç”¨ SDK å†…ç½®çš„ history.structured_output
    if output_model:
        parsed = None

        # æ–¹å¼1: SDK å†…ç½® structured_outputï¼ˆè‡ªåŠ¨è§£æï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç† JSONï¼‰
        try:
            structured = history.structured_output
            if structured is not None:
                parsed = structured
        except Exception:
            pass

        # æ–¹å¼2: å›é€€åˆ°æ‰‹åŠ¨è§£æï¼ˆå…¼å®¹ structured_output å¤±è´¥çš„æƒ…å†µï¼‰
        if parsed is None and final_text:
            cleaned = _clean_final_result(str(final_text))
            try:
                parsed = output_model.model_validate_json(cleaned)
            except Exception:
                json_text = _extract_json(str(final_text))
                if json_text:
                    try:
                        parsed = output_model.model_validate_json(json_text)
                    except Exception as e:
                        result["parse_error"] = str(e)

        if parsed is not None:
            dumped = parsed.model_dump() if hasattr(parsed, 'model_dump') else parsed
            result["structured"] = dumped
            result["result"] = dumped

    # å…³é—­æµè§ˆå™¨
    try:
        await browser_session.close()
    except:
        pass

    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# BrowserUseWorker â€” å®ç° BaseWorker æ¥å£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class BrowserUseWorker(BaseWorker):
    """
    åŸºäº browser-use æ— å¤´æµè§ˆå™¨çš„æ·±åº¦æœç´¢ Workerã€‚

    å®ç° BaseWorker æ¥å£:
        worker = BrowserUseWorker()
        result = worker.search("æµ¦ä¸œæ–°åŒºå…‰é€šä¿¡äº§ä¸šæ‰¶æŒæ”¿ç­–")  # â†’ WorkerResult
    """

    name = "browser_use"

    def __init__(
        self,
        max_steps: int = 25,
        use_vision: str = "auto",
        headless: bool = True,
    ):
        self.max_steps = max_steps
        self.use_vision = use_vision
        self.headless = headless

    def _build_task(self, query: str) -> str:
        """æ ¹æ®æŸ¥è¯¢æ„å»º browser-use ä»»åŠ¡æŒ‡ä»¤"""
        return (
            f"ä½ çš„ä»»åŠ¡ï¼šæœç´¢å¹¶æå–ä»¥ä¸‹æŸ¥è¯¢ç›¸å…³çš„æ”¿ç­–ä¿¡æ¯ï¼š{query}\n\n"
            "ã€ç­–ç•¥ã€‘ï¼ˆç™¾åº¦å·²è‡ªåŠ¨æ‰“å¼€ï¼Œç›´æ¥ä»æœç´¢å¼€å§‹ï¼‰\n"
            f"1. åœ¨æœç´¢æ¡†ä¸­è¾“å…¥: {query} site:gov.cn\n"
            "2. ä»æœç´¢ç»“æœé¡µç›´æ¥ç‚¹å‡»ç»“æœæ ‡é¢˜é“¾æ¥ï¼ˆä¸è¦ç”¨ find_elements æ‰¾ hrefï¼Œç™¾åº¦ä¼šéšè—çœŸå® URLï¼‰\n"
            "3. è¿›å…¥æ”¿ç­–é¡µåç”¨ extract æå–è¯¦æƒ…ï¼Œæ‰¾ PDF é“¾æ¥\n"
            "4. å°½å¯èƒ½æ”¶é›†å¤šæ¡æ”¿ç­–ï¼Œä½†è‡³å°‘1æ¡å³å¯ç»“æŸ\n\n"
            "ã€è§„åˆ™ã€‘\n"
            "- é‡åˆ°éªŒè¯ç /æ‹¦æˆª â†’ ç«‹å³ go_back\n"
            "- ä¸è®¿é—® qichacha/tianyancha/aiqicha ç­‰\n"
            "- æ¯æ¡æ”¿ç­–æå–: æ ‡é¢˜ã€æ¥æºã€URLã€PDFé“¾æ¥ã€æ‘˜è¦ã€æ—¥æœŸ\n\n"
            "è¿”å› JSONï¼š\n"
            '{"policies": [{"policy_title": "æ ‡é¢˜", "source": "æœºæ„", '
            '"url": "é“¾æ¥", "pdf_url": "PDFé“¾æ¥", "summary": "æ‘˜è¦", '
            '"publish_date": "æ—¥æœŸ", "applicable_industry": "è¡Œä¸š", '
            '"key_support": "æ‰¶æŒå†…å®¹"}]}'
        )

    def search(self, query: str, **kwargs) -> WorkerResult:
        """
        æ‰§è¡Œæ·±åº¦æœç´¢ï¼Œè¿”å›ç»Ÿä¸€çš„ WorkerResultï¼ˆå®ç° BaseWorker æ¥å£ï¼‰

        å†…éƒ¨é€šè¿‡ asyncio è°ƒç”¨ run_browser_task()ã€‚
        """
        import time as _time
        start = _time.time()

        task = kwargs.get("task") or self._build_task(query)
        max_steps = kwargs.get("max_steps", self.max_steps)

        try:
            # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å·²åœ¨äº‹ä»¶å¾ªç¯ä¸­ â€” éœ€è¦åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as pool:
                    raw = pool.submit(
                        asyncio.run,
                        run_browser_task(
                            task,
                            output_model=PolicySearchResult,
                            max_steps=max_steps,
                            use_vision=self.use_vision,
                            headless=self.headless,
                        )
                    ).result()
            else:
                raw = asyncio.run(
                    run_browser_task(
                        task,
                        output_model=PolicySearchResult,
                        max_steps=max_steps,
                        use_vision=self.use_vision,
                        headless=self.headless,
                    )
                )

            elapsed = round(_time.time() - start, 1)
            return self._raw_to_worker_result(query, raw, elapsed)

        except Exception as e:
            elapsed = round(_time.time() - start, 1)
            return WorkerResult(
                query=query,
                worker=self.name,
                duration=elapsed,
                error=str(e),
            )

    async def search_async(self, query: str, **kwargs) -> WorkerResult:
        """å¼‚æ­¥ç‰ˆæœ¬çš„ searchï¼ˆserver.py ä¸­ä½¿ç”¨ï¼‰"""
        import time as _time
        start = _time.time()

        task = kwargs.get("task") or self._build_task(query)
        max_steps = kwargs.get("max_steps", self.max_steps)

        try:
            raw = await run_browser_task(
                task,
                output_model=PolicySearchResult,
                max_steps=max_steps,
                use_vision=self.use_vision,
                headless=self.headless,
            )
            elapsed = round(_time.time() - start, 1)
            return self._raw_to_worker_result(query, raw, elapsed)
        except Exception as e:
            elapsed = round(_time.time() - start, 1)
            return WorkerResult(
                query=query,
                worker=self.name,
                duration=elapsed,
                error=str(e),
            )

    def _raw_to_worker_result(self, query: str, raw: dict, elapsed: float) -> WorkerResult:
        """æŠŠ run_browser_task çš„åŸå§‹ dict è½¬ä¸º WorkerResult"""
        policies = []

        # ä» structured æå–
        structured = raw.get("structured") or raw.get("result")
        if isinstance(structured, dict):
            for p in structured.get("policies", []):
                policies.append(PolicyItem(
                    title=p.get("policy_title", ""),
                    url=p.get("url", ""),
                    source=p.get("source", ""),
                    date=p.get("publish_date", ""),
                    summary=p.get("summary", ""),
                    support=p.get("key_support", ""),
                    pdf_url=p.get("pdf_url", ""),
                    industry=p.get("applicable_industry", ""),
                ))

        return WorkerResult(
            query=query,
            policies=policies,
            sources=raw.get("urls", []),
            worker=self.name,
            duration=elapsed,
            error=None if raw.get("success") else raw.get("error"),
            raw_answer=json.dumps(structured, ensure_ascii=False) if isinstance(structured, dict) else str(raw.get("result", "")),
        )


def _clean_final_result(text: str) -> str:
    """æ¸…ç† final_result ä¸­å¯èƒ½è¢«é™„åŠ çš„ judge verdict ç­‰é JSON å†…å®¹"""
    if not text:
        return text
    
    # å¦‚æœæ–‡æœ¬ä»¥ { å¼€å¤´ï¼Œå°è¯•æ‰¾åˆ°åŒ¹é…çš„ }
    text = text.strip()
    if text.startswith("{"):
        depth = 0
        for i, ch in enumerate(text):
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    return text[:i+1]
    
    # å¦‚æœæ–‡æœ¬ä»¥ [ å¼€å¤´ï¼Œæ‰¾åŒ¹é…çš„ ]
    if text.startswith("["):
        depth = 0
        for i, ch in enumerate(text):
            if ch == "[":
                depth += 1
            elif ch == "]":
                depth -= 1
                if depth == 0:
                    return text[:i+1]
    
    return text


def _extract_json(text: str) -> Optional[str]:
    """ä»æ··åˆæ–‡æœ¬ä¸­æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡"""
    # æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
    start = text.find("{")
    if start == -1:
        return None
    
    depth = 0
    for i in range(start, len(text)):
        if text[i] == "{":
            depth += 1
        elif text[i] == "}":
            depth -= 1
            if depth == 0:
                candidate = text[start:i+1]
                try:
                    json.loads(candidate)
                    return candidate
                except:
                    continue
    return None


def _list_downloads() -> list[str]:
    """åˆ—å‡ºä¸‹è½½ç›®å½•ä¸­çš„æ–‡ä»¶"""
    if not os.path.exists(DOWNLOAD_DIR):
        return []
    files = []
    for f in os.listdir(DOWNLOAD_DIR):
        fpath = os.path.join(DOWNLOAD_DIR, f)
        if os.path.isfile(fpath):
            size = os.path.getsize(fpath)
            files.append(f"{f} ({size} bytes)")
    return files


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é¢„è®¾ç¤ºä¾‹ä»»åŠ¡ï¼ˆfocused, single-objectiveï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

EXAMPLES = {
    "weather": {
        "task": 'ç™¾åº¦å·²æ‰“å¼€ï¼Œç›´æ¥åœ¨æœç´¢æ¡†è¾“å…¥â€œåŒ—äº¬ä»Šå¤©å¤©æ°”â€ï¼Œæå–å½“å‰æ¸©åº¦ã€å¤©æ°”çŠ¶å†µã€é£åŠ›ä¿¡æ¯ã€‚',
        "model": None,
        "max_steps": 10,
    },

    "policy_search": {
        "task": (
            "ä½ çš„ä»»åŠ¡ï¼šæ‰¾åˆ°2025-2026å¹´ä¸Šæµ·å¸‚é€‚åˆã€Œå…‰é€šä¿¡ã€è¡Œä¸šçš„æ”¿åºœäº§ä¸šæ‰¶æŒæ”¿ç­–ã€‚\n\n"
            "ã€ç­–ç•¥ â€” ç™¾åº¦å·²è‡ªåŠ¨æ‰“å¼€ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œã€‘\n\n"
            "ç¬¬ä¸€è½®æœç´¢ï¼ˆæ­¥éª¤1-5ï¼‰ï¼šç™¾åº¦æœç´¢æ”¿åºœæ”¿ç­–\n"
            "1. åœ¨æœç´¢æ¡†ä¸­è¾“å…¥: ä¸Šæµ· å…‰é€šä¿¡ äº§ä¸šæ‰¶æŒæ”¿ç­– 2025 site:gov.cn\n"
            "2. æŸ¥çœ‹æœç´¢ç»“æœï¼Œä»æ‘˜è¦ä¸­æå–ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æ—¥æœŸã€æ¥æºï¼‰\n"
            "3. ç‚¹å‡»ç¬¬1ä¸ª .gov.cn é“¾æ¥ï¼Œè¿›å…¥åæå–æ”¿ç­–è¯¦æƒ…å’ŒPDFé“¾æ¥\n"
            "4. è¿”å›æœç´¢ç»“æœé¡µï¼ˆgo_backï¼‰ï¼Œç‚¹å‡»ç¬¬2ä¸ª .gov.cn é“¾æ¥è·å–ç¬¬2æ¡æ”¿ç­–\n\n"
            "ç¬¬äºŒè½®æœç´¢ï¼ˆæ­¥éª¤5-8ï¼‰ï¼šæ¢æœç´¢è¯æ‰©å¤§èŒƒå›´\n"
            "5. æ–°æœç´¢: ä¸Šæµ· é€šä¿¡äº§ä¸š è¡¥è´´ å¥–åŠ±æ”¿ç­– site:gov.cn\n"
            "6. ä»ç»“æœä¸­å†è·å–1-2æ¡ä¸åŒçš„æ”¿ç­–\n\n"
            "ç¬¬ä¸‰è½®ï¼ˆæ­¥éª¤7-10ï¼‰ï¼šç›´æ¥è®¿é—®æ”¿åºœç½‘ç«™\n"
            "7. æ‰“å¼€ https://sheitc.sh.gov.cn ï¼ˆä¸Šæµ·å¸‚ç»ä¿¡å§”ï¼‰\n"
            "8. åœ¨ç½‘ç«™ä¸Šæœç´¢ã€Œå…‰é€šä¿¡ã€æˆ–ã€Œé€šä¿¡äº§ä¸šã€\n"
            "9. æå–ç›¸å…³æ”¿ç­–ä¿¡æ¯\n\n"
            "ã€é‡è¦è§„åˆ™ã€‘\n"
            "- é‡åˆ°éªŒè¯ç /æ‹¦æˆª â†’ ç«‹å³ go_backï¼Œæ¢ä¸‹ä¸€ä¸ªé“¾æ¥\n"
            "- ä¸è¦è®¿é—® qichacha/tianyancha/aiqicha/weixin.sogou ç­‰ä¼šæ‹¦æˆªçš„ç½‘ç«™\n"
            "- æ¯ä¸ªæ”¿ç­–éƒ½è¦æå–: æ ‡é¢˜ã€æ¥æºã€URLã€PDFé“¾æ¥ã€æ‘˜è¦ã€å‘å¸ƒæ—¥æœŸ\n"
            "- è‡³å°‘æ”¶é›†2æ¡æ”¿ç­–ä¿¡æ¯åæ‰èƒ½ç»“æŸ\n\n"
            "è¿”å› JSON æ ¼å¼ï¼ˆå¿…é¡»æ˜¯åˆæ³• JSONï¼‰ï¼š\n"
            '{"search_query": "å®é™…æœç´¢è¯", "target_industry": "å…‰é€šä¿¡", '
            '"target_region": "ä¸Šæµ·", '
            '"policies": [{"policy_title": "æ ‡é¢˜", "source": "å‘å¸ƒæœºæ„", '
            '"url": "åŸæ–‡é“¾æ¥", "pdf_url": "PDFé“¾æ¥", "summary": "æ‘˜è¦", '
            '"publish_date": "æ—¥æœŸ", "applicable_industry": "é€‚ç”¨è¡Œä¸š", '
            '"key_support": "æ”¯æŒå†…å®¹"}], '
            '"search_notes": "æœç´¢è¿‡ç¨‹å¤‡æ³¨"}'
        ),
        "model": PolicySearchResult,
        "max_steps": 25,
    },

    "gov_direct": {
        "task": (
            "ä½ çš„ä»»åŠ¡ï¼šç›´æ¥è®¿é—®ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒºæ”¿åºœç½‘ç«™ï¼ŒæŸ¥æ‰¾é€šä¿¡äº§ä¸šç›¸å…³çš„æ‰¶æŒæ”¿ç­–ã€‚\n\n"
            "æ­¥éª¤ï¼š\n"
            "1. ç›´æ¥æ‰“å¼€ https://www.pudong.gov.cn/\n"
            "2. åœ¨ç½‘ç«™çš„æœç´¢åŠŸèƒ½ä¸­æœç´¢ã€Œé€šä¿¡ äº§ä¸š æ‰¶æŒã€æˆ–ã€Œå…‰é€šä¿¡ã€\n"
            "3. å¦‚æœæ²¡æœ‰æœç´¢æ¡†ï¼Œå°è¯•è®¿é—®æ”¿ç­–å…¬å¼€æ ç›®\n"
            "4. æ‰¾åˆ°ä¸é€šä¿¡äº§ä¸šç›¸å…³çš„æ”¿ç­–æ–‡ä»¶ï¼Œæå–æ ‡é¢˜ã€æ—¥æœŸã€URLã€PDFé“¾æ¥\n"
            "5. å¦‚æœæ‰¾åˆ° PDF ä¸‹è½½æŒ‰é’®ï¼Œç‚¹å‡»ä¸‹è½½\n\n"
            "è¿”å› JSON æ ¼å¼ï¼š\n"
            '{"search_query": "é€šä¿¡ äº§ä¸š æ‰¶æŒ", "target_industry": "å…‰é€šä¿¡", '
            '"target_region": "ä¸Šæµ·æµ¦ä¸œæ–°åŒº", '
            '"policies": [{"policy_title": "æ ‡é¢˜", "source": "æ¥æº", '
            '"url": "é“¾æ¥", "pdf_url": "PDFé“¾æ¥", "summary": "æ‘˜è¦", '
            '"publish_date": "æ—¥æœŸ", "applicable_industry": "é€‚ç”¨è¡Œä¸š", '
            '"key_support": "æ”¯æŒå†…å®¹"}], '
            '"search_notes": "å¤‡æ³¨"}'
        ),
        "model": PolicySearchResult,
        "max_steps": 15,
    },

    "pdf_download": {
        "task": (
            "ä½ çš„ä»»åŠ¡ï¼šä¸‹è½½ä¸€ä¸ªæ”¿ç­–PDFæ–‡ä»¶ã€‚\n\n"
            "æ­¥éª¤ï¼š\n"
            "1. ç›´æ¥æ‰“å¼€è¿™ä¸ªURL: https://www.pudong.gov.cn/zwgk/gfxwj-kjwzcwj/2024/299/333469.html\n"
            "2. åœ¨é¡µé¢ä¸­å¯»æ‰¾ PDF ä¸‹è½½é“¾æ¥æˆ–æŒ‰é’®\n"
            "3. ç‚¹å‡»ä¸‹è½½ PDF æ–‡ä»¶\n"
            "4. æå–é¡µé¢ä¸­çš„æ”¿ç­–æ ‡é¢˜å’Œä¸»è¦å†…å®¹æ‘˜è¦\n\n"
            "è¿”å›é¡µé¢æ ‡é¢˜ã€PDFé“¾æ¥åœ°å€ã€ä»¥åŠæ”¿ç­–ä¸»è¦å†…å®¹æ¦‚è¦ã€‚"
        ),
        "model": None,
        "max_steps": 10,
    },

    "captcha_test": {
        "task": (
            "ä½ çš„ä»»åŠ¡ï¼šæµ‹è¯•åéªŒè¯ç ç­–ç•¥ã€‚ï¼ˆç™¾åº¦å·²è‡ªåŠ¨æ‰“å¼€ï¼‰\n\n"
            "æ­¥éª¤ï¼š\n"
            "1. åœ¨æœç´¢æ¡†è¾“å…¥ã€Œä¸Šæµ·è¿å‡¡é¢†å…‰é€šä¿¡æœ‰é™å…¬å¸ã€\n"
            "2. ä»æœç´¢ç»“æœæ‘˜è¦ä¸­æå–å…¬å¸åŸºæœ¬ä¿¡æ¯ï¼ˆåœ°å€ã€è¡Œä¸šã€æˆç«‹æ—¥æœŸç­‰ï¼‰\n"
            "   - ä¸è¦ç‚¹å‡»çˆ±ä¼æŸ¥ã€ä¼æŸ¥æŸ¥ã€å¤©çœ¼æŸ¥çš„é“¾æ¥\n"
            "3. å¦‚æœæœç´¢ç»“æœæ‘˜è¦ä¸­æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œç›´æ¥è¿”å›\n"
            "4. å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå°è¯•ç‚¹å‡»å…¶ä»–é“¾æ¥ï¼ˆå¦‚ç™¾åº¦ç™¾ç§‘ï¼‰\n"
            "5. é‡åˆ°ä»»ä½•éªŒè¯ç /æ‹¦æˆªé¡µé¢ï¼Œç«‹å³ go_back è¿”å›\n\n"
            "è¿”å›å…¬å¸çš„ï¼šåç§°ã€æ³¨å†Œåœ°å€ã€è¡Œä¸šã€ä¼ä¸šç±»å‹ã€æˆç«‹æ—¥æœŸã€‚"
        ),
        "model": None,
        "max_steps": 10,
    },

    "extract_page": {
        "task": (
            "ä½ çš„ä»»åŠ¡ï¼šæå–æŒ‡å®šç½‘é¡µçš„å®Œæ•´å†…å®¹ã€‚\n\n"
            "æ­¥éª¤ï¼š\n"
            "1. æ‰“å¼€ https://www.pudong.gov.cn/zwgk/gfxwj-kjwzcwj/2024/299/333469.html\n"
            "2. ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ\n"
            "3. æå–é¡µé¢æ ‡é¢˜\n"
            "4. æå–æ­£æ–‡å…¨éƒ¨å†…å®¹\n"
            "5. æ‰¾åˆ°é¡µé¢ä¸­æ‰€æœ‰çš„ PDF ä¸‹è½½é“¾æ¥\n"
            "6. æ‰¾åˆ°é¡µé¢åº•éƒ¨çš„ç›¸å…³é“¾æ¥\n\n"
            "è¿”å› JSON æ ¼å¼ï¼š\n"
            '{"title": "æ ‡é¢˜", "url": "URL", "main_content": "æ­£æ–‡å†…å®¹", '
            '"pdf_links": ["PDFé“¾æ¥1"], "related_links": ["ç›¸å…³é“¾æ¥1"]}'
        ),
        "model": PageContent,
        "max_steps": 8,
    },
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¾“å‡ºæ ¼å¼åŒ–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_result(result: dict):
    """ç¾åŒ–è¾“å‡ºç»“æœ"""
    print("\n" + "=" * 60)
    print(f"{'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±è´¥'}")
    print(f"â±  è€—æ—¶: {result['duration']}s | æ­¥æ•°: {result['steps']}")

    if result.get("error"):
        print(f"\nâŒ é”™è¯¯: {result['error']}")

    if result.get("downloads"):
        print(f"\nğŸ“¥ ä¸‹è½½çš„æ–‡ä»¶:")
        for f in result["downloads"]:
            print(f"   {f}")

    if result.get("urls"):
        unique_urls = list(dict.fromkeys(u for u in result["urls"] if u))
        print(f"\nğŸ“ è®¿é—®è¿‡çš„ URL ({len(unique_urls)} ä¸ª):")
        for url in unique_urls[:10]:
            print(f"   {url}")
        if len(unique_urls) > 10:
            print(f"   ... è¿˜æœ‰ {len(unique_urls)-10} ä¸ª")

    print(f"\nğŸ“„ æœ€ç»ˆç»“æœ:")
    print("-" * 60)

    r = result["result"]
    if isinstance(r, dict):
        print(json.dumps(r, ensure_ascii=False, indent=2))
    elif r:
        if len(r) > 3000:
            print(r[:3000])
            print(f"\n... (æˆªæ–­ï¼Œå…± {len(r)} å­—ç¬¦)")
        else:
            print(r)
    else:
        print("(æ— ç»“æœ)")

    if result.get("parse_error"):
        print(f"\nâš ï¸  ç»“æ„åŒ–è§£æå¤±è´¥: {result['parse_error']}")

    print("=" * 60)


def save_result(result: dict, filename: str = None):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    if not filename:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"result_{ts}.json"

    with open(filename, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¸»å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def main():
    if len(sys.argv) > 1:
        arg = sys.argv[1]

        # é¢„è®¾ç¤ºä¾‹
        if arg == "--example" and len(sys.argv) > 2:
            example_name = sys.argv[2]
            if example_name not in EXAMPLES:
                print(f"å¯ç”¨ç¤ºä¾‹: {', '.join(EXAMPLES.keys())}")
                return
            ex = EXAMPLES[example_name]
            steps = ex.get("max_steps", 20)
            vision = ex.get("use_vision", True)
            print(f"ğŸš€ è¿è¡Œç¤ºä¾‹: {example_name}")
            print(f"ğŸ“ ä»»åŠ¡: {ex['task'][:100]}...")
            print(f"ğŸ“Š æœ€å¤§æ­¥æ•°: {steps} | è§†è§‰: {'å¼€' if vision else 'å…³'}")
            result = await run_browser_task(
                ex["task"],
                output_model=ex.get("model"),
                max_steps=steps,
                use_vision=vision,
            )
            print_result(result)
            save_result(result)
            return

        if arg == "--help":
            print(__doc__)
            print(f"\né¢„è®¾ç¤ºä¾‹: {', '.join(EXAMPLES.keys())}")
            print("  python browser_use_worker.py --example policy_search")
            return

        # ç›´æ¥ä¼ å…¥ä»»åŠ¡
        task = " ".join(sys.argv[1:])
        print(f"ğŸš€ æ‰§è¡Œä»»åŠ¡: {task}")
        result = await run_browser_task(task)
        print_result(result)
        save_result(result)
        return

    # äº¤äº’æ¨¡å¼
    print("=" * 60)
    print("ğŸŒ Browser Use æ·±åº¦æŒ–æ˜å·¥å…· v0.12")
    print("=" * 60)
    print()
    print("ğŸ’¡ æ€ä¹ˆå†™ä»»åŠ¡ï¼ˆåƒå†™ promptï¼‰ï¼š")
    print("   1. å…·ä½“æ˜ç¡® â€” è¯´æ¸…æ¥šå»å“ªä¸ªç½‘ç«™ã€åšä»€ä¹ˆã€è¿”å›ä»€ä¹ˆ")
    print("   2. åˆ†æ­¥éª¤å†™ â€” ç”¨ 1. 2. 3. ç¼–å·æ›´å¯é ")
    print("   3. æŒ‡å®šæ ¼å¼ â€” è¦ JSON/é“¾æ¥åˆ—è¡¨ï¼Œç›´æ¥åœ¨ä»»åŠ¡é‡Œè¯´")
    print()
    print("ğŸ“Œ é¢„è®¾ç¤ºä¾‹ï¼š")
    for name, ex in EXAMPLES.items():
        print(f"   {name:15s} â€” {ex['task'][:50]}...")
    print()
    print("âŒ¨ï¸  'q' é€€å‡º | 'run <ç¤ºä¾‹å>' è¿è¡Œç¤ºä¾‹")
    print()

    while True:
        task = input("ğŸ“ è¾“å…¥ä»»åŠ¡> ").strip()

        if not task:
            continue
        if task.lower() == "q":
            break
        if task.lower().startswith("run "):
            name = task[4:].strip()
            if name in EXAMPLES:
                ex = EXAMPLES[name]
                steps = ex.get("max_steps", 20)
                print(f"ğŸš€ è¿è¡Œç¤ºä¾‹: {name}")
                result = await run_browser_task(
                    ex["task"], output_model=ex.get("model"), max_steps=steps
                )
                print_result(result)
                save_result(result)
            else:
                print(f"æœªçŸ¥ç¤ºä¾‹: {name}ï¼Œå¯ç”¨: {', '.join(EXAMPLES.keys())}")
            continue

        print(f"ğŸš€ æ‰§è¡Œä¸­...")
        result = await run_browser_task(task)
        print_result(result)

        save = input("ğŸ’¾ ä¿å­˜ç»“æœ? (y/N) ").strip().lower()
        if save == "y":
            save_result(result)


if __name__ == "__main__":
    asyncio.run(main())
