"""
Web Search Worker
=================
ä½¿ç”¨ Azure OpenAI Responses API + web_search_preview å·¥å…·çš„æœç´¢ Workerã€‚
ä¸éœ€è¦åˆ›å»ºé¢å¤–çš„ Bing èµ„æºï¼Œç›´æ¥è°ƒç”¨ Responses APIã€‚

å®ç° BaseWorker æ¥å£ï¼Œsearch() è¿”å›ç»Ÿä¸€çš„ WorkerResultã€‚

å®˜æ–¹æ–‡æ¡£:
    https://learn.microsoft.com/azure/ai-foundry/openai/how-to/web-search

ç¯å¢ƒå˜é‡:
    AZURE_AI_PROJECT_ENDPOINT        - Azure AI Foundry é¡¹ç›®ç«¯ç‚¹
    AZURE_AI_API_KEY                 - API Key
    AZURE_AI_MODEL_DEPLOYMENT_NAME   - æ¨¡å‹éƒ¨ç½²åç§° (å¦‚ gpt-4o)

ä½¿ç”¨æ–¹å¼:
    1. å‘½ä»¤è¡Œæœç´¢:
       python web_search_worker.py "æµ¦ä¸œæ–°åŒºå…‰é€šä¿¡äº§ä¸šæ‰¶æŒæ”¿ç­–"

    2. ä½œä¸ºæ¨¡å—å¯¼å…¥:
       from web_search_worker import WebSearchWorker
       worker = WebSearchWorker()
       result = worker.search("æµ¦ä¸œæ–°åŒºå…‰é€šä¿¡äº§ä¸šæ‰¶æŒæ”¿ç­–")  # â†’ WorkerResult

    3. ä½œä¸º FastAPI æœåŠ¡:
       python web_search_worker.py --serve --port 8001
"""

import asyncio
import json
import logging
import os
import re
import sys
import time
from dataclasses import dataclass, field, asdict
from typing import Optional

from dotenv import load_dotenv

load_dotenv()  # åŠ è½½ .env
load_dotenv(".env.web_search")  # åŠ è½½ .env.web_search (è¦†ç›–)

from models import BaseWorker, WorkerResult, PolicyItem

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é»˜è®¤ Instructionsï¼ˆè¦æ±‚è¾“å‡ºé“¾æ¥ã€PDFï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DEFAULT_POLICY_INSTRUCTIONS = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ”¿ç­–ç ”ç©¶åŠ©æ‰‹ã€‚è¯·æ ¹æ®æœç´¢ç»“æœï¼Œå°½å¯èƒ½å®Œæ•´åœ°æå–å’Œå‘ˆç°æ”¿ç­–ä¿¡æ¯ã€‚

è¦æ±‚ï¼š
1. æä¾›æ¯æ¡æ”¿ç­–çš„å®Œæ•´æ ‡é¢˜ã€å‘æ–‡å­—å·ã€å‘å¸ƒæ—¥æœŸã€å‘å¸ƒæœºæ„
2. åˆ—å‡ºæ”¿ç­–çš„å…·ä½“æ¡æ¬¾å’Œæªæ–½ï¼ˆåŸæ–‡æ‘˜å½•ï¼Œä¸è¦æ¦‚æ‹¬ï¼‰
3. åŒ…å«å…·ä½“çš„æ•°å­—ã€æ¯”ä¾‹ã€é‡‘é¢ä¸Šé™ç­‰å…³é”®æ•°æ®
4. æ¯æ¡æ”¿ç­–éƒ½å¿…é¡»ç»™å‡ºå®˜ç½‘åŸæ–‡é“¾æ¥ï¼ˆURLï¼‰
5. å¦‚æœæœ‰PDFä¸‹è½½é“¾æ¥ï¼Œä¹Ÿè¦åˆ—å‡º
6. æ ‡æ³¨æ¯æ¡æ”¿ç­–é€‚ç”¨çš„è¡Œä¸šèŒƒå›´
7. æœç´¢å°½å¯èƒ½å¤šçš„ç›¸å…³æ¥æºï¼Œå¹¿æ³›è¦†ç›–æ”¿åºœå®˜ç½‘ã€æ”¿ç­–åº“ç­‰æ¸ é“

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆä¸¥æ ¼JSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "policies": [
    {
      "title": "æ”¿ç­–å®Œæ•´æ ‡é¢˜",
      "source": "å‘å¸ƒæœºæ„",
      "url": "å®˜ç½‘åŸæ–‡é“¾æ¥",
      "pdf_url": "PDFä¸‹è½½é“¾æ¥ï¼ˆæ²¡æœ‰åˆ™ç•™ç©ºï¼‰",
      "date": "å‘å¸ƒæ—¥æœŸ",
      "summary": "æ”¿ç­–æ‘˜è¦ï¼ˆåŒ…å«å…·ä½“æ•°å­—å’Œæ¯”ä¾‹ï¼‰",
      "support": "å…³é”®æ‰¶æŒå†…å®¹ï¼ˆèµ„é‡‘é¢åº¦ã€è¡¥è´´æ¯”ä¾‹ç­‰ï¼‰",
      "industry": "é€‚ç”¨è¡Œä¸š"
    }
  ]
}"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Web Search Worker
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class WebSearchWorker(BaseWorker):
    """
    Azure OpenAI Responses API + web_search_preview Worker

    ç›´æ¥ä½¿ç”¨ Responses API çš„å†…ç½® web_search_preview å·¥å…·ï¼Œ
    æ— éœ€åˆ›å»º Agentï¼Œæ— éœ€ azure-ai-projects åŒ…ã€‚

    å®ç° BaseWorker æ¥å£:
        worker = WebSearchWorker()
        result = worker.search("æŸ¥è¯¢å†…å®¹")  # â†’ WorkerResult
    """

    name = "web_search"

    def __init__(
        self,
        endpoint: str = None,
        api_key: str = None,
        model_deployment: str = None,
        api_version: str = "2025-04-01-preview",
        instructions: str = None,
        search_context_size: str = "high",
    ):
        self.api_key = api_key or os.environ.get("AZURE_AI_API_KEY")
        self.model_deployment = model_deployment or os.environ.get("AZURE_AI_MODEL_DEPLOYMENT_NAME", "gpt-4o")
        self.api_version = api_version
        self.search_context_size = search_context_size  # "low" | "medium" | "high"
        self.instructions = instructions or DEFAULT_POLICY_INSTRUCTIONS

        # ä» project endpoint æå– OpenAI endpoint
        project_endpoint = endpoint or os.environ.get("AZURE_AI_PROJECT_ENDPOINT", "")
        self.endpoint = self._resolve_openai_endpoint(project_endpoint)

        if not self.endpoint:
            raise ValueError(
                "éœ€è¦è®¾ç½® AZURE_AI_PROJECT_ENDPOINT ç¯å¢ƒå˜é‡ï¼Œ"
                "æˆ–åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥ endpoint å‚æ•°ã€‚\n"
                "è·å–æ–¹å¼: Azure AI Foundry Portal â†’ Project â†’ Settings â†’ Overview"
            )
        if not self.api_key:
            raise ValueError(
                "éœ€è¦è®¾ç½® AZURE_AI_API_KEY ç¯å¢ƒå˜é‡ï¼Œ"
                "æˆ–åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥ api_key å‚æ•°ã€‚"
            )

        self._client = None

    @staticmethod
    def _resolve_openai_endpoint(project_endpoint: str) -> str:
        """
        ä» Foundry Project Endpoint æå– Azure OpenAI å…¼å®¹ Endpointã€‚
        ä¾‹: https://xxx-resource.services.ai.azure.com/api/projects/xxx
          â†’ https://xxx-resource.services.ai.azure.com
        """
        if not project_endpoint:
            return ""
        # å»æ‰ /api/projects/xxx éƒ¨åˆ†ï¼Œä¿ç•™åŸºç¡€ URL
        from urllib.parse import urlparse
        parsed = urlparse(project_endpoint)
        return f"{parsed.scheme}://{parsed.netloc}"

    def _ensure_client(self):
        """å»¶è¿Ÿåˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        if self._client is not None:
            return

        from openai import AzureOpenAI

        logger.info(f"åˆå§‹åŒ– AzureOpenAI å®¢æˆ·ç«¯ (endpoint: {self.endpoint})...")
        self._client = AzureOpenAI(
            api_key=self.api_key,
            api_version=self.api_version,
            azure_endpoint=self.endpoint,
        )
        logger.info("å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

    def search(self, query: str, **kwargs) -> WorkerResult:
        """
        æ‰§è¡Œæœç´¢ï¼Œè¿”å›ç»Ÿä¸€çš„ WorkerResultï¼ˆå®ç° BaseWorker æ¥å£ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢

        Returns:
            WorkerResultï¼ˆåŒ…å« policies, sources ç­‰ï¼‰
        """
        start = time.time()
        self._ensure_client()

        logger.info(f"[web_search] æœç´¢: {query}")

        try:
            response = self._client.responses.create(
                model=self.model_deployment,
                instructions=self.instructions,
                tools=[{"type": "web_search_preview", "search_context_size": self.search_context_size}],
                input=query,
            )

            # æå–å›ç­”æ–‡æœ¬
            answer = response.output_text or ""

            # æå–å¼•ç”¨ URLï¼ˆå»é‡ï¼‰
            sources = []
            seen_urls = set()
            for item in response.output:
                if hasattr(item, "content"):
                    for content in item.content:
                        if hasattr(content, "annotations"):
                            for ann in content.annotations:
                                if hasattr(ann, "type") and ann.type == "url_citation":
                                    if ann.url not in seen_urls:
                                        seen_urls.add(ann.url)
                                        sources.append(ann.url)

            # æå–ç”¨é‡ä¿¡æ¯
            usage = {}
            if hasattr(response, "usage") and response.usage:
                usage = {
                    "input_tokens": getattr(response.usage, "input_tokens", 0),
                    "output_tokens": getattr(response.usage, "output_tokens", 0),
                    "total_tokens": getattr(response.usage, "total_tokens", 0),
                }

            # è§£æ LLM å›ç­” â†’ PolicyItem åˆ—è¡¨
            policies = self._parse_policies(answer, sources)

            elapsed = round(time.time() - start, 1)
            logger.info(f"[web_search] å®Œæˆ, æ”¿ç­–æ•°: {len(policies)}, å¼•ç”¨æ•°: {len(sources)}, è€—æ—¶: {elapsed}s")

            return WorkerResult(
                query=query,
                policies=policies,
                sources=sources,
                worker=self.name,
                duration=elapsed,
                token_usage=usage,
                raw_answer=answer,
            )

        except Exception as e:
            elapsed = round(time.time() - start, 1)
            logger.error(f"[web_search] æœç´¢å¤±è´¥: {e}")
            return WorkerResult(
                query=query,
                worker=self.name,
                duration=elapsed,
                error=str(e),
            )

    @staticmethod
    def _parse_policies(answer: str, sources: list[str]) -> list[PolicyItem]:
        """
        ä» LLM å›ç­”ä¸­è§£æ PolicyItem åˆ—è¡¨ã€‚
        ä¼˜å…ˆå°è¯• JSON è§£æï¼Œå¤±è´¥åˆ™ç”¨å¼•ç”¨ URL æ„å»ºåŸºç¡€åˆ—è¡¨ã€‚
        """
        # å°è¯•ä»å›ç­”ä¸­æå– JSON
        json_match = re.search(r'\{[\s\S]*"policies"[\s\S]*\}', answer)
        if json_match:
            try:
                parsed = json.loads(json_match.group())
                items = []
                for p in parsed.get("policies", []):
                    items.append(PolicyItem(
                        title=p.get("title") or p.get("policy_title", ""),
                        url=p.get("url", ""),
                        source=p.get("source", ""),
                        date=p.get("date") or p.get("publish_date", ""),
                        summary=p.get("summary", ""),
                        support=p.get("support") or p.get("key_support", ""),
                        pdf_url=p.get("pdf_url", ""),
                        industry=p.get("industry") or p.get("applicable_industry", ""),
                    ))
                if items:
                    return items
            except json.JSONDecodeError:
                pass

        # JSON è§£æå¤±è´¥ï¼šç”¨å¼•ç”¨ URL æ„å»ºåŸºç¡€åˆ—è¡¨
        if sources:
            return [
                PolicyItem(title=f"æœç´¢ç»“æœ {i+1}", url=url)
                for i, url in enumerate(sources)
            ]

        return []

    def search_stream(self, query: str):
        """
        æµå¼æœç´¢ï¼Œé€æ­¥ yield æ–‡æœ¬ç‰‡æ®µ

        Args:
            query: æœç´¢æŸ¥è¯¢

        Yields:
            dict: {"type": "delta"|"citation"|"done", "content": ...}
        """
        self._ensure_client()

        logger.info(f"æµå¼æœç´¢: {query}")

        try:
            stream_response = self._client.responses.create(
                model=self.model_deployment,
                instructions=self.instructions,
                tools=[{"type": "web_search_preview", "search_context_size": self.search_context_size}],
                input=query,
                stream=True,
            )

            for event in stream_response:
                if event.type == "response.output_text.delta":
                    yield {"type": "delta", "content": event.delta}

                elif event.type == "response.output_item.done":
                    if event.item.type == "message":
                        text_content = event.item.content[-1]
                        if hasattr(text_content, "annotations"):
                            for ann in text_content.annotations:
                                if ann.type == "url_citation":
                                    yield {
                                        "type": "citation",
                                        "content": {
                                            "url": ann.url,
                                            "title": getattr(ann, "title", ""),
                                        },
                                    }

                elif event.type == "response.completed":
                    yield {"type": "done", "content": ""}

        except Exception as e:
            logger.error(f"æµå¼æœç´¢å¤±è´¥: {e}")
            yield {"type": "error", "content": str(e)}

    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self._client:
            self._client.close()
            self._client = None
            logger.info("å®¢æˆ·ç«¯å·²å…³é—­")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FastAPI æœåŠ¡æ¨¡å¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_app() -> "FastAPI":
    """åˆ›å»º FastAPI åº”ç”¨"""
    from fastapi import FastAPI, Query
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import StreamingResponse, JSONResponse

    app = FastAPI(title="Web Search Worker API", version="1.0")
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )

    worker = WebSearchWorker()

    @app.get("/search")
    async def search(q: str = Query(..., description="æœç´¢æŸ¥è¯¢")):
        """åŒæ­¥æœç´¢æ¥å£ï¼Œè¿”å›å®Œæ•´ç»“æœ"""
        result = worker.search(q)
        return JSONResponse(content=result.to_dict())

    @app.get("/search/stream")
    async def search_stream(q: str = Query(..., description="æœç´¢æŸ¥è¯¢")):
        """æµå¼æœç´¢æ¥å£ï¼ŒSSE æ ¼å¼"""
        def event_generator():
            for chunk in worker.search_stream(q):
                yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
        )

    @app.get("/health")
    async def health():
        return {"status": "ok"}

    return app


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å‘½ä»¤è¡Œå…¥å£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def main():
    import argparse

    parser = argparse.ArgumentParser(description="Web Search Worker")
    parser.add_argument("query", nargs="?", help="æœç´¢æŸ¥è¯¢å†…å®¹")
    parser.add_argument("--serve", action="store_true", help="å¯åŠ¨ FastAPI æœåŠ¡")
    parser.add_argument("--port", type=int, default=8001, help="æœåŠ¡ç«¯å£ (é»˜è®¤ 8001)")
    parser.add_argument("--stream", action="store_true", help="ä½¿ç”¨æµå¼è¾“å‡º")
    parser.add_argument("--json", action="store_true", help="è¾“å‡º JSON æ ¼å¼")
    parser.add_argument("--context", choices=["low", "medium", "high"], default="medium", help="æœç´¢ä¸Šä¸‹æ–‡é‡ (é»˜è®¤ medium, high=æ›´å¤šé“¾æ¥)")
    args = parser.parse_args()

    # æœåŠ¡æ¨¡å¼
    if args.serve:
        import uvicorn
        app = create_app()
        logger.info(f"å¯åŠ¨ Web Search Worker API æœåŠ¡ï¼Œç«¯å£: {args.port}")
        uvicorn.run(app, host="0.0.0.0", port=args.port)
        return

    # æœç´¢æ¨¡å¼
    if not args.query:
        parser.print_help()
        return

    worker = WebSearchWorker(search_context_size=args.context)

    try:
        if args.stream:
            # æµå¼è¾“å‡º
            for chunk in worker.search_stream(args.query):
                if chunk["type"] == "delta":
                    print(chunk["content"], end="", flush=True)
                elif chunk["type"] == "citation":
                    print(f"\nğŸ“ {chunk['content']['url']}")
                elif chunk["type"] == "done":
                    print("\n\nâœ… å®Œæˆ")
        else:
            # ç»Ÿä¸€è¾“å‡º
            result = worker.search(args.query)

            if args.json:
                print(result.to_json())
            else:
                print(f"\n{'='*60}")
                print(f"ğŸ” æŸ¥è¯¢: {result.query}")
                print(f"{'='*60}")

                if result.error:
                    print(f"\nâŒ é”™è¯¯: {result.error}")
                else:
                    print(f"\nğŸ“ æ‰¾åˆ° {result.policy_count} æ¡æ”¿ç­– (Worker: {result.worker}, è€—æ—¶: {result.duration}s)")
                    for i, p in enumerate(result.policies, 1):
                        print(f"\n  {i}. {p.title}")
                        if p.source: print(f"     æ¥æº: {p.source}")
                        if p.date:   print(f"     æ—¥æœŸ: {p.date}")
                        if p.summary: print(f"     æ‘˜è¦: {p.summary[:100]}...")
                        if p.support: print(f"     ğŸ’° {p.support}")
                        if p.url:     print(f"     ğŸ“„ {p.url}")
                        if p.pdf_url: print(f"     ğŸ“¥ {p.pdf_url}")

                    if result.sources:
                        print(f"\nğŸ“ å¼•ç”¨æ¥æº ({len(result.sources)} ä¸ª):")
                        for i, url in enumerate(result.sources, 1):
                            print(f"   {i}. {url}")

                    if result.token_usage:
                        print(f"\nğŸ“Š Token: {result.token_usage}")
    finally:
        worker.close()


if __name__ == "__main__":
    asyncio.run(main())
