"""
Orchestrator â€” AI æ™ºèƒ½è°ƒåº¦
==========================
æ ¹æ®ä¼æŸ¥æŸ¥ä¼ä¸šä¿¡æ¯ï¼ŒAI æ€è€ƒåæ‹†åˆ†æœç´¢ä»»åŠ¡ï¼Œå¹¶åŠ¨æ€å†³å®šæ˜¯å¦è°ƒç”¨ browse useã€‚

æµç¨‹ï¼š
    1. æ¥æ”¶ä¼æŸ¥æŸ¥ä¼ä¸šä¿¡æ¯ï¼ˆåç§°ã€è¡Œä¸šã€åœ°åŒºã€æ ‡ç­¾ç­‰ï¼‰
    2. AI åˆ†æä¼ä¸šç‰¹å¾ â†’ ç”Ÿæˆè‹¥å¹² web search ä»»åŠ¡
    3. å¹¶è¡Œæ‰§è¡Œ web search
    4. AI è¯„ä¼°æœç´¢ç»“æœ â†’ å†³å®šå“ªäº›éœ€è¦ browse use æ·±åº¦æŠ“å–
    5. æ‰§è¡Œ browse useï¼ˆå¯é€‰ï¼‰
    6. åˆå¹¶ + å»é‡ â†’ è¿”å›æœ€ç»ˆç»“æœ

ç”¨æ³•ï¼š
    from orchestrator import Orchestrator

    orch = Orchestrator()
    # ä»… AI æ‹†åˆ†ï¼ˆä¸æ‰§è¡Œæœç´¢ï¼Œç”¨äºè°ƒè¯•ï¼‰
    plan = orch.plan(company_info)
    # å®Œæ•´æµç¨‹
    result = await orch.run(company_info)
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable

from dotenv import load_dotenv

load_dotenv()
load_dotenv(".env.web_search")

from models import PolicyItem, WorkerResult
from policy_categories import get_layers_reference, get_dimensions_reference

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# åŠ è½½ä¸“å®¶ Prompt æ–‡ä»¶
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_PROMPT_DIR = Path(__file__).parent / "prompts"

def _load_prompt(filename: str) -> str:
    """ä» prompts/ ç›®å½•åŠ è½½ markdown prompt æ–‡ä»¶"""
    filepath = _PROMPT_DIR / filename
    if filepath.exists():
        return filepath.read_text(encoding="utf-8")
    logger.warning(f"Prompt æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    return ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AI æ€è€ƒ Prompt
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_plan_system_prompt() -> str:
    """æ„å»º PLAN é˜¶æ®µçš„ system promptï¼Œèåˆä¸“å®¶æ¡†æ¶ + å››å±‚åˆ†ç±» + è¾“å‡ºæ ¼å¼"""
    expert_knowledge = _load_prompt("expert_system_prompt.md")
    layers_ref = get_layers_reference()
    dimensions_ref = get_dimensions_reference()

    return (
        "ä½ æ˜¯ä¸€ä¸ªæ”¿ç­–æœç´¢è°ƒåº¦ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¼ä¸šçš„å·¥å•†æ•°æ®ï¼Œè¿›è¡Œæ·±åº¦ç‰¹å¾å·¥ç¨‹ï¼Œå¹¶ç”Ÿæˆç²¾å‡†çš„æœç´¢ä»»åŠ¡åˆ—è¡¨ã€‚\n\n"
        "# ä¸“å®¶è®¤çŸ¥æ¡†æ¶\n\n"
        f"{expert_knowledge}\n\n"
        "# æ”¿ç­–åˆ†ç±»å‚è€ƒ\n\n"
        f"{layers_ref}\n\n"
        f"{dimensions_ref}\n\n"
        "# æ‰§è¡Œè§„åˆ™\n\n"
        "ã€æ ¸å¿ƒåŸåˆ™ã€‘\n"
        "1. åœ¨\"å¾®è§‚é¢—ç²’åº¦ç‰¹å¾æ˜ å°„\"çš„åŸºç¡€ä¸Šï¼Œå¿…é¡»ä¿ç•™\"åœ°åŒº+è¡Œä¸š+è¡¥è´´\"çš„åŸºç¡€æœç´¢æ¨¡å¼\n"
        "2. å…ˆå¯¹ä¼ä¸šæ•°æ®è¿›è¡Œã€ç‰¹å¾é€†å‘å·¥ç¨‹ã€‘ï¼Œå†ç”Ÿæˆæœç´¢ä»»åŠ¡\n"
        "3. è¾“å‡ºçš„ tasks ä¸­ï¼Œæ¯ä¸ªæœç´¢è¯å¿…é¡»å…·ä½“ã€å¯ç›´æ¥åœ¨ Bing/ç™¾åº¦ æœç´¢\n"
        "4. ç©ºé—´è½½ä½“æœç´¢è¯å¿…é¡»åŒ…å« [å›­åŒºåç§°] + ç®¡å§”ä¼š/ä¸“é¡¹èµ„é‡‘ï¼Œè€Œéä»…æœå¸‚çº§æ”¿ç­–\n"
        "5. åˆè§„ç†”æ–­æ£€æŸ¥ï¼šå¦‚æœä¼ä¸šæœ‰ä¸¥é‡å¤±ä¿¡ï¼Œè®¾ç½® compliance_veto.passed = false\n\n"
        "ã€æœç´¢è¯è´¨é‡è¦æ±‚ â€” æå…¶é‡è¦ã€‘\n"
        "- æ¯ä¸ªç»´åº¦è‡³å°‘ 1-3 ä¸ªæœç´¢è¯\n"
        "- æœç´¢è¯ä¸è¦è¶…è¿‡ 20 ä¸ªå­—\n"
        "- âš ï¸ æ‰€æœ‰æœç´¢è¯å¿…é¡»åŒ…å«ä¼ä¸šæ‰€åœ¨åœ°åŒºï¼ˆå¦‚\"ä¸Šæµ·\"\"æµ¦ä¸œæ–°åŒº\"ï¼‰ï¼Œä¸¥ç¦ç”Ÿæˆä¸å¸¦åœ°åŒºçš„æœç´¢è¯\n"
        "- âš ï¸ äº§ä¸šé“¾ç»´åº¦å¿…é¡»ä¿ç•™è‡³å°‘ä¸€ä¸ª\"åœ°åŒº+è¡Œä¸š+è¡¥è´´/æ‰¶æŒ\"çš„åŸºç¡€æœç´¢è¯ï¼ˆå¦‚\"æµ¦ä¸œæ–°åŒº å…‰é€šä¿¡ äº§ä¸šæ‰¶æŒæ”¿ç­–\"ï¼‰ï¼Œè¿™æ˜¯æœç´¢å¼•æ“æœ€æ“…é•¿çš„æ¨¡å¼\n"
        "- âš ï¸ äº§ä¸šé“¾æœ¯è¯­ï¼ˆå¼ºé“¾è¡¥é“¾ã€é¦–å°å¥—ç­‰ï¼‰ä½œä¸ºé¢å¤–è¡¥å……æœç´¢ï¼Œä¸æ›¿ä»£åŸºç¡€æ¨¡å¼ï¼Œä¸”å¿…é¡»å¸¦åœ°åŒºå‰ç¼€\n"
        "- ä¼˜å…ˆæœç´¢å›­åŒºçº§ > åŒºçº§ > å¸‚çº§æ”¿ç­–\n"
        "- å¤–èµ„ä¼ä¸šé¢å¤–æœç´¢\"å¤–èµ„ç ”å‘ä¸­å¿ƒ\"ç›¸å…³æ”¿ç­–\n"
        "- é«˜æ ¡èƒŒæ™¯ä¼ä¸šé¢å¤–æœç´¢\"äº§å­¦ç ”åˆä½œ\"ç›¸å…³æ”¿ç­–\n\n"
        "ã€è¾“å‡ºæ ¼å¼ â€” ä¸¥æ ¼ JSONã€‘\n"
        "{{\n"
        "  \"feature_engineering\": {{\n"
        "    \"spatial\": \"ç©ºé—´è½½ä½“åˆ†æç»“æœ\",\n"
        "    \"industry_chain\": \"äº§ä¸šé“¾åœ°ä½åˆ†æ\",\n"
        "    \"identity\": \"èº«ä»½å±æ€§åˆ†æ\",\n"
        "    \"hr_dynamics\": \"äººåŠ›èµ„æºåŠ¨æ€åˆ†æ\",\n"
        "    \"compliance\": \"åˆè§„çŠ¶æ€åˆ†æ\",\n"
        "    \"tax_financial\": \"ç¨æ”¶ä¸è´¢åŠ¡ä¼˜æƒ åˆ†æ\",\n"
        "    \"talent_incentive\": \"äººæ‰æ¿€åŠ±æ”¿ç­–åˆ†æ\"\n"
        "  }},\n"
        "  \"gap_analysis\": {{\n"
        "    \"money\": \"è¡¥è´´æ½œåŠ›è¯„ä¼°\",\n"
        "    \"qualification\": \"èµ„è´¨æ½œåŠ›è¯„ä¼°\",\n"
        "    \"talent\": \"äººæ‰æ”¿ç­–æ½œåŠ›\",\n"
        "    \"compliance\": \"åˆè§„é£é™©è¯„ä¼°\"\n"
        "  }},\n"
        "  \"analysis\": \"ç»¼åˆåˆ†æï¼ˆ2-3å¥è¯ï¼‰\",\n"
        "  \"tasks\": [\n"
        "    {{\n"
        "      \"dimension\": \"ç©ºé—´è½½ä½“|äº§ä¸šé“¾|èº«ä»½å±æ€§|äººåŠ›èµ„æº|åˆè§„|ç¨æ”¶ä¸è´¢åŠ¡|äººæ‰æ¿€åŠ±\",\n"
        "      \"layer\": \"åŸºç¡€å±‚|å‘å±•å±‚|äººæ‰å±‚|è£èª‰å±‚\",\n"
        "      \"search_term\": \"å…·ä½“æœç´¢å…³é”®è¯\",\n"
        "      \"priority\": \"high|medium|low\",\n"
        "      \"reason\": \"æœç´¢æ„å›¾è¯´æ˜\",\n"
        "      \"focus_hints\": \"ç»™æœç´¢æ¨¡å‹çš„é‡ç‚¹å…³æ³¨æŒ‡å¼•\"\n"
        "    }}\n"
        "  ],\n"
        "  \"compliance_veto\": {{\n"
        "    \"passed\": true,\n"
        "    \"risk_level\": \"none|low|medium|high|blocked\",\n"
        "    \"detail\": \"åˆè§„åˆ¤æ–­è¯´æ˜\"\n"
        "  }}\n"
        "}}\n"
    )

EVALUATE_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ”¿ç­–æœç´¢è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚æ ¹æ® web search æœç´¢ç»“æœï¼Œåˆ¤æ–­å“ªäº›æ”¿ç­–æ¡ç›®éœ€è¦ç”¨æµè§ˆå™¨æ·±åº¦æŠ“å–ã€‚

ã€éœ€è¦æ·±åº¦æŠ“å–çš„æƒ…å†µã€‘
1. æ‘˜è¦ä¸å®Œæ•´ï¼Œåªæœ‰"..."æˆ–è¿‡äºç®€çŸ­ï¼ˆå°‘äº20å­—ï¼‰
2. URL æŒ‡å‘ PDF æ–‡ä»¶ï¼ˆ.pdf ç»“å°¾ï¼‰
3. ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼ˆå¦‚æ‰¶æŒé‡‘é¢ã€ç”³æŠ¥æ¡ä»¶ï¼‰
4. æ¥è‡ªæ”¿åºœå®˜ç½‘(.gov.cn)ä½†æ‘˜è¦æ¨¡ç³Šï¼Œå¯èƒ½åŒ…å«æ›´è¯¦ç»†çš„æ”¿ç­–åŸæ–‡
5. æ ‡é¢˜çœ‹èµ·æ¥å¾ˆç›¸å…³ä½†æ²¡æœ‰å…·ä½“å†…å®¹

ã€ä¸éœ€è¦æ·±åº¦æŠ“å–çš„æƒ…å†µã€‘
1. æ‘˜è¦å·²ç»åŒ…å«å®Œæ•´çš„æ”¿ç­–è¦ç‚¹å’Œé‡‘é¢
2. æ¥è‡ªæ–°é—»èšåˆç«™ï¼Œå†…å®¹å¯èƒ½åªæ˜¯è½¬è½½
3. URL å·²å¤±æ•ˆæˆ–ä¸å¯è®¿é—®çš„è¿¹è±¡

è¾“å‡ºä¸¥æ ¼ JSONï¼š
{{
  "evaluation": "æ•´ä½“è¯„ä»·ï¼ˆ1å¥è¯ï¼‰",
  "browse_targets": [
    {{
      "title": "æ”¿ç­–æ ‡é¢˜",
      "url": "éœ€è¦æ·±åº¦æŠ“å–çš„URL",
      "reason": "ä¸ºä»€ä¹ˆéœ€è¦æ·±åº¦æŠ“å–"
    }}
  ],
  "skip_reasons": ["è·³è¿‡é¡¹1çš„åŸå› ", "è·³è¿‡é¡¹2çš„åŸå› "]
}}
"""

# â”€â”€ æ‰“åˆ†æ’åº Prompt â”€â”€

def _build_scoring_system_prompt() -> str:
    """åŠ¨æ€ç”Ÿæˆæ‰“åˆ† system promptï¼Œæ³¨å…¥å½“å‰æ—¥æœŸï¼Œä½¿ç”¨5ç»´åº¦è¯„åˆ†ä½“ç³»"""
    today = datetime.now().strftime("%Y-%m-%d")
    current_year = datetime.now().year
    return (
        f"ä½ æ˜¯ä¸€ä¸ªæ”¿ç­–åŒ¹é…è¯„åˆ†ä¸“å®¶ã€‚å½“å‰æ—¥æœŸä¸º {today}ã€‚\n"
        "ä½ éœ€è¦ç”¨5ä¸ªç»´åº¦ä¸ºæ¯æ¡æ”¿ç­–æ‰“åˆ†ï¼Œç„¶ååŠ æƒè®¡ç®—ç»¼åˆåˆ†ã€‚\n\n"

        "ã€é‡è¦åŸåˆ™ã€‘\n"
        "- æ¯æ¡æ”¿ç­–éƒ½å¿…é¡»è®¤çœŸè¯„åˆ†ï¼Œä¸è¦ç»™0åˆ†ï¼ˆé™¤éä¸ä¼ä¸šå®Œå…¨æ— å…³ï¼Œå¦‚å¤–çœæ”¿ç­–ï¼‰\n"
        "- å¯å¾—æ€§ä½ä¸æ˜¯æ·˜æ±°ç†ç”±ï¼Œè€Œæ˜¯æ”¹è¿›å»ºè®®æ–¹å‘ï¼ˆä¼ä¸šå¯ä»¥ä¸ºä¹‹åŠªåŠ›ï¼‰\n"
        "- æ—¶æ•ˆæ€§æ˜¯ç¡¬æ ‡å‡†ï¼šè¿‡æœŸæ”¿ç­–å¿…é¡»åœ¨ç´§è¿«æ€§ç»´åº¦ä½“ç°ï¼Œä½†å…¶ä»–ç»´åº¦æ­£å¸¸è¯„åˆ†\n"
        "- æœç´¢é˜¶æ®µé‡è¦†ç›–ç‡ï¼Œè¯„åˆ†ç”¨äºæ’åºè€Œéç­›é™¤\n\n"

        "ã€5ç»´åº¦è¯„åˆ†ä½“ç³»ï¼ˆæ¯ä¸ªç»´åº¦ 0-100 åˆ†ï¼‰ã€‘\n\n"

        "1. ğŸ’° é‡‘é¢ä»·å€¼ score_amountï¼ˆæƒé‡30%ï¼‰â€” ä¼ä¸šèƒ½æ‹¿åˆ°å¤šå°‘é’±\n"
        "   100åˆ†: >500ä¸‡ï¼ˆSçº§ï¼‰  80åˆ†: 100-500ä¸‡ï¼ˆAçº§ï¼‰  60åˆ†: 20-100ä¸‡ï¼ˆBçº§ï¼‰\n"
        "   40åˆ†: 5-20ä¸‡ï¼ˆCçº§ï¼‰  20åˆ†: <5ä¸‡ï¼ˆDçº§ï¼‰\n"
        "   é—¨æ§›å‹æ”¿ç­–æŒ‰æ’¬åŠ¨ä»·å€¼è¯„ä¼°ã€‚ç¨æ”¶ä¼˜æƒ æŠ˜ç®—å®é™…çœç¨é‡‘é¢ã€‚\n\n"

        "2. ğŸ¯ ç‹¬å æ€§ score_exclusivityï¼ˆæƒé‡25%ï¼‰â€” ç«äº‰å¯¹æ‰‹å¤šä¸å¤š\n"
        "   100åˆ†: å®šåˆ¶å‹(<50å®¶)  80åˆ†: è¡Œä¸šå‹(<200å®¶)  60åˆ†: å›­åŒºå‹\n"
        "   40åˆ†: åœ°åŒºå‹  20åˆ†: æ™®æƒ å‹\n\n"

        "3. âœ… å¯å¾—æ€§ score_feasibilityï¼ˆæƒé‡10%ï¼‰â€” ä¼ä¸šå½“å‰èƒ½å¦æ»¡è¶³æ¡ä»¶\n"
        "   âš ï¸ å¯å¾—æ€§ä½â‰ ä¸é‡è¦ï¼ä½å¯å¾—æ€§è¯´æ˜ä¼ä¸šéœ€è¦ä¸ºä¹‹åŠªåŠ›ï¼ˆå¦‚å…ˆæ‹¿é«˜ä¼è®¤å®šï¼‰ï¼Œæ˜¯æ”¹è¿›å»ºè®®çš„å¥½æ–¹å‘ã€‚\n"
        "   100åˆ†: å…¨æ»¡è¶³  80åˆ†: ç¼º1é¡¹éå…³é”®  60åˆ†: ç¼º1-2é¡¹å¯çŸ­æœŸè¡¥é½\n"
        "   40åˆ†: ç¼ºå…³é”®æ¡ä»¶éœ€6æœˆ+  20åˆ†: åŸºæœ¬ä¸æ»¡è¶³ï¼ˆä½†ä»åº”å±•ç¤ºç»™ç”¨æˆ·ï¼‰\n\n"

        "4. â° ç´§è¿«æ€§ score_urgencyï¼ˆæƒé‡25%ï¼‰â€” æ—¶æ•ˆæ€§ï¼Œæ˜¯å¦è¿˜èƒ½ç”³æŠ¥\n"
        f"   âš ï¸ è¿™æ˜¯æœ€é‡è¦çš„ç»´åº¦ã€‚å½“å‰æ—¥æœŸ {today}ï¼Œä¸¥æ ¼åˆ¤æ–­ï¼\n"
        f"   100åˆ†: ç”³æŠ¥æˆªæ­¢<30å¤©\n"
        "   80åˆ†:  æˆªæ­¢30-90å¤©\n"
        "   60åˆ†:  åŠå¹´å†…æˆ–å¸¸å¹´å¯ç”³\n"
        "   40åˆ†:  é¢„è®¡ä¸‹æ‰¹æ¬¡å¼€æ”¾ï¼ˆå¦‚å¹´åº¦æ”¿ç­–ç­‰æ–°ä¸€è½®ï¼‰\n"
        "   20åˆ†:  æœ‰æ•ˆæœŸå·²è¿‡ï¼Œä½†é¢„è®¡æœ‰æ¥ç»­æ”¿ç­–ï¼ˆå¦‚åå››äº”â†’åäº”äº”ï¼‰ï¼Œä»æœ‰å‚è€ƒä»·å€¼\n"
        "   5åˆ†:   æœ‰æ•ˆæœŸå·²è¿‡ï¼Œæ— æ¥ç»­è¿¹è±¡\n\n"

        "5. ğŸ”„ æŒç»­æ€§ score_sustainabilityï¼ˆæƒé‡10%ï¼‰â€” å¯å¦åå¤è·å¾—\n"
        "   100åˆ†: æ¯å¹´å¯ç”³  80åˆ†: å‘¨æœŸæ€§  60åˆ†: ä¸€æ¬¡æ€§+é—¨æ§›\n"
        "   40åˆ†: çº¯ä¸€æ¬¡æ€§  20åˆ†: ä¸€æ¬¡æ€§ä¸”å°é¢\n\n"

        f"ã€æ—¶æ•ˆæ€§åˆ¤æ–­è§„åˆ™ â€” å½“å‰ {today}ã€‘\n"
        f"- æœ‰æ•ˆæœŸæ ‡æ³¨'è‡³2025-12-31'ä¸”ä»Šå¤©æ˜¯{today} â†’ å·²è¿‡æœŸ â†’ score_urgencyâ‰¤20\n"
        f"- å¹´åº¦ç”³æŠ¥é€šçŸ¥å·²æˆªæ­¢ â†’ score_urgency=5\n"
        f"- åå››äº”æ¡†æ¶æ”¿ç­–(2021-2025) â†’ score_urgency=20ï¼ˆå¯èƒ½æœ‰åäº”äº”æ¥ç»­ï¼‰\n"
        f"- å‘å¸ƒè¶…3å¹´æ— 'é•¿æœŸæœ‰æ•ˆ' â†’ score_urgencyæœ€é«˜40\n"
        f"- 2026å¹´æ–°å‘å¸ƒä¸”åœ¨ç”³æŠ¥æœŸ â†’ score_urgencyâ‰¥80\n"
        f"- ä¸ä¼ä¸šè¡Œä¸š/åœ°åŒºå®Œå…¨æ— å…³ â†’ æ‰€æœ‰ç»´åº¦â‰¤10\n\n"

        "ã€æœ‰æ•ˆæœŸåˆ¤æ–­ã€‘\n"
        "- æ ‡é¢˜/æ‘˜è¦æœ‰å¹´ä»½èŒƒå›´â†’æå–  - å·²æœ‰validityâ†’ç›´æ¥ä½¿ç”¨\n"
        "- é•¿æœŸæ”¿ç­–â†’'é•¿æœŸæœ‰æ•ˆ'  - æ— æ³•åˆ¤æ–­â†’'è¯·æŸ¥åŸæ–‡ç¡®è®¤'\n\n"

        "ã€é‡‘é¢æå–ä¸åˆ†çº§ã€‘\n"
        "- amount_level: S(>500ä¸‡)/A(100-500ä¸‡)/B(20-100ä¸‡)/C(5-20ä¸‡)/D(<5ä¸‡)/?ï¼ˆæœªçŸ¥ï¼‰\n\n"

        "ã€ç»¼åˆåˆ†ã€‘relevance = amountÃ—0.3 + exclusivityÃ—0.25 + urgencyÃ—0.25 + feasibilityÃ—0.1 + sustainabilityÃ—0.1\n"
        "ï¼ˆå››èˆäº”å…¥å–æ•´ã€‚æœ€ä½åˆ†5åˆ†ï¼Œä¸è¦ç»™0åˆ†ï¼Œé™¤éå®Œå…¨æ— å…³ã€‚ï¼‰\n\n"

        "è¾“å‡ºä¸¥æ ¼ JSONï¼š\n"
        "{{\n"
        "  \"scored_policies\": [\n"
        "    {{\n"
        "      \"index\": 1,\n"
        "      \"score_amount\": 80,\n"
        "      \"score_exclusivity\": 60,\n"
        "      \"score_feasibility\": 70,\n"
        "      \"score_urgency\": 80,\n"
        "      \"score_sustainability\": 60,\n"
        "      \"relevance\": 72,\n"
        "      \"validity\": \"2026-12-31\",\n"
        "      \"amount\": \"æœ€é«˜500ä¸‡\",\n"
        "      \"amount_level\": \"A\",\n"
        "      \"reason\": \"è¯„åˆ†ç†ç”±ï¼ˆå«ç‹¬å æ€§å’Œå¯å¾—æ€§åˆ¤æ–­ï¼‰\"\n"
        "    }}\n"
        "  ]\n"
        "}}\n"
    )

# â”€â”€ å›è·¯è¯„ä¼° Prompt â”€â”€

def _build_round_review_system_prompt() -> str:
    """æ„å»ºå›è·¯è¯„ä¼° system promptï¼ŒæŒ‰5ç»´åº¦+4å±‚åŒé‡è¯„ä¼°"""
    expert_knowledge = _load_prompt("expert_system_prompt.md")
    layers_ref = get_layers_reference()
    dimensions_ref = get_dimensions_reference()

    return (
        "ä½ æ˜¯ä¸€ä¸ªæ”¿ç­–æœç´¢è´¨é‡è¯„å®¡ä¸“å®¶ã€‚ä½ åˆšå®Œæˆäº†ä¸€è½®æœç´¢ï¼Œç°åœ¨éœ€è¦åˆ¤æ–­ç»“æœè´¨é‡ã€‚\n\n"
        "# ä¸“å®¶è®¤çŸ¥æ¡†æ¶\n\n"
        f"{expert_knowledge}\n\n"
        "# å‚è€ƒåˆ†ç±»\n\n"
        f"{layers_ref}\n\n"
        f"{dimensions_ref}\n\n"
        "ã€ä½ çš„ä»»åŠ¡ã€‘\n"
        "æ ¹æ®ä¼ä¸šç‰¹å¾å·¥ç¨‹ç»“æœå’Œå·²æœåˆ°çš„æ”¿ç­–ï¼ŒåŒæ—¶ä»ä¸¤ä¸ªè§’åº¦è¯„ä¼°è¦†ç›–åº¦ï¼š\n\n"
        "A. ç»´åº¦è¦†ç›–ï¼ˆ7ç»´åº¦ï¼‰ï¼š\n"
        "1. ç©ºé—´è½½ä½“ â€” æ˜¯å¦æœåˆ°äº†å›­åŒºçº§/åŠŸèƒ½åŒºçº§æ”¿ç­–ï¼Ÿ\n"
        "2. äº§ä¸šé“¾ â€” æ˜¯å¦è¦†ç›–äº†ä¼ä¸šåœ¨äº§ä¸šé“¾ä¸­çš„å…³é”®ç¯èŠ‚æ”¿ç­–ï¼Ÿ\n"
        "3. èº«ä»½å±æ€§ â€” å¤–èµ„/å›½èµ„/é«˜æ ¡ç­‰èº«ä»½ä¸“å±æ”¿ç­–æ˜¯å¦å·²è¦†ç›–ï¼Ÿ\n"
        "4. äººåŠ›èµ„æº â€” å¢å‘˜/ç¨³å‘˜/äººæ‰è®¤å®šç›¸å…³æ”¿ç­–æ˜¯å¦å·²è¦†ç›–ï¼Ÿ\n"
        "5. åˆè§„ â€” å¦‚æœ‰åˆè§„é£é™©ï¼Œæ˜¯å¦æœåˆ°äº†ä¿¡ç”¨ä¿®å¤è·¯å¾„ï¼Ÿ\n"
        "6. ç¨æ”¶ä¸è´¢åŠ¡ â€” æ˜¯å¦æœåˆ°äº†ç ”å‘åŠ è®¡æ‰£é™¤ã€ä¼ä¸šæ‰€å¾—ç¨ä¼˜æƒ ã€å¢å€¼ç¨å‡å…ç­‰ç¨æ”¶æ”¿ç­–ï¼Ÿ\n"
        "7. äººæ‰æ¿€åŠ± â€” æ˜¯å¦æœåˆ°äº†é¢å‘å‘˜å·¥ä¸ªäººçš„æ”¿åºœå¥–åŠ±ï¼ˆé‡ç‚¹äº§ä¸šäººæ‰å¥–åŠ±ã€è½æˆ·ã€èŒç§°è¯„å®šï¼‰ï¼Ÿ\n\n"
        "B. ä¸šåŠ¡å±‚è¦†ç›–ï¼ˆ4å±‚ï¼‰ï¼šåŸºç¡€å±‚/å‘å±•å±‚/äººæ‰å±‚/è£èª‰å±‚ å„æœ‰å¤šå°‘æœ‰æ•ˆç»“æœï¼Ÿ\n\n"
        "ã€åˆ¤æ–­æ ‡å‡†ã€‘\n"
        "- æ¯ä¸ªç›¸å…³ç»´åº¦è‡³å°‘æœ‰ 1-2 æ¡æœ‰æ•ˆæ”¿ç­–ï¼ˆå« URL å’Œæ‰¶æŒå†…å®¹ï¼‰ç®—\"è¶³å¤Ÿ\"\n"
        "- æŸç»´åº¦ 0 æ¡ç»“æœï¼Œæˆ–å…¨éƒ¨æ‘˜è¦ç©ºç™½ â†’ \"ä¸è¶³\"\n"
        "- æœç´¢è¯å¤ªæ³›ï¼ˆç»“æœä¸ç›¸å…³ï¼‰æˆ–å¤ªçª„ï¼ˆ0 ç»“æœï¼‰â†’ éœ€è¦è°ƒæ•´\n"
        "- è¡¥å……æœç´¢è¯åº”éµå¾ªä¸“å®¶æ¡†æ¶çš„æœç´¢æ„å»ºè§„åˆ™ï¼ˆå›­åŒºçº§ä¼˜å…ˆï¼‰\n\n"
        "è¾“å‡ºä¸¥æ ¼ JSONï¼š\n"
        "{{\n"
        "  \"overall_quality\": \"good|fair|poor\",\n"
        "  \"quality_reason\": \"æ•´ä½“è´¨é‡åˆ¤æ–­åŸå› ï¼ˆ1-2å¥è¯ï¼‰\",\n"
        "  \"dimension_coverage\": {{\n"
        "    \"ç©ºé—´è½½ä½“\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"äº§ä¸šé“¾\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"èº«ä»½å±æ€§\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"äººåŠ›èµ„æº\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"åˆè§„\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"ç¨æ”¶ä¸è´¢åŠ¡\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"äººæ‰æ¿€åŠ±\": {{\"status\": \"sufficient|insufficient|missing|not_applicable\", \"count\": 0, \"note\": \"...\"}}\n"
        "  }},\n"
        "  \"layer_coverage\": {{\n"
        "    \"åŸºç¡€å±‚\": {{\"status\": \"sufficient|insufficient|missing\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"å‘å±•å±‚\": {{\"status\": \"sufficient|insufficient|missing\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"äººæ‰å±‚\": {{\"status\": \"sufficient|insufficient|missing\", \"count\": 0, \"note\": \"...\"}},\n"
        "    \"è£èª‰å±‚\": {{\"status\": \"sufficient|insufficient|missing\", \"count\": 0, \"note\": \"...\"}}\n"
        "  }},\n"
        "  \"timeliness\": {{\n"
        "    \"status\": \"good|poor\",\n"
        "    \"current_year_count\": 0,\n"
        "    \"outdated_count\": 0,\n"
        "    \"note\": \"æ—¶æ•ˆæ€§è¯´æ˜ï¼ˆå½“å¹´æ”¿ç­–æ•°é‡ã€è¿‡æœŸæ”¿ç­–æ¯”ä¾‹ç­‰ï¼‰\"\n"
        "  }},\n"
        "  \"need_more_search\": true,\n"
        "  \"retry_tasks\": [\n"
        "    {{\n"
        "      \"dimension\": \"éœ€è¦è¡¥å……çš„ç»´åº¦\",\n"
        "      \"layer\": \"å¯¹åº”çš„ä¸šåŠ¡å±‚\",\n"
        "      \"search_term\": \"æ”¹è¿›åçš„æœç´¢è¯\",\n"
        "      \"reason\": \"ä¸ºä»€ä¹ˆéœ€è¦é‡æ–°æœç´¢\"\n"
        "    }}\n"
        "  ]\n"
        "}}\n"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Orchestrator ä¸»ç±»
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class Orchestrator:
    """
    AI æ™ºèƒ½è°ƒåº¦å™¨ï¼ˆå¸¦è¯„ä¼°åé¦ˆå›è·¯ï¼‰

    Args:
        on_log:       æ—¥å¿—å›è°ƒï¼ˆå¯é€‰ï¼Œç”¨äº SSE æ¨é€ï¼‰
        time_budget:  æ€»æ—¶é—´é¢„ç®—ï¼ˆç§’ï¼‰ï¼Œè¶…æ—¶åä¸å†å¯åŠ¨æ–°æœç´¢è½®æ¬¡
        max_rounds:   æœ€å¤§æœç´¢è½®æ¬¡ï¼ˆå«é¦–è½®ï¼‰
        request_delay: æ¯æ¬¡ web search è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å… 429
    """

    def __init__(
        self,
        on_log: Optional[Callable[[str], None]] = None,
        time_budget: float = 360.0,
        max_rounds: int = 3,
        request_delay: float = 2.0,
    ):
        self.on_log = on_log or (lambda msg: logger.info(msg))
        self.time_budget = time_budget
        self.max_rounds = max_rounds
        self.request_delay = request_delay
        self._client = None
        self._start_time: float = 0.0

    def _log(self, msg: str):
        self.on_log(msg)

    def _elapsed(self) -> float:
        """å·²ç”¨æ—¶é—´ï¼ˆç§’ï¼‰"""
        return round(time.time() - self._start_time, 1)

    def _time_remaining(self) -> float:
        """å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰"""
        return max(0, self.time_budget - (time.time() - self._start_time))

    def _is_timeout(self) -> bool:
        """æ˜¯å¦å·²è¶…æ—¶"""
        return time.time() - self._start_time >= self.time_budget

    def _ensure_client(self):
        """å»¶è¿Ÿåˆå§‹åŒ– Azure OpenAI å®¢æˆ·ç«¯"""
        if self._client is not None:
            return
        from openai import AzureOpenAI

        # å¤ç”¨ web_search_worker çš„é…ç½®
        project_endpoint = os.environ.get("AZURE_AI_PROJECT_ENDPOINT", "")
        from urllib.parse import urlparse
        parsed = urlparse(project_endpoint)
        endpoint = f"{parsed.scheme}://{parsed.netloc}" if project_endpoint else ""

        self._client = AzureOpenAI(
            api_key=os.environ.get("AZURE_AI_API_KEY", ""),
            api_version="2025-04-01-preview",
            azure_endpoint=endpoint,
        )

    def _ai_call(self, system_prompt: str, user_content: str) -> dict:
        """
        è°ƒç”¨ AIï¼ˆGPT-4oï¼‰è¿›è¡Œæ€è€ƒï¼Œè¿”å› JSON dictã€‚
        """
        self._ensure_client()
        model = os.environ.get("AZURE_AI_MODEL_DEPLOYMENT_NAME", "gpt-4o")

        response = self._client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            temperature=0.3,
            response_format={"type": "json_object"},
        )

        text = response.choices[0].message.content or "{}"
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            # å°è¯•æå– JSON å—
            import re
            m = re.search(r'\{[\s\S]*\}', text)
            if m:
                return json.loads(m.group())
            return {"error": "AI è¿”å›äº†é JSON å†…å®¹", "raw": text}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: AI æ‹†åˆ†ä»»åŠ¡
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ„å»º User Prompt
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _build_user_content(company_info: Dict[str, Any]) -> str:
        """
        ä» company_info æ„å»ºç»“æ„åŒ–çš„ user promptã€‚
        æ”¯æŒä¸°å¯Œå­—æ®µï¼ˆæ–¹æ¡ˆ Aï¼‰ï¼Œç¼ºå¤±å­—æ®µä¼˜é›…é™çº§ã€‚

        æ‰©å±•å­—æ®µæ¸…å•ï¼š
            name, industry, region, tags,
            address,              # æ³¨å†Œåœ°å€å…¨æ–‡ï¼ˆç©ºé—´è½½ä½“åˆ†æï¼‰
            business_scope,       # ç»è¥èŒƒå›´ï¼ˆäº§ä¸šé“¾åˆ†æï¼‰
            registered_capital,   # æ³¨å†Œèµ„æœ¬
            shareholders,         # [{"name": ..., "type": ..., "ratio": ...}]ï¼ˆèº«ä»½å±æ€§ï¼‰
            ip,                   # {"invention": 8, "utility": 20, "software": 5}ï¼ˆIPåˆ†çº§ï¼‰
            headcount_history,    # {"2023": 45, "2024": 82}ï¼ˆHRåŠ¨æ€ï¼‰
            employees,            # å‘˜å·¥è§„æ¨¡ï¼ˆç®€ç•¥ï¼‰
            founded,              # æˆç«‹æ—¶é—´
            risk_info,            # é£é™©ä¿¡æ¯æ–‡æœ¬ï¼ˆåˆè§„ç†”æ–­ï¼‰
        """
        # åŠ è½½ user prompt æ¨¡æ¿
        template = _load_prompt("expert_user_prompt.md")

        # â”€â”€ æ„å»ºå„å­—æ®µ â”€â”€
        name = company_info.get("name", "æœªçŸ¥")
        industry = company_info.get("industry", "æœªçŸ¥")
        region = company_info.get("region", "æœªçŸ¥")
        address = company_info.get("address", "æœªæä¾›")
        business_scope = company_info.get("business_scope", "æœªæä¾›")
        registered_capital = company_info.get("registered_capital", "æœªæä¾›")
        founded = company_info.get("founded", "æœªæä¾›")
        employees = company_info.get("employees", "æœªæä¾›")
        tags = ", ".join(company_info.get("tags", [])) or "æ— "
        risk_info = company_info.get("risk_info", "æœªæä¾›")

        # IP
        ip_data = company_info.get("ip", {})
        ip_invention = ip_data.get("invention", "æœªçŸ¥")
        ip_utility = ip_data.get("utility", "æœªçŸ¥")
        ip_software = ip_data.get("software", "æœªçŸ¥")

        # è‚¡ä¸œ
        shareholders = company_info.get("shareholders", [])
        if shareholders:
            sh_lines = []
            for sh in shareholders:
                sh_name = sh.get("name", "?")
                sh_type = sh.get("type", "?")
                sh_ratio = sh.get("ratio", "?")
                sh_lines.append(f"  - {sh_name}ï¼ˆ{sh_type}ï¼ŒæŒè‚¡ {sh_ratio}ï¼‰")
            shareholders_text = "\n".join(sh_lines)
        else:
            shareholders_text = "  æœªæä¾›"

        # å‚ä¿äººæ•°å†å²
        headcount = company_info.get("headcount_history", {})
        if headcount:
            hc_lines = [f"  - {year}å¹´ï¼š{count}äºº" for year, count in sorted(headcount.items())]
            headcount_text = "\n".join(hc_lines)
        else:
            headcount_text = "  æœªæä¾›"

        # å¦‚æœæœ‰æ¨¡æ¿æ–‡ä»¶ï¼Œç”¨æ¨¡æ¿ï¼›å¦åˆ™ç”¨è¡Œå†…æ ¼å¼
        if template:
            try:
                user_content = template.format(
                    name=name, industry=industry, region=region,
                    address=address, business_scope=business_scope,
                    registered_capital=registered_capital,
                    founded=founded, employees=employees, tags=tags,
                    risk_info=risk_info,
                    ip_invention=ip_invention, ip_utility=ip_utility, ip_software=ip_software,
                    shareholders_text=shareholders_text,
                    headcount_text=headcount_text,
                )
                # è¿½åŠ  Step 0 è¡¥å……ä¿¡æ¯
                extras = []
                actual_addr = company_info.get("actual_address", "")
                if actual_addr:
                    extras.append(f"- âš ï¸ å®é™…åŠå…¬åœ°å€ï¼š{actual_addr}ï¼ˆä¸æ³¨å†Œåœ°å€ä¸åŒï¼Œéœ€åŒæ—¶æœä¸¤ä¸ªåŒºçš„æ”¿ç­–ï¼‰")
                core_products = company_info.get("core_products", "")
                if core_products:
                    extras.append(f"- ğŸ”¬ æ ¸å¿ƒäº§å“/æŠ€æœ¯è·¯çº¿ï¼š{core_products}")
                certifications = company_info.get("certifications", [])
                if certifications:
                    extras.append(f"- ğŸ… å·²è·èµ„è´¨ï¼š{', '.join(certifications)}")
                founder_bg = company_info.get("founder_background", "")
                if founder_bg:
                    extras.append(f"- ğŸ‘¤ åˆ›å§‹äººèƒŒæ™¯ï¼š{founder_bg}")
                financing = company_info.get("financing_info", "")
                if financing:
                    extras.append(f"- ğŸ’° èèµ„ä¿¡æ¯ï¼š{financing}")
                findings = company_info.get("key_findings", "")
                if findings:
                    extras.append(f"- ğŸ’¡ è¡¥å……å‘ç°ï¼š{findings}")
                if extras:
                    user_content += "\n\n### Step 0 è¡¥å……ä¿¡æ¯ï¼ˆç½‘ç»œæœç´¢è·å–ï¼‰\n" + "\n".join(extras)
                return user_content
            except (KeyError, IndexError) as e:
                logger.warning(f"User prompt æ¨¡æ¿å¡«å……å¤±è´¥: {e}ï¼Œå›é€€åˆ°è¡Œå†…æ ¼å¼")

        # å›é€€ï¼šè¡Œå†…æ„å»º
        parts = [
            f"**ç›®æ ‡ä¼ä¸šæ•°æ®ï¼š**",
            f"- ä¼ä¸šåç§°ï¼š{name}",
            f"- è¡Œä¸šï¼š{industry}",
            f"- åœ°åŒºï¼š{region}",
            f"- æ³¨å†Œåœ°å€ï¼š{address}",
        ]
        # Step 0 è¡¥å……çš„å®é™…åœ°å€
        actual_addr = company_info.get("actual_address", "")
        if actual_addr:
            parts.append(f"- âš ï¸ å®é™…åŠå…¬åœ°å€ï¼š{actual_addr}ï¼ˆä¸æ³¨å†Œåœ°å€ä¸åŒï¼Œéœ€åŒæ—¶æœä¸¤ä¸ªåŒºçš„æ”¿ç­–ï¼‰")

        parts.extend([
            f"- ç»è¥èŒƒå›´ï¼š{business_scope}",
            f"- æ³¨å†Œèµ„æœ¬ï¼š{registered_capital}",
            f"- æˆç«‹æ—¶é—´ï¼š{founded}",
            f"- å‘˜å·¥è§„æ¨¡ï¼š{employees}",
            f"- ä¼ä¸šæ ‡ç­¾ï¼š{tags}",
            f"- çŸ¥è¯†äº§æƒï¼šå‘æ˜ä¸“åˆ© {ip_invention}ä»¶ï¼Œå®ç”¨æ–°å‹ {ip_utility}ä»¶ï¼Œè½¯è‘— {ip_software}ä»¶",
            f"- è‚¡ä¸œä¿¡æ¯ï¼š\n{shareholders_text}",
            f"- å‚ä¿äººæ•°å†å²ï¼š\n{headcount_text}",
            f"- é£é™©ä¿¡æ¯ï¼š{risk_info}",
        ])

        # Step 0 è¡¥å……çš„å…¶ä»–å­—æ®µ
        core_products = company_info.get("core_products", "")
        if core_products:
            parts.append(f"- ğŸ”¬ æ ¸å¿ƒäº§å“/æŠ€æœ¯è·¯çº¿ï¼š{core_products}")
        certifications = company_info.get("certifications", [])
        if certifications:
            parts.append(f"- ğŸ… å·²è·èµ„è´¨ï¼š{', '.join(certifications)}")
        founder_bg = company_info.get("founder_background", "")
        if founder_bg:
            parts.append(f"- ğŸ‘¤ åˆ›å§‹äººèƒŒæ™¯ï¼š{founder_bg}")
        financing = company_info.get("financing_info", "")
        if financing:
            parts.append(f"- ğŸ’° èèµ„ä¿¡æ¯ï¼š{financing}")
        findings = company_info.get("key_findings", "")
        if findings:
            parts.append(f"- ğŸ’¡ è¡¥å……å‘ç°ï¼š{findings}")

        parts.append(f"\nè¯·æ ¹æ®ä¸“å®¶è®¤çŸ¥æ¡†æ¶ï¼Œå¯¹è¯¥ä¼ä¸šè¿›è¡Œç‰¹å¾é€†å‘å·¥ç¨‹å¹¶ç”Ÿæˆæœç´¢ç­–ç•¥ã€‚")
        return "\n".join(parts)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 0: ä¼ä¸šä¿¡æ¯è¡¥å…¨ï¼ˆæœç´¢ä¼ä¸šæœ¬èº«ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _enrich_company_info(self, company_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        åœ¨æœæ”¿ç­–ä¹‹å‰ï¼Œå…ˆç”¨ 2 æ¬¡ web search æœä¼ä¸šæœ¬èº«ï¼Œè¡¥å…¨ä¼æŸ¥æŸ¥ç»™ä¸äº†çš„ä¿¡æ¯ï¼š
        - å®é™…åŠå…¬åœ°å€ï¼ˆå¯èƒ½â‰ æ³¨å†Œåœ°å€ï¼‰
        - æ ¸å¿ƒäº§å“/æŠ€æœ¯è·¯çº¿
        - å·²è·èµ„è´¨ï¼ˆé«˜ä¼/ä¸“ç²¾ç‰¹æ–°/ç§‘æŠ€å‹ä¸­å°ä¼ä¸šï¼‰
        - åˆ›å§‹äººèƒŒæ™¯ï¼ˆæµ·å½’/åšå£«/é™¢å£«ï¼‰
        - èèµ„è½®æ¬¡
        """
        name = company_info.get("name", "")
        if not name:
            return company_info

        self._log(f"\n{'â”€'*30}")
        self._log(f"ğŸ” Step 0: ä¼ä¸šä¿¡æ¯è¡¥å…¨ â€” {name}")
        self._log(f"{'â”€'*30}")

        from web_search_worker import WebSearchWorker
        worker = WebSearchWorker()

        search_queries = [
            f'"{name}" å®˜ç½‘ äº§å“ èèµ„ æŠ€æœ¯',
            f'"{name}" é«˜æ–°æŠ€æœ¯ ä¸“ç²¾ç‰¹æ–° è·å¥– è¡¥è´´ è®¤å®š',
        ]

        raw_texts = []
        for i, q in enumerate(search_queries, 1):
            if self._is_timeout():
                break
            self._log(f"   ğŸ” [{i}/{len(search_queries)}] æœç´¢ä¼ä¸šä¿¡æ¯: {q}")
            try:
                result = worker.search(q)
                for p in result.policies:
                    raw_texts.append(f"æ ‡é¢˜: {p.title}\næ‘˜è¦: {p.summary}\næ¥æº: {p.source}")
                if result.raw_answer:
                    raw_texts.append(result.raw_answer[:2000])
                self._log(f"   âœ… è·å–åˆ° {len(result.policies)} æ¡ä¿¡æ¯, è€—æ—¶ {result.duration}s")
            except Exception as e:
                self._log(f"   âš ï¸ æœç´¢å¤±è´¥: {e}")

            if i < len(search_queries) and self.request_delay > 0:
                time.sleep(self.request_delay)

        worker.close()

        if not raw_texts:
            self._log(f"   âš ï¸ æœªè·å–åˆ°ä¼ä¸šè¡¥å……ä¿¡æ¯ï¼Œè·³è¿‡è¡¥å…¨")
            return company_info

        # AI è§£æè¡¥å……ä¿¡æ¯
        self._log(f"   ğŸ§  AI è§£æä¼ä¸šè¡¥å……ä¿¡æ¯...")
        enrich_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¼ä¸šä¿¡æ¯åˆ†æä¸“å®¶ã€‚æ ¹æ®æœç´¢åˆ°çš„å…³äºè¯¥ä¼ä¸šçš„ä¿¡æ¯ï¼Œæå–ä»¥ä¸‹è¡¥å……æ•°æ®ã€‚\n"
            "åªæå–åœ¨æœç´¢ç»“æœä¸­æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä¸è¦æ¨æµ‹ã€‚æ²¡æœ‰ä¿¡æ¯çš„å­—æ®µå¡«nullã€‚\n\n"
            "è¾“å‡ºä¸¥æ ¼ JSONï¼š\n"
            "{\n"
            '  "actual_address": "å®é™…åŠå…¬/ç”Ÿäº§åœ°å€ï¼ˆå¦‚ä¸æ³¨å†Œåœ°å€ä¸åŒï¼‰",\n'
            '  "core_products": "æ ¸å¿ƒäº§å“æˆ–æŠ€æœ¯è·¯çº¿ï¼ˆå¦‚800Gå…‰æ¨¡å—ã€VCSELèŠ¯ç‰‡ç­‰ï¼‰",\n'
            '  "certifications": ["å·²è·èµ„è´¨åˆ—è¡¨ï¼Œå¦‚é«˜æ–°æŠ€æœ¯ä¼ä¸šã€ç§‘æŠ€å‹ä¸­å°ä¼ä¸šã€ä¸“ç²¾ç‰¹æ–°ç­‰"],\n'
            '  "founder_background": "åˆ›å§‹äºº/æ ¸å¿ƒå›¢é˜ŸèƒŒæ™¯ï¼ˆå¦‚æµ·å½’åšå£«ã€é™¢å£«ç­‰ï¼‰",\n'
            '  "financing_info": "èèµ„ä¿¡æ¯ï¼ˆå¦‚Bè½®ã€ä¼°å€¼ç­‰ï¼‰",\n'
            '  "key_findings": "å…¶ä»–å¯¹æ”¿ç­–åŒ¹é…æœ‰ä»·å€¼çš„å‘ç°ï¼ˆ1-2å¥è¯ï¼‰"\n'
            "}\n"
        )

        search_text = "\n\n---\n\n".join(raw_texts[:10])
        user_content = (
            f"ã€ä¼ä¸šåç§°ã€‘{name}\n"
            f"ã€æ³¨å†Œåœ°å€ã€‘{company_info.get('address', 'æœªçŸ¥')}\n"
            f"ã€è¡Œä¸šã€‘{company_info.get('industry', 'æœªçŸ¥')}\n\n"
            f"ã€æœç´¢åˆ°çš„ä¿¡æ¯ã€‘\n{search_text}"
        )

        try:
            enriched = self._ai_call(enrich_prompt, user_content)
            enriched_info = dict(company_info)

            actual_addr = enriched.get("actual_address")
            if actual_addr and actual_addr != "null" and actual_addr != company_info.get("address", ""):
                enriched_info["actual_address"] = actual_addr
                self._log(f"   ğŸ“ è¡¥å……å®é™…åœ°å€: {actual_addr}")

            core_products = enriched.get("core_products")
            if core_products and core_products != "null":
                enriched_info["core_products"] = core_products
                self._log(f"   ğŸ”¬ æ ¸å¿ƒäº§å“: {core_products}")

            certs = enriched.get("certifications", [])
            if certs and certs != [None] and certs != ["null"]:
                certs = [c for c in certs if c and c != "null"]
                if certs:
                    enriched_info["certifications"] = certs
                    self._log(f"   ğŸ… å·²è·èµ„è´¨: {', '.join(certs)}")

            founder = enriched.get("founder_background")
            if founder and founder != "null":
                enriched_info["founder_background"] = founder
                self._log(f"   ğŸ‘¤ åˆ›å§‹äºº: {founder}")

            financing = enriched.get("financing_info")
            if financing and financing != "null":
                enriched_info["financing_info"] = financing
                self._log(f"   ğŸ’° èèµ„: {financing}")

            findings = enriched.get("key_findings")
            if findings and findings != "null":
                enriched_info["key_findings"] = findings
                self._log(f"   ğŸ’¡ å‘ç°: {findings}")

            self._log(f"   âœ… ä¼ä¸šä¿¡æ¯è¡¥å…¨å®Œæˆ (è€—æ—¶ {self._elapsed()}s)")
            return enriched_info

        except Exception as e:
            self._log(f"   âš ï¸ AI è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹ä¿¡æ¯ç»§ç»­")
            return company_info

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: AI æ‹†åˆ†ä»»åŠ¡ï¼ˆä¸“å®¶ç‰¹å¾å·¥ç¨‹ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def plan(self, company_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        AI åˆ†æä¼ä¸šä¿¡æ¯ï¼ˆä¸“å®¶ç‰¹å¾å·¥ç¨‹ï¼‰ï¼Œç”Ÿæˆæœç´¢ä»»åŠ¡è®¡åˆ’ã€‚
        ä¸æ‰§è¡Œæœç´¢ï¼Œä»…è¿”å›ä»»åŠ¡åˆ—è¡¨ã€‚

        æ”¯æŒæ‰©å±•å­—æ®µï¼šaddress, business_scope, shareholders, ip,
                     headcount_history, risk_info ç­‰ã€‚
        ç¼ºå¤±å­—æ®µä¼šè‡ªåŠ¨è·³è¿‡å¯¹åº”ç»´åº¦åˆ†æã€‚

        Returns:
            {"feature_engineering": {...}, "analysis": "...", "tasks": [...], "compliance_veto": {...}}
        """
        self._log(f"ğŸ§  AI æ­£åœ¨åˆ†æä¼ä¸šä¿¡æ¯ï¼ˆä¸“å®¶ç‰¹å¾å·¥ç¨‹ï¼‰: {company_info.get('name', '?')}")

        system = _build_plan_system_prompt()
        user_content = self._build_user_content(company_info)

        plan = self._ai_call(system, user_content)

        # â”€â”€ åˆè§„ç†”æ–­æ£€æŸ¥ â”€â”€
        veto = plan.get("compliance_veto", {})
        if veto and not veto.get("passed", True):
            risk_level = veto.get("risk_level", "unknown")
            detail = veto.get("detail", "")
            self._log(f"ğŸš« åˆè§„ç†”æ–­è§¦å‘ï¼é£é™©ç­‰çº§: {risk_level}")
            self._log(f"   åŸå› : {detail}")
            if risk_level == "blocked":
                self._log(f"   â›” ä¼ä¸šå¤„äº'æ”¿ç­–ç»ç¼˜'çŠ¶æ€ï¼Œä»…æœç´¢ä¿¡ç”¨ä¿®å¤è·¯å¾„")

        # â”€â”€ ç‰¹å¾å·¥ç¨‹æ—¥å¿— â”€â”€
        fe = plan.get("feature_engineering", {})
        if fe:
            self._log(f"\nğŸ“ ç‰¹å¾é€†å‘å·¥ç¨‹ç»“æœ:")
            for dim, result in fe.items():
                dim_icon = {"spatial": "ğŸ“", "industry_chain": "ğŸ­", "identity": "ğŸ·ï¸",
                           "hr_dynamics": "ğŸ‘¥", "compliance": "âš–ï¸",
                           "tax_financial": "ğŸ“Š", "talent_incentive": "ğŸ†"}.get(dim, "ğŸ“Œ")
                self._log(f"   {dim_icon} {dim}: {result}")

        # â”€â”€ å·®è·åˆ†ææ—¥å¿— â”€â”€
        gap = plan.get("gap_analysis", {})
        if gap:
            self._log(f"\nğŸ“Š ç»´åº¦å·®è·åˆ†æ:")
            for dim, result in gap.items():
                self._log(f"   â†’ {dim}: {result}")

        # â”€â”€ æœç´¢ä»»åŠ¡æ—¥å¿— â”€â”€
        analysis = plan.get("analysis", "")
        tasks = plan.get("tasks", [])
        self._log(f"\nğŸ“‹ AI åˆ†æ: {analysis}")
        self._log(f"ğŸ“‹ ç”Ÿæˆ {len(tasks)} ä¸ªæœç´¢ä»»åŠ¡:")
        for i, t in enumerate(tasks, 1):
            priority_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(t.get("priority", ""), "âšª")
            dim = t.get("dimension", "?")
            layer = t.get("layer", "?")
            self._log(f"   {i}. [{dim}â†’{layer}] {priority_icon} {t.get('search_term', '?')}")
            self._log(f"      åŸå› : {t.get('reason', '')}")
            if t.get("focus_hints"):
                self._log(f"      ğŸ” å…³æ³¨: {t['focus_hints']}")

        return plan

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 2: æ‰§è¡Œ Web Search
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _run_web_searches(self, tasks: List[Dict]) -> List[WorkerResult]:
        """
        é€ä¸ªæ‰§è¡Œ web search ä»»åŠ¡ï¼Œæ”¶é›†ç»“æœã€‚
        æ”¯æŒè¯·æ±‚é—´éš”ï¼ˆé¿å… 429ï¼‰å’Œè¶…æ—¶æ£€æŸ¥ã€‚
        """
        from web_search_worker import WebSearchWorker

        worker = WebSearchWorker()
        results = []

        for i, task in enumerate(tasks, 1):
            # è¶…æ—¶æ£€æŸ¥
            if self._is_timeout():
                self._log(f"   â° æ—¶é—´é¢„ç®—ç”¨å°½ï¼ˆå·² {self._elapsed()}sï¼‰ï¼Œè·³è¿‡å‰©ä½™ {len(tasks)-i+1} ä¸ªä»»åŠ¡")
                break

            term = task.get("search_term", "")
            layer = task.get("layer", "?")
            remaining = round(self._time_remaining())
            self._log(f"ğŸ” [{i}/{len(tasks)}] Webæœç´¢ [{layer}]: {term}  (å‰©ä½™ {remaining}s)")

            try:
                result = worker.search(term)
                result.worker = f"web_search({layer})"
                results.append(result)
                self._log(f"   âœ… æ‰¾åˆ° {result.policy_count} æ¡æ”¿ç­–, è€—æ—¶ {result.duration}s")
            except Exception as e:
                self._log(f"   âŒ æœç´¢å¤±è´¥: {e}")
                results.append(WorkerResult(query=term, worker=f"web_search({layer})", error=str(e)))

            # è¯·æ±‚é—´éš”ï¼ˆé¿å… 429ï¼‰ï¼Œæœ€åä¸€ä¸ªä¸ç­‰
            if i < len(tasks) and self.request_delay > 0:
                time.sleep(self.request_delay)

        worker.close()
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: AI è¯„ä¼° â†’ æ˜¯å¦éœ€è¦ browse use
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _evaluate_results(self, all_policies: List[PolicyItem]) -> Dict[str, Any]:
        """
        AI è¯„ä¼°æœç´¢ç»“æœï¼Œå†³å®šå“ªäº›éœ€è¦ browse useã€‚
        """
        if not all_policies:
            return {"evaluation": "æ— æœç´¢ç»“æœ", "browse_targets": [], "skip_reasons": []}

        self._log(f"ğŸ§  AI æ­£åœ¨è¯„ä¼° {len(all_policies)} æ¡æœç´¢ç»“æœ...")

        # æ„å»ºè¯„ä¼°è¾“å…¥
        items_text = []
        for i, p in enumerate(all_policies, 1):
            items_text.append(
                f"{i}. æ ‡é¢˜: {p.title}\n"
                f"   URL: {p.url}\n"
                f"   æ‘˜è¦: {p.summary or 'æ— '}\n"
                f"   æ‰¶æŒ: {p.support or 'æ— '}\n"
                f"   æ¥æº: {p.source or 'æ— '}"
            )

        user_content = f"ä»¥ä¸‹æ˜¯ web search è¿”å›çš„æ”¿ç­–æ¡ç›®ï¼Œè¯·è¯„ä¼°å“ªäº›éœ€è¦ç”¨æµè§ˆå™¨æ·±åº¦æŠ“å–ï¼š\n\n" + "\n\n".join(items_text)

        evaluation = self._ai_call(EVALUATE_SYSTEM_PROMPT, user_content)

        targets = evaluation.get("browse_targets", [])
        self._log(f"ğŸ“‹ è¯„ä¼°å®Œæˆ: {evaluation.get('evaluation', '')}")
        self._log(f"   éœ€è¦æ·±åº¦æŠ“å–: {len(targets)} æ¡")
        for t in targets:
            self._log(f"   â†’ {t.get('title', '?')} ({t.get('reason', '')})")

        return evaluation

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 6: AI æ‰“åˆ†æ’åº + æœ‰æ•ˆæœŸ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _score_policies(self, company_info: Dict[str, Any], policies: List[PolicyItem]) -> List[PolicyItem]:
        """
        AI ä¸ºæ¯æ¡æ”¿ç­–æ‰“åˆ†ï¼ˆç›¸å…³åº¦ï¼‰å¹¶è¡¥å……æœ‰æ•ˆæœŸï¼ŒæŒ‰åˆ†æ•°æ’åºã€‚
        """
        if not policies:
            return policies

        self._log(f"\n{'â”€'*30}")
        self._log(f"ğŸ“Š AI æ‰“åˆ†æ’åºï¼ˆ{len(policies)} æ¡æ”¿ç­–ï¼‰")
        self._log(f"{'â”€'*30}")

        # æ„å»ºè¾“å…¥
        items_text = []
        for i, p in enumerate(policies, 1):
            items_text.append(
                f"{i}. [{p.layer or '?'}] {p.title}\n"
                f"   æ‘˜è¦: {(p.summary or '')[:100]}\n"
                f"   æ‰¶æŒ: {p.support or 'æ— '}\n"
                f"   å‘å¸ƒæ—¥æœŸ: {p.date or 'æœªçŸ¥'}\n"
                f"   æœ‰æ•ˆæœŸ: {p.validity or 'æœªçŸ¥'}\n"
                f"   ç”³æŠ¥æˆªæ­¢: {p.application_deadline or 'æœªçŸ¥'}"
            )

        user_content = (
            f"ã€ä¼ä¸šä¿¡æ¯ã€‘\n"
            f"åç§°: {company_info.get('name', '?')}\n"
            f"è¡Œä¸š: {company_info.get('industry', '?')}\n"
            f"åœ°åŒº: {company_info.get('region', '?')}\n"
            f"æ ‡ç­¾: {', '.join(company_info.get('tags', []))}\n\n"
            f"ã€å¾…è¯„åˆ†æ”¿ç­–ï¼ˆ{len(policies)} æ¡ï¼‰ã€‘\n" + "\n\n".join(items_text)
        )

        try:
            result = self._ai_call(_build_scoring_system_prompt(), user_content)
            scored = result.get("scored_policies", [])

            for item in scored:
                idx = item.get("index", 0) - 1
                if 0 <= idx < len(policies):
                    policies[idx].relevance = item.get("relevance", 0)
                    policies[idx].score_amount = item.get("score_amount", 0)
                    policies[idx].score_exclusivity = item.get("score_exclusivity", 0)
                    policies[idx].score_feasibility = item.get("score_feasibility", 0)
                    policies[idx].score_urgency = item.get("score_urgency", 0)
                    policies[idx].score_sustainability = item.get("score_sustainability", 0)
                    policies[idx].score_reason = item.get("reason", "")
                    policies[idx].validity = item.get("validity", "")
                    policies[idx].amount = item.get("amount", "")
                    policies[idx].amount_level = item.get("amount_level", "")

            # æŒ‰ç»¼åˆåˆ†æ’åºï¼ˆé«˜â†’ä½ï¼‰
            policies.sort(key=lambda p: p.relevance, reverse=True)

            # æ—¥å¿— â€” æ˜¾ç¤º5ç»´åº¦è¯„åˆ†
            for p in policies:
                score_bar = "â–ˆ" * (p.relevance // 10) + "â–‘" * (10 - p.relevance // 10)
                lvl = p.amount_level or '?'
                self._log(
                    f"   {p.relevance:3d}åˆ† {score_bar} [{p.layer or '?'}] {p.title[:30]}  "
                    f"ğŸ’°{lvl}:{p.amount or '?'}  ğŸ“…{p.validity or '?'}  "
                    f"[ğŸ’°{p.score_amount} ğŸ¯{p.score_exclusivity} âœ…{p.score_feasibility} â°{p.score_urgency} ğŸ”„{p.score_sustainability}]"
                )

        except Exception as e:
            self._log(f"   âš ï¸ æ‰“åˆ†å¤±è´¥ï¼ˆä¸å½±å“ç»“æœï¼‰: {e}")

        return policies

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3b: å›è·¯è¯„ä¼° â€” åˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……æœç´¢
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _review_round(
        self,
        company_info: Dict[str, Any],
        round_num: int,
        all_policies: List[PolicyItem],
        search_history: List[str],
        feature_engineering: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        AI è¯„å®¡å½“å‰è½®æ¬¡çš„æœç´¢ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……æœç´¢ã€‚
        ä½¿ç”¨äº”ç»´åº¦+å››å±‚åŒé‡è¯„ä¼°ã€‚

        Args:
            company_info:        ä¼ä¸šä¿¡æ¯
            round_num:           å½“å‰è½®æ¬¡
            all_policies:        å·²æ”¶é›†åˆ°çš„æ‰€æœ‰æ”¿ç­–
            search_history:      å·²ä½¿ç”¨è¿‡çš„æœç´¢è¯
            feature_engineering: plan() é˜¶æ®µçš„ç‰¹å¾å·¥ç¨‹ç»“æœï¼ˆå¯é€‰ï¼‰

        Returns:
            {"overall_quality": "good|fair|poor", "need_more_search": bool, "retry_tasks": [...]}
        """
        self._log(f"\nğŸ”„ ç¬¬ {round_num} è½®è¯„å®¡ï¼ˆå·²æœ‰ {len(all_policies)} æ¡æ”¿ç­–ï¼Œå·²ç”¨ {self._elapsed()}sï¼‰")

        # æŒ‰ layer ç»Ÿè®¡ç»“æœæ•°
        layer_counts: Dict[str, int] = {}
        for p in all_policies:
            worker = getattr(p, 'layer', '') or ''
            if worker:
                layer_counts[worker] = layer_counts.get(worker, 0) + 1

        system = _build_round_review_system_prompt()

        # æ„å»ºå·²æœ‰ç»“æœæ‘˜è¦ï¼ˆå«æ—¥æœŸå’Œæœ‰æ•ˆæœŸï¼‰
        results_summary = []
        for i, p in enumerate(all_policies, 1):
            date_info = p.date or 'æ—¥æœŸæœªçŸ¥'
            validity_info = f" | æœ‰æ•ˆæœŸ:{p.validity}" if p.validity else ""
            deadline_info = f" | ç”³æŠ¥æˆªæ­¢:{p.application_deadline}" if p.application_deadline else ""
            support_info = p.support or (p.summary[:50] if p.summary else 'æ— æ‘˜è¦')
            results_summary.append(f"{i}. [{getattr(p, 'layer', '?')}] {p.title} â€” {date_info}{validity_info}{deadline_info} â€” {support_info}")

        # ä½¿ç”¨ä¸°å¯Œçš„ä¼ä¸šä¿¡æ¯ï¼ˆä¸ plan é˜¶æ®µä¸€è‡´ï¼‰
        enterprise_summary = self._build_user_content(company_info)

        user_content = (
            f"ã€ä¼ä¸šç‰¹å¾åˆ†æã€‘\n{enterprise_summary}\n\n"
        )

        # é™„åŠ  plan é˜¶æ®µçš„ç‰¹å¾å·¥ç¨‹ç»“æœ
        if feature_engineering:
            user_content += (
                f"ã€ç‰¹å¾å·¥ç¨‹ç»“æœï¼ˆæ¥è‡ª plan é˜¶æ®µï¼‰ã€‘\n"
                f"{json.dumps(feature_engineering, ensure_ascii=False, indent=2)}\n\n"
            )

        user_content += (
            f"ã€å½“å‰æ—¥æœŸã€‘{datetime.now().strftime('%Y-%m-%d')}\n"
            f"ã€å½“å‰è½®æ¬¡ã€‘ç¬¬ {round_num} è½®\n"
            f"ã€æ—¶é—´å‰©ä½™ã€‘{round(self._time_remaining())}s\n"
            f"ã€å·²ç”¨æœç´¢è¯ã€‘\n" + "\n".join(f"  - {s}" for s in search_history) + "\n\n"
            f"ã€å·²æœåˆ°çš„æ”¿ç­–ï¼ˆ{len(all_policies)} æ¡ï¼‰ã€‘\n" + "\n".join(results_summary) + "\n\n"
            f"è¯·è¯„å®¡æœç´¢è´¨é‡ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……æœç´¢ã€‚å¦‚æœæ—¶é—´ä¸è¶³30ç§’ï¼Œè¯·è®¾ç½® need_more_search=falseã€‚"
        )

        review = self._ai_call(system, user_content)

        quality = review.get("overall_quality", "?")
        quality_icon = {"good": "ğŸŸ¢", "fair": "ğŸŸ¡", "poor": "ğŸ”´"}.get(quality, "âšª")
        self._log(f"   {quality_icon} è´¨é‡: {quality} â€” {review.get('quality_reason', '')}")

        # æ‰“å°ç»´åº¦è¦†ç›–æƒ…å†µ
        dim_cov = review.get("dimension_coverage", {})
        if dim_cov:
            self._log(f"   â”€â”€ ç»´åº¦è¦†ç›– â”€â”€")
            for dim, info in dim_cov.items():
                status = info.get("status", "?")
                s_icon = {"sufficient": "âœ…", "insufficient": "âš ï¸", "missing": "âŒ", "not_applicable": "â–"}.get(status, "?")
                self._log(f"   {s_icon} {dim}: {status} ({info.get('count', '?')}æ¡) {info.get('note', '')}")

        # æ‰“å°å„å±‚è¦†ç›–æƒ…å†µ
        layer_cov = review.get("layer_coverage", {})
        for layer, info in layer_cov.items():
            status = info.get("status", "?")
            s_icon = {"sufficient": "âœ…", "insufficient": "âš ï¸", "missing": "âŒ"}.get(status, "?")
            self._log(f"   {s_icon} {layer}: {status} ({info.get('count', '?')}æ¡) {info.get('note', '')}")

        # æ‰“å°æ—¶æ•ˆæ€§è¯„ä¼°
        timeliness = review.get("timeliness", {})
        if timeliness:
            t_status = timeliness.get("status", "?")
            t_icon = {"good": "âœ…", "poor": "âš ï¸"}.get(t_status, "?")
            self._log(f"   {t_icon} æ—¶æ•ˆæ€§: {t_status} (å½“å¹´{timeliness.get('current_year_count', '?')}æ¡, è¿‡æœŸ{timeliness.get('outdated_count', '?')}æ¡) {timeliness.get('note', '')}")

        need_more = review.get("need_more_search", False)
        retry_tasks = review.get("retry_tasks", [])
        if need_more and retry_tasks:
            self._log(f"   ğŸ”„ éœ€è¦è¡¥å……æœç´¢ {len(retry_tasks)} ä¸ªä»»åŠ¡:")
            for t in retry_tasks:
                dim = t.get("dimension", "?")
                layer = t.get("layer", "?")
                self._log(f"      â†’ [{dim}â†’{layer}] {t.get('search_term', '?')} ({t.get('reason', '')})")
        else:
            self._log(f"   âœ… æœç´¢è´¨é‡{'' if quality == 'good' else 'åŸºæœ¬'}æ»¡è¶³è¦æ±‚ï¼Œä¸å†è¡¥å……")

        return review

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: Browse Use æ·±åº¦æŠ“å–
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _run_browse_use(self, targets: List[Dict]) -> List[PolicyItem]:
        """
        å¯¹éœ€è¦æ·±åº¦æŠ“å–çš„ç›®æ ‡æ‰§è¡Œ browse useã€‚
        """
        if not targets:
            return []

        from browser_use_worker import BrowserUseWorker
        worker = BrowserUseWorker()
        results = []

        for i, target in enumerate(targets, 1):
            url = target.get("url", "")
            title = target.get("title", "?")
            self._log(f"ğŸŒ [{i}/{len(targets)}] Browse Use æ·±åº¦æŠ“å–: {title}")

            try:
                task = (
                    f"è¯·è®¿é—®ä»¥ä¸‹URLå¹¶æå–å®Œæ•´çš„æ”¿ç­–ä¿¡æ¯ï¼š\n"
                    f"URL: {url}\n"
                    f"æ ‡é¢˜: {title}\n\n"
                    f"æå–ï¼šæ”¿ç­–å…¨æ–‡æ‘˜è¦ã€æ‰¶æŒé‡‘é¢/æ¯”ä¾‹ã€ç”³æŠ¥æ¡ä»¶ã€æˆªæ­¢æ—¥æœŸã€PDFä¸‹è½½é“¾æ¥ã€‚"
                )
                result = worker.search(task)
                results.extend(result.policies)
                self._log(f"   âœ… æå–åˆ° {result.policy_count} æ¡è¯¦ç»†æ”¿ç­–")
            except Exception as e:
                self._log(f"   âŒ æ·±åº¦æŠ“å–å¤±è´¥: {e}")

        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: å»é‡
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def deduplicate(policies: List[PolicyItem]) -> List[PolicyItem]:
        """
        å»é‡é€»è¾‘ï¼šæŒ‰ (æ ‡é¢˜, URL) å»é‡ï¼Œä¿ç•™ä¿¡æ¯æ›´å®Œæ•´çš„ç‰ˆæœ¬ã€‚
        """
        seen: Dict[str, PolicyItem] = {}  # key â†’ PolicyItem

        for p in policies:
            title = p.title.strip()
            url = p.url.strip().rstrip("/")
            key = f"{title}||{url}"

            if key in seen:
                # ä¿ç•™æ‘˜è¦æ›´é•¿çš„ç‰ˆæœ¬
                existing = seen[key]
                if len(p.summary or "") > len(existing.summary or ""):
                    seen[key] = p
                # è¡¥å……ç¼ºå¤±å­—æ®µ
                if p.pdf_url and not existing.pdf_url:
                    seen[key].pdf_url = p.pdf_url
                if p.support and not existing.support:
                    seen[key].support = p.support
                if p.full_text and not existing.full_text:
                    seen[key].full_text = p.full_text
            else:
                seen[key] = p

        return list(seen.values())

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸»æµç¨‹
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def run(self, company_info: Dict[str, Any], skip_browse_use: bool = False) -> WorkerResult:
        """
        å®Œæ•´æ‰§è¡Œ orchestrator æµç¨‹ï¼ˆå¸¦è¯„ä¼°åé¦ˆå›è·¯ï¼‰ã€‚

        æµç¨‹ï¼š
            Round 1: AIæ‹†åˆ† â†’ Web Search â†’ AIè¯„å®¡
            Round 2: (å¦‚éœ€) AI ç»™å‡ºè¡¥å……æœç´¢è¯ â†’ Web Search â†’ AIè¯„å®¡
            Round N: ... ç›´åˆ°è´¨é‡ good æˆ–è¶…æ—¶/è½®æ¬¡ç”¨å°½
            æœ€å:    AI è¯„ä¼° browse use â†’ æ‰§è¡Œ(å¯é€‰) â†’ åˆå¹¶å»é‡

        Args:
            company_info:    ä¼æŸ¥æŸ¥ä¼ä¸šä¿¡æ¯
            skip_browse_use: è·³è¿‡ browse useï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰

        Returns:
            WorkerResultï¼ˆåˆå¹¶åçš„æœ€ç»ˆç»“æœï¼‰
        """
        self._start_time = time.time()
        company_name = company_info.get("name", "æœªçŸ¥ä¼ä¸š")

        self._log(f"{'='*50}")
        self._log(f"ğŸš€ Orchestrator å¯åŠ¨: {company_name}")
        self._log(f"   æ—¶é—´é¢„ç®—: {self.time_budget}s | æœ€å¤§è½®æ¬¡: {self.max_rounds} | è¯·æ±‚é—´éš”: {self.request_delay}s")
        self._log(f"{'='*50}")

        # â”€â”€ Step 0: ä¼ä¸šä¿¡æ¯è¡¥å…¨ â”€â”€
        enriched_info = self._enrich_company_info(company_info)

        # â”€â”€ Step 1: AI æ‹†åˆ†ä»»åŠ¡ï¼ˆä¸“å®¶ç‰¹å¾å·¥ç¨‹ï¼‰ â”€â”€
        plan = self.plan(enriched_info)
        tasks = plan.get("tasks", [])

        # ä¿å­˜ç‰¹å¾å·¥ç¨‹ç»“æœï¼Œä¾›å›è·¯è¯„ä¼°ä½¿ç”¨
        feature_engineering = plan.get("feature_engineering", {})

        # â”€â”€ åˆè§„ç†”æ–­æ£€æŸ¥ â”€â”€
        veto = plan.get("compliance_veto", {})
        if veto and not veto.get("passed", True) and veto.get("risk_level") == "blocked":
            self._log("â›” ä¼ä¸šå¤„äºæ”¿ç­–ç»ç¼˜çŠ¶æ€ï¼Œä»…ä¿ç•™ä¿¡ç”¨ä¿®å¤ç›¸å…³æœç´¢ä»»åŠ¡")
            # åªä¿ç•™åˆè§„ç»´åº¦çš„ä»»åŠ¡
            tasks = [t for t in tasks if t.get("dimension") == "åˆè§„"]
            if not tasks:
                return WorkerResult(
                    query=company_name,
                    error="ä¼ä¸šå­˜åœ¨ä¸¥é‡å¤±ä¿¡è®°å½•ï¼Œæš‚æ— æ³•åŒ¹é…æ”¿ç­–ã€‚å»ºè®®å…ˆè¿›è¡Œä¿¡ç”¨ä¿®å¤ã€‚",
                    worker="orchestrator",
                    duration=round(time.time() - self._start_time, 1),
                )

        if not tasks:
            self._log("âš ï¸ AI æœªç”Ÿæˆä»»ä½•æœç´¢ä»»åŠ¡")
            return WorkerResult(query=company_name, error="AI æœªç”Ÿæˆæœç´¢ä»»åŠ¡")

        # â”€â”€ æœç´¢å›è·¯ â”€â”€
        all_policies: List[PolicyItem] = []
        all_sources: List[str] = []
        total_tokens: Dict[str, int] = {}
        search_history: List[str] = []
        round_num = 0

        current_tasks = tasks
        while round_num < self.max_rounds:
            round_num += 1

            # è¶…æ—¶æ£€æŸ¥
            if self._is_timeout():
                self._log(f"\nâ° æ—¶é—´é¢„ç®—ç”¨å°½ï¼ˆ{self._elapsed()}sï¼‰ï¼Œåœæ­¢æœç´¢")
                break

            self._log(f"\n{'â”€'*30}")
            self._log(f"ğŸ“¡ ç¬¬ {round_num} è½® Web Searchï¼ˆ{len(current_tasks)} ä¸ªä»»åŠ¡ï¼Œå·²ç”¨ {self._elapsed()}sï¼‰")
            self._log(f"{'â”€'*30}")

            # æ‰§è¡Œ Web Search
            loop = asyncio.get_event_loop()
            web_results = await loop.run_in_executor(None, self._run_web_searches, current_tasks)

            # æ±‡æ€»æœ¬è½®ç»“æœ
            round_policies = []
            for r in web_results:
                # ç»™æ¯æ¡ policy æ‰“ä¸Š layer æ ‡è®°
                layer_tag = r.worker.replace("web_search(", "").rstrip(")")
                for p in r.policies:
                    p.layer = layer_tag
                round_policies.extend(r.policies)
                all_sources.extend(r.sources)
                if r.token_usage:
                    for k, v in r.token_usage.items():
                        total_tokens[k] = total_tokens.get(k, 0) + v

            # è®°å½•æœç´¢è¯
            for t in current_tasks:
                search_history.append(t.get("search_term", ""))

            all_policies.extend(round_policies)
            self._log(f"\nğŸ“Š ç¬¬ {round_num} è½®: +{len(round_policies)} æ¡, ç´¯è®¡ {len(all_policies)} æ¡ (å·²ç”¨ {self._elapsed()}s)")

            # æœ€åä¸€è½®ä¸è¯„å®¡
            if round_num >= self.max_rounds:
                self._log(f"\nğŸ›‘ å·²è¾¾æœ€å¤§è½®æ¬¡ ({self.max_rounds})ï¼Œç»“æŸæœç´¢")
                break

            # è¶…æ—¶æ£€æŸ¥ï¼ˆè¯„å®¡ä¹Ÿéœ€è¦æ—¶é—´ï¼‰
            if self._time_remaining() < 45:
                self._log(f"\nâ° å‰©ä½™æ—¶é—´ä¸è¶³45sï¼Œè·³è¿‡è¯„å®¡")
                break

            # â”€â”€ AI è¯„å®¡å›è·¯ â”€â”€
            review = self._review_round(company_info, round_num, all_policies, search_history, feature_engineering)

            if not review.get("need_more_search", False):
                self._log(f"\nâœ… æœç´¢è´¨é‡è¾¾æ ‡ï¼Œç»“æŸæœç´¢å›è·¯")
                break

            # å‡†å¤‡ä¸‹ä¸€è½®ä»»åŠ¡
            retry_tasks = review.get("retry_tasks", [])
            if not retry_tasks:
                self._log(f"\nâœ… æ— è¡¥å……ä»»åŠ¡ï¼Œç»“æŸæœç´¢å›è·¯")
                break

            # å»æ‰å·²æœè¿‡çš„è¯
            new_tasks = [t for t in retry_tasks if t.get("search_term", "") not in search_history]
            if not new_tasks:
                self._log(f"\nâœ… è¡¥å……æœç´¢è¯éƒ½å·²æœè¿‡ï¼Œç»“æŸæœç´¢å›è·¯")
                break

            current_tasks = new_tasks

        # â”€â”€ Step 3: AI è¯„ä¼°æ˜¯å¦éœ€è¦ browse use â”€â”€
        browse_policies = []
        if not skip_browse_use and all_policies:
            if self._time_remaining() > 90:  # browse use è‡³å°‘éœ€è¦ 90s
                self._log(f"\n{'â”€'*30}")
                self._log(f"ğŸ§  AI è¯„ä¼°æœç´¢è´¨é‡ï¼ˆæ˜¯å¦éœ€è¦ Browse Useï¼‰")
                self._log(f"{'â”€'*30}")

                evaluation = self._evaluate_results(all_policies)
                targets = evaluation.get("browse_targets", [])

                if targets and self._time_remaining() > 90:
                    self._log(f"\n{'â”€'*30}")
                    self._log(f"ğŸŒ Browse Use æ·±åº¦æŠ“å–ï¼ˆ{len(targets)} ä¸ªç›®æ ‡ï¼‰")
                    self._log(f"{'â”€'*30}")
                    browse_policies = await self._run_browse_use(targets)
                elif targets:
                    self._log(f"\nâ° å‰©ä½™æ—¶é—´ä¸è¶³90sï¼Œè·³è¿‡ Browse Useï¼ˆéœ€æ·±åº¦æŠ“å– {len(targets)} æ¡ï¼‰")
            else:
                self._log(f"\nâ° å‰©ä½™æ—¶é—´ä¸è¶³90sï¼Œè·³è¿‡ Browse Use è¯„ä¼°")
        elif skip_browse_use:
            self._log("\nâ­ï¸ è·³è¿‡ Browse Useï¼ˆskip_browse_use=Trueï¼‰")

        # â”€â”€ Step 5: åˆå¹¶ + å»é‡ â”€â”€
        self._log(f"\n{'â”€'*30}")
        self._log(f"ğŸ”— åˆå¹¶ä¸å»é‡")
        self._log(f"{'â”€'*30}")

        combined = all_policies + browse_policies
        final = self.deduplicate(combined)
        self._log(f"   åˆå¹¶å‰: {len(combined)} æ¡ â†’ å»é‡å: {len(final)} æ¡")

        # â”€â”€ Step 6: AI æ‰“åˆ†æ’åº + æœ‰æ•ˆæœŸ â”€â”€
        if final and not self._is_timeout():
            final = self._score_policies(company_info, final)

        elapsed = round(time.time() - self._start_time, 1)

        # æ„å»ºæœ€ç»ˆç»“æœ
        result = WorkerResult(
            query=f"{company_name} æ”¿ç­–æœç´¢",
            policies=final,
            sources=list(set(all_sources)),
            worker="orchestrator",
            duration=elapsed,
            token_usage=total_tokens,
        )

        self._log(f"\n{'='*50}")
        self._log(f"âœ… Orchestrator å®Œæˆ!")
        self._log(f"   ä¼ä¸š: {company_name}")
        self._log(f"   æ”¿ç­–: {result.policy_count} æ¡")
        self._log(f"   è½®æ¬¡: {round_num}")
        self._log(f"   è€—æ—¶: {elapsed}s")
        self._log(f"{'='*50}")

        return result
