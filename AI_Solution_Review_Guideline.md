# AI 项目 Solution Review Guideline

> 适用于 AI 交付团队在项目启动前对 Solution 方案进行系统性评审，确保方案完整性、可行性和风险可控。

---

## 一、Solution 文档必备章节清单（Checklist）

每份 Solution 文档提交评审前，必须包含以下章节，缺失项需标注原因：

| # | 章节 | 必须 | 备注 |
|---|------|:----:|------|
| 1 | 项目概述 & 业务目标 | ✅ | |
| 2 | AI 项目类型分类 | ✅ | |
| 3 | Scope 界定（In/Out） | ✅ | |
| 4 | 技术方案 & 架构设计 | ✅ | |
| 5 | 数据需求与准备 | ✅ | |
| 6 | 模型/算法选型 | ✅ | 非模型类项目可豁免 |
| 7 | 工作量评估（WBS） | ✅ | |
| 8 | 工作时长评估 & 里程碑 | ✅ | |
| 9 | 团队配置 & 外包划分 | ✅ | |
| 10 | Assumptions | ✅ | |
| 11 | Dependencies | ✅ | |
| 12 | 风险评估 & 缓解方案 | ✅ | |
| 13 | 验收标准（DoD） | ✅ | |
| 14 | 成本估算 | ✅ | |

---

## 二、AI 项目类型分类

评审时首先确认项目属于哪种类型，不同类型关注点不同：

| 类型 | 典型场景 | 重点关注 |
|------|---------|---------|
| **A. NLP / LLM 应用** | 智能客服、文档摘要、RAG、Agent | Prompt 工程复杂度、模型选型、Token 成本、幻觉控制 |
| **B. 计算机视觉** | OCR、目标检测、图像分类 | 数据标注量、GPU 资源、模型精度 baseline |
| **C. 推荐/搜索系统** | 商品推荐、内容排序 | 数据管线、A/B 测试、冷启动策略 |
| **D. 数据平台/MLOps** | 特征平台、模型监控、Pipeline | 基础设施依赖、与现有系统集成 |
| **E. RPA + AI** | 流程自动化 + 智能决策 | 规则引擎 vs 模型边界、异常处理 |
| **F. GenAI 应用** | Copilot、代码生成、多模态 | API 成本、安全合规、输出质量控制 |
| **G. 传统 ML** | 风控模型、预测模型 | 特征工程、模型可解释性、数据质量 |

---

## 三、Scope 界定（In Scope / Out of Scope）

### 3.1 评审要点

- [ ] In Scope 是否与客户签署的 SOW / 合同条款一致
- [ ] Out of Scope 是否**明确列出**客户可能期望但不包含的功能
- [ ] 是否有灰色地带未界定（常见争议点需提前标注）
- [ ] 是否区分了 MVP / Phase 1 与后续阶段的边界
- [ ] 是否明确了"AI 能力边界"——即模型无法 100% 解决的场景如何处理

### 3.2 常见需要明确 Out of Scope 的项

| 类别 | 常见 Out of Scope 示例 |
|------|----------------------|
| 数据 | 历史数据清洗、数据标注、数据采集爬虫 |
| 基础设施 | 客户侧 GPU 采购、网络环境搭建、VPN 配置 |
| 集成 | 与第三方系统的深度对接（非 API 层面） |
| 运维 | 上线后持续运维、模型持续迭代 |
| 合规 | 数据合规审查、隐私评估（DPIA） |
| 培训 | 客户团队技术培训、知识转移（除非明确包含） |

---

## 四、工作量评估（WBS）

### 4.1 评审标准

- [ ] 是否按 **WBS（Work Breakdown Structure）** 分解到可执行粒度
- [ ] 每个工作包是否有明确的 **交付物（Deliverable）**
- [ ] 估算单位是否统一（人天 / 人时 / Story Point）
- [ ] 是否包含了 **Buffer / Contingency**（建议 AI 项目 15%-30%）
- [ ] 是否区分了**确定性工作**和**探索性工作（Spike）**

### 4.2 AI 项目 WBS 标准阶段模板

```
1. 需求分析 & 方案设计
   1.1 业务需求梳理
   1.2 数据可行性评估
   1.3 技术方案设计
   1.4 方案评审 & 确认

2. 数据工程
   2.1 数据获取 & 接入
   2.2 数据清洗 & 预处理
   2.3 数据标注（如适用）
   2.4 数据质量验证
   2.5 特征工程（如适用）

3. 模型/算法开发
   3.1 Baseline 模型搭建
   3.2 模型训练 & 调优
   3.3 Prompt Engineering（LLM 项目）
   3.4 模型评估 & 验证
   3.5 模型性能优化

4. 应用开发 & 集成
   4.1 API / 服务开发
   4.2 前端/UI 开发（如适用）
   4.3 系统集成
   4.4 端到端测试

5. 部署 & 上线
   5.1 环境配置
   5.2 部署 & 灰度发布
   5.3 性能测试 & 压测
   5.4 上线验证

6. 项目管理 & 沟通
   6.1 日常项目管理
   6.2 客户沟通 & 汇报
   6.3 文档 & 知识转移
```

### 4.3 工作量估算注意事项（AI 特有）

| 阶段 | 常见低估的工作 | 建议加权 |
|------|--------------|---------|
| 数据工程 | 数据质量差导致的额外清洗、客户数据延迟交付 | ×1.5 - ×2.0 |
| 模型开发 | 调优迭代次数不确定、精度达标困难 | ×1.3 - ×2.0 |
| Prompt 工程 | 边界 case 多、多轮优化 | ×1.5 |
| 集成联调 | 客户系统接口不规范、环境差异 | ×1.5 |
| 部署 | 客户环境限制（断网、低配、安全审批） | ×1.3 - ×1.8 |

---

## 五、工作时长评估 & 里程碑

### 5.1 评审要点

- [ ] 总工期是否合理（参考历史项目基准）
- [ ] 关键路径（Critical Path）是否识别
- [ ] 里程碑是否有明确的 **日期 + 交付物 + 验收标准**
- [ ] 是否考虑了客户侧响应时间（Review、确认、数据提供）
- [ ] 是否预留了节假日、团队成员请假等非工作日
- [ ] 并行工作流是否合理（资源是否冲突）

### 5.2 里程碑模板

| 里程碑 | 预计日期 | 交付物 | 验收标准 | 依赖 |
|--------|---------|--------|---------|------|
| M0: 项目启动 | YYYY-MM-DD | Kickoff 会议纪要 | 双方确认 | 合同签署 |
| M1: 方案确认 | YYYY-MM-DD | 技术方案文档 | 客户签字确认 | 需求澄清完成 |
| M2: 数据就绪 | YYYY-MM-DD | 数据集 + 质量报告 | 数据满足建模要求 | 客户提供数据 |
| M3: 模型 Baseline | YYYY-MM-DD | 基线模型 + 评估报告 | 达到约定最低指标 | 数据就绪 |
| M4: 集成完成 | YYYY-MM-DD | 集成测试报告 | 端到端流程跑通 | API 对接完成 |
| M5: UAT | YYYY-MM-DD | UAT 测试报告 | 客户确认通过 | 集成完成 |
| M6: 上线 & 验收 | YYYY-MM-DD | 上线确认书、项目总结 | 合同验收标准全部满足 | UAT 通过 |

---

## 六、团队配置 & 外包划分

### 6.1 评审要点

- [ ] 角色分工是否覆盖所有 WBS 工作包
- [ ] 核心岗位是否由内部团队承担
- [ ] 外包范围是否明确且可管控
- [ ] 是否有 **backup 人员** 安排

### 6.2 内部 vs 外包划分原则

| 工作类型 | 建议归属 | 原因 |
|---------|---------|------|
| 方案设计 & 架构 | **内部** | 核心能力，需要深度理解业务 |
| 算法研发 & 调优 | **内部** | 核心竞争力，IP 保护 |
| Prompt Engineering | **内部** | 需要持续迭代，经验积累 |
| 数据标注 | **可外包** | 劳动密集型，质量可控 |
| 前端 UI 开发 | **可外包** | 标准化程度高 |
| 基础 API 开发 | **可外包** | 有明确接口规范即可 |
| 数据清洗 & ETL | **可外包**（需质检） | 明确规则后可标准化 |
| 测试（功能/性能） | **可外包** | 有测试用例即可执行 |
| 部署 & DevOps | **视情况** | 涉及客户环境则需内部；标准部署可外包 |
| 项目管理 | **内部** | 客户关系管理，无法替代 |

### 6.3 外包管理检查项

- [ ] 外包交付物是否有明确的验收标准
- [ ] 数据安全协议（NDA）是否签署
- [ ] 外包沟通机制是否建立（周期、频率、工具）
- [ ] 外包质量 Review 流程是否设计
- [ ] 外包工作的知识产权归属是否明确

---

## 七、Assumptions（假设条件）

### 7.1 评审要点

- [ ] 假设条件是否全面、合理
- [ ] 每条假设是否有对应的 **风险**（如假设不成立时的影响）
- [ ] 假设是否已与客户沟通确认（或计划确认）

### 7.2 AI 项目常见 Assumptions 模板

**客户侧：**
- 客户在项目启动后 X 个工作日内提供所需数据
- 客户提供的数据质量满足基本要求（完整性 > X%，准确性 > X%）
- 客户指定 1 名业务对接人，每周至少 X 次沟通会议
- 客户现有系统提供标准 API 接口用于集成
- 客户环境满足部署最低要求（GPU / CPU / 内存 / 存储）
- 客户在每个里程碑的 Review 反馈时间不超过 X 个工作日

**技术侧：**
- 所选模型/框架在项目周期内保持稳定版本
- 第三方 API（如 OpenAI、Claude）服务可用性 > 99.5%
- 模型精度可在 X 轮迭代内达到目标指标
- 训练数据量 >= X 条可满足模型训练要求
- 项目期间不涉及大规模架构重构

**商务侧：**
- 报价基于当前 Scope，Scope 变更需走 Change Request 流程
- 云资源/API 调用费用由客户承担（或：已包含在报价中）
- 项目按固定价格交付（或：按 T&M 计费）

---

## 八、Dependencies（依赖项）

### 8.1 评审要点

- [ ] 所有外部依赖是否识别并标注负责方
- [ ] 关键依赖是否有 **Plan B**
- [ ] 依赖项的时间窗口是否与项目计划对齐

### 8.2 依赖项分类模板

| 依赖类型 | 依赖项 | 提供方 | 需要日期 | 当前状态 | Plan B |
|---------|--------|--------|---------|---------|--------|
| **数据** | 历史业务数据 | 客户 | M0+5d | 待确认 | 使用公开数据集做 POC |
| **数据** | 数据标注完成 | 外包供应商 | M1+10d | 未开始 | 内部标注小批量 |
| **环境** | GPU 服务器就绪 | 客户 IT | M0+3d | 已申请 | 使用云 GPU 临时过渡 |
| **环境** | VPN 账号开通 | 客户 IT | M0+2d | 未开始 | 现场开发 |
| **接口** | 业务系统 API 文档 | 客户研发 | M1 | 部分提供 | 先 Mock 接口开发 |
| **审批** | 数据合规审批 | 客户法务 | M0+10d | 未开始 | 使用脱敏数据 |
| **第三方** | LLM API Key & 额度 | OpenAI/Azure | M0 | 已就绪 | 备选模型 |
| **人员** | 算法工程师到岗 | 内部 | M0 | 已确认 | 借调其他项目组 |

---

## 九、风险评估 & 缓解方案

### 9.1 评审要点

- [ ] 是否覆盖技术、数据、人员、商务各维度风险
- [ ] 每个风险是否有 **概率 × 影响** 评级
- [ ] 高级别风险是否有具体的缓解措施和负责人
- [ ] 是否识别了 AI 项目特有风险

### 9.2 AI 项目典型风险矩阵

| # | 风险描述 | 概率 | 影响 | 级别 | 缓解措施 | 负责人 |
|---|---------|:----:|:----:|:----:|---------|--------|
| R1 | 模型精度无法达到客户期望 | 高 | 高 | 🔴 | 事先约定量化指标 & 阶梯式验收标准；预留调优 buffer | 算法 Lead |
| R2 | 客户数据质量差 / 延迟提供 | 高 | 高 | 🔴 | 首周做数据采样评估；合同约定数据提供时间节点 | PM |
| R3 | 需求蔓延（Scope Creep） | 中 | 高 | 🟡 | 严格 Change Request 流程；每阶段确认 Scope | PM |
| R4 | 第三方 API 费用超预算 | 中 | 中 | 🟡 | 事前做 Token 用量估算；设置费用告警 | 架构师 |
| R5 | 关键人员离职/调岗 | 低 | 高 | 🟡 | 关键岗位 AB 角备份；文档化制度 | PM |
| R6 | 模型安全问题（幻觉、有害输出）| 中 | 高 | 🟡 | 输出过滤 & 人工审核机制；测试覆盖边界 case | 算法 Lead |
| R7 | 客户环境部署困难 | 中 | 中 | 🟡 | 提前获取环境信息；容器化交付 | DevOps |
| R8 | LLM 模型版本升级导致行为变化 | 中 | 中 | 🟡 | 锁定模型版本；建立回归测试集 | 算法 Lead |
| R9 | 数据隐私合规问题 | 低 | 高 | 🟡 | 提前做合规评估；数据脱敏处理 | PM + 法务 |
| R10 | 项目工期不足 | 中 | 高 | 🟡 | 预留 15-30% buffer；分阶段交付降低风险 | PM |

### 9.3 风险评级标准

```
概率：高(>60%) / 中(30-60%) / 低(<30%)
影响：高(项目失败或严重延期) / 中(部分目标无法达成) / 低(可接受的偏差)

🔴 红色 = 高概率×高影响 → 必须有具体缓解计划，需 escalation
🟡 黄色 = 中高风险 → 需有缓解方案，定期跟踪
🟢 绿色 = 低风险 → 记录观察即可
```

---

## 十、验收标准（Definition of Done）

### 10.1 评审要点

- [ ] 验收标准是否**量化、可测量**
- [ ] 是否与客户确认过验收标准（避免上线后争议）
- [ ] AI 指标是否设置了合理范围（非 100%）
- [ ] 是否区分了 **功能验收** 和 **性能验收**

### 10.2 AI 项目常用验收指标

| 类型 | 指标 | 示例要求 |
|------|------|---------|
| **模型效果** | 准确率 / Precision / Recall / F1 | F1 >= 0.85（在测试集上） |
| **模型效果** | 幻觉率（LLM） | 关键事实错误率 < 5% |
| **性能** | 响应时间（Latency） | P95 < 2s |
| **性能** | 吞吐量（QPS） | >= 100 QPS |
| **可用性** | 系统可用性 | >= 99.5% |
| **功能** | 功能覆盖率 | Scope 内功能 100% 实现 |
| **文档** | 交付文档完整性 | 技术文档、用户手册、运维手册 |
| **安全** | 安全测试通过 | 无高危漏洞 |

---

## 十一、成本估算

### 11.1 评审要点

- [ ] 人力成本是否与 WBS 工时一致
- [ ] 云资源 / API 调用成本是否估算
- [ ] 是否区分了一次性成本和持续性成本
- [ ] 利润率是否满足公司要求
- [ ] 外包成本是否包含管理成本

### 11.2 成本构成模板

| 成本项 | 一次性 | 月度持续 | 承担方 | 备注 |
|--------|:------:|:--------:|:------:|------|
| 内部人力 | ¥XXX | - | 我方 | 基于 WBS 工时 |
| 外包费用 | ¥XXX | - | 我方 | 数据标注 + 前端 |
| 云服务器（GPU） | - | ¥XXX | 客户 | 训练期间 |
| LLM API 调用 | - | ¥XXX | 客户 | 按实际用量 |
| 软件许可 | ¥XXX | ¥XXX | 视情况 | 如标注工具 |
| 差旅费用 | ¥XXX | - | 我方 | 驻场期间 |
| Contingency (15%) | ¥XXX | - | 我方 | 风险储备 |

---

## 十二、Solution Review 会议流程

### 12.1 参会角色

| 角色 | 职责 |
|------|------|
| **Solution 负责人** | 方案讲解、回答问题 |
| **技术评审人**（≥2人） | 评估技术方案可行性、架构合理性 |
| **PM / 交付经理** | 评估工期、成本、风险可控性 |
| **业务/售前** | 确认 Scope 与客户期望一致 |
| **BP/财务**（可选） | 验证成本估算合理性 |

### 12.2 评审流程

```
1. 【会前准备】Solution 文档提前 2 个工作日发给所有评审人
2. 【方案宣讲】30-45 min —— Solution 负责人讲解方案
3. 【逐项评审】45-60 min —— 按 Checklist 逐项 Review
4. 【评审结论】三种结论：
   ✅ 通过 —— 可以进入交付
   🔄 有条件通过 —— 需补充 X 项内容后再次确认
   ❌ 不通过 —— 需重大修改后重新评审
5. 【会后跟踪】会议纪要 + Action Items 24h 内输出
```

### 12.3 评审评分表（可选量化）

| 评审维度 | 权重 | 评分(1-5) | 加权分 | 评审意见 |
|---------|:----:|:---------:|:------:|---------|
| Scope 清晰度 | 15% | | | |
| 技术方案可行性 | 20% | | | |
| 工作量估算合理性 | 15% | | | |
| 风险识别完整性 | 15% | | | |
| 依赖管理 | 10% | | | |
| 验收标准明确性 | 10% | | | |
| 成本估算合理性 | 10% | | | |
| 团队配置合理性 | 5% | | | |
| **总分** | **100%** | | | |

> 通过标准：总分 ≥ 3.5 且无单项 ≤ 2

---

## 十三、附录：不同 AI 项目类型的 Review 侧重点

### A. LLM / RAG / Agent 类项目

- [ ] Prompt 策略是否设计（System Prompt、Few-shot、CoT）
- [ ] RAG 的知识库构建方案是否明确（Chunking 策略、Embedding 模型、向量库选型）
- [ ] Token 成本是否估算（输入/输出 Token 数 × 单价 × 预估调用量）
- [ ] 幻觉控制策略是否设计
- [ ] 模型降级方案（如 GPT-4 降级到 GPT-3.5）
- [ ] 内容安全过滤机制

### B. 计算机视觉类项目

- [ ] 数据标注方案（工具、标注规范、质检流程）
- [ ] 训练数据量是否充足
- [ ] GPU 资源需求是否明确
- [ ] 模型推理部署方案（边缘端 or 云端）
- [ ] 模型压缩 / 加速方案（如适用）

### C. 推荐/搜索类项目

- [ ] 数据管线设计（实时/离线）
- [ ] 冷启动方案
- [ ] A/B 测试方案
- [ ] 特征工程方案
- [ ] 效果评估指标体系

### D. MLOps / 平台类项目

- [ ] 与现有基础设施的兼容性
- [ ] 权限 & 多租户设计
- [ ] 监控告警方案
- [ ] CI/CD Pipeline 设计
- [ ] 模型版本管理方案

---

## 十四、文档模板 & 工具

| 用途 | 推荐工具/模板 |
|------|-------------|
| WBS & 甘特图 | MS Project / Monday.com / 飞书多维表格 |
| 架构图 | Draw.io / Excalidraw / PlantUML |
| 风险矩阵 | Excel / Notion 数据库 |
| 成本估算 | Excel 标准模板 |
| 评审记录 | Confluence / 飞书文档 |
| 项目管理 | Jira / 飞书项目 / Azure DevOps |

---

## 版本记录

| 版本 | 日期 | 修改内容 | 作者 |
|------|------|---------|------|
| v1.0 | 2026-02-14 | 初始版本 | AI 交付团队 |

---

> **使用说明：** 本 Guideline 为 AI 交付团队 Solution Review 的标准框架。各项目可根据实际情况裁剪或扩展，但裁剪项需在评审会上说明原因。建议每半年根据项目经验回顾更新一次。
