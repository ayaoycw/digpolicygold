# 踩坑记录

> 项目开发过程中踩过的坑，避免重复犯错

---

## 坑 1：在低配阿里云上跑 browser-use 本地 Chrome — OOM 致死

**日期**：2026-02-12  
**严重程度**：🔴 致命 — 导致服务器 SSH 完全无法连接

### 服务器配置

| 项目 | 值 |
|------|------|
| CPU | 2 核 |
| 内存 | 3.4GB + 4GB Swap |
| 实例 | 阿里云 ECS（低配） |

### 现象

1. browser-use 启动 headless Chrome 搜索百度/gov.cn 政策
2. 搜索开始后，服务器内存迅速从 84%（2942MB / 3499MB）飙升到 100%
3. **SSH 完全无法连接**（`Connection timed out during banner exchange`）
4. HTTP 服务（FastAPI uvicorn）偶尔还能响应，但极慢
5. 前端 SSE 日志只收到 "Page readiness timeout (4.0s)" 后就卡死
6. 搜索质量极差 — Chrome 连百度首页都加载超时

### 内存分析

| 组件 | 估算内存占用 |
|------|------|
| 系统 + nginx + Python 基础 | ~800MB |
| Chrome headless（1个tab） | 300-500MB |
| Playwright runtime | ~100MB |
| `use_vision=True`（截图+图像处理） | 200-400MB |
| LLM API 调用的请求/响应缓存 | ~100MB |
| **总计** | **1500-1900MB** |
| **可用** | **~550MB** |
| **缺口** | **~1000-1400MB** |

### 根本原因

**3.5GB RAM 跑不动 browser-use + Chrome + 视觉模式。**

- Chrome 本身就是内存大户，一个 tab 轻松吃 300-500MB
- `use_vision=True` 每步截图再发给 LLM，额外消耗 200-400MB
- 百度首页广告/追踪脚本多，加载慢，Chrome 渲染内存持续增长
- Linux 进入 swap thrashing，所有进程都极慢，SSH daemon 也无法分配内存响应

### 尝试过的（无效的）缓解措施

| 措施 | 效果 |
|------|------|
| 添加 4GB swap | 有一定帮助但 swap thrashing 太慢 |
| `use_vision=False` | 理论省 200-400MB，但总量仍不够 |
| 每次启动新 Chrome（非 host 模式） | 启动开销大，但运行时内存一样高 |
| `--disable-gpu`, `--no-sandbox` | 省不了多少 |

### 正确方案

| 方案 | 推荐度 | 说明 |
|------|------|------|
| **browser-use Cloud** | ⭐⭐⭐⭐⭐ | Chrome 跑在他们服务器上，阿里云只跑 Python。`use_cloud=True` 即可 |
| 升级服务器到 8GB+ RAM | ⭐⭐⭐⭐ | 根本解，但月费增加 |
| 第三方 CDP 服务（Browserbase 等） | ⭐⭐⭐ | 传入 `cdp_url` 即可，任何 CDP 提供商都行 |
| 在本地开发机跑 Chrome，远程 CDP 转发 | ⭐⭐ | 临时方案，依赖本地机器在线 |

### 关键教训

> **永远不要在 < 4GB RAM 的机器上跑 headless Chrome + LLM agent。**  
> browser-use 的 Cloud 模式（`use_cloud=True`）是低配服务器的唯一可行方案。

---

## 坑 2：browser-use `use_vision=True` 的截图吃 token 和内存

**日期**：2026-02-12

### 现象

- 开启 `use_vision=True` 后，每步都截图发送给 LLM
- 即使 `vision_detail_level="low"`，每张截图仍占用 LLM token
- 在低内存机器上更是雪上加霜

### 教训

> 除非确实需要看到页面（如验证码识别），否则默认 `use_vision=False`。  
> 大部分政策搜索任务靠 DOM 提取就够了。

---

## 坑 3：browser-use `auto_download_pdfs=True` 导致 DownloadsWatchdog 超时

**日期**：2026-02-12

### 现象

- 设置 `auto_download_pdfs=True` 后，agent 访问 PDF 链接时触发下载
- `DownloadsWatchdog` 等待下载完成，但在慢速网络下超时
- 整个 agent 卡在下载步骤，浪费步数

### 解决

```python
auto_download_pdfs=False  # agent 可以直接 navigate 到 PDF URL 读取内容
```

---

## 坑 4：browser-use `use_judge=True` 污染 JSON 输出

**日期**：2026-02-12

### 现象

- `use_judge=True` 时，judge 会在 `final_result` 后面**追加** verdict 文本
- 导致返回的 JSON 变成 `{"policies": [...]}The task is complete...`
- Pydantic `model_validate_json()` 解析失败

### 解决

```python
use_judge=False  # 关掉 judge
```

加上 `_clean_final_result()` 函数，找到匹配的 `{}` 后截断尾部垃圾文本。

---

## 坑 5：PowerShell 的 `$` 变量会污染 SSH 命令

**日期**：2026-02-12

### 现象

- 在 PowerShell 中执行 `ssh aliyun-dev "echo PID=$(pgrep -f server.py)"`
- PowerShell 把 `$(pgrep ...)` 当成自己的变量替换
- SSH 收到的命令已经被 PowerShell 篡改

### 解决

用 scp 上传脚本文件到服务器，再 ssh 执行脚本，不依赖 PowerShell 直接传复杂命令。

---

## 坑 6：nginx `sed` 注入配置被 PowerShell 变量替换破坏

**日期**：2026-02-12

### 现象

- 用 `ssh aliyun-dev "sed -i '...$host...' /etc/nginx/..."` 修改 nginx 配置
- PowerShell 把 `$host`、`$remote_addr` 等 nginx 变量替换成空字符串
- nginx 配置变成 `proxy_set_header Host System.Management.Automation...`

### 解决

在本地创建完整配置文件，用 `scp` 上传，再 SSH 执行 `cp` + `nginx -t` + `reload`。

---

## 坑 7：browser-use 搜索词过长导致百度无结果

**日期**：2026-02-12

### 现象

- 前端传入的 `industry` 是 "光通信设备制造"（从 mock 企查查数据取的完整行业分类）
- 搜索词变成 "上海 浦东新区 光通信设备制造 产业扶持政策 2025 site:gov.cn"
- 太长太具体，百度搜索结果极少

### 教训

> 传给 browser-use 的搜索词要**精炼**。  
> "光通信设备制造" → "光通信"，前端或 server.py 做关键词提取。
