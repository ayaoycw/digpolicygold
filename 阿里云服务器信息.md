# 阿里云 Browser-Use 部署 — 完整指南

> **最后更新**：2026-02-12  
> **用途**：供所有 Copilot 聊天窗口 / Agent 作为上下文参考，了解服务器现状和操作方法

---

## 1. SSH 连接信息

| 项目 | 值 |
|---|---|
| **服务器 IP** | 120.26.87.185 |
| **用户名** | root |
| **SSH 别名** | aliyun-dev（已在 `~/.ssh/config` 配置） |
| **密钥路径** | ~/.ssh/id_rsa |

```bash
# 快速连接
ssh aliyun-dev
# 或直接
ssh root@120.26.87.185
```

---

## 2. 服务器环境（2026-02-12 诊断）

| 项目 | 值 |
|---|---|
| **操作系统** | Ubuntu 24.04.3 LTS (Noble Numbat) |
| **CPU** | 2 核 |
| **内存** | 3.4GB 总计 + **4GB Swap**（已添加 2026-02-12） |
| **磁盘** | 40GB，已用 18GB (46%) |
| **Docker** | v29.2.1 + Compose v5.0.2 |
| **Python (venv)** | 3.12.3（`/opt/web-ui/.venv/`） |
| **Playwright** | 1.58.0 |

---

## 3. 项目部署现状

### 当前运行方式：裸机 venv（非 Docker）

WebUI 直接用 venv + xvfb-run 在宿主机运行，**不是** Docker 容器。

| 项目 | 值 |
|---|---|
| **项目路径** | `/opt/web-ui/` |
| **虚拟环境** | `/opt/web-ui/.venv/` (Python 3.12.3) |
| **启动命令** | `xvfb-run --auto-servernum python -u webui.py --ip 0.0.0.0 --port 7788` |
| **日志文件** | `/tmp/webui.log` |
| **配置文件** | `/opt/web-ui/.env` |
| **PID 示例** | webui.py = 23223, Xvfb = 23220, Playwright node = 26129 |

### 端口状态

| 端口 | 用途 | 状态 |
|---|---|---|
| **7788** | Gradio WebUI | ✅ 运行中 |
| **6080** | noVNC | ❌ 未运行（裸机模式无 noVNC） |
| **5901** | VNC | ❌ 未运行 |
| **9222** | Chrome DevTools | ❌ 未运行 |
| **8501** | Streamlit (policy-mvp 另一项目) | ✅ 运行中 |

### LLM 配置

| 项目 | 值 |
|---|---|
| **DEFAULT_LLM** | `azure_openai` |
| **Azure Endpoint** | `https://forbrowseuse-resource.cognitiveservices.azure.com/` |
| **API Version** | `2024-12-01-preview`（已从 `2024-05-01-preview` 修正，o3 模型要求） |
| **API Key** | 已配置在 `/opt/web-ui/.env` |
| **网络连通性** | ✅ HTTP 200，~1s 响应 |

### Docker 构建状态：⚠️ 部分修复

- **noVNC 问题**：✅ 已修复 — 注释掉 `git clone ghgo.xyz`，改为 `mkdir -p /opt/novnc`
- **Playwright Chromium 下载**：✅ 已修复 — npmmirror 没有最新版本 (404)，改为跳过下载 + apt 安装 `chromium`
- **当前构建**：未完成完整验证（构建时间较长，等待中）
- **已有镜像**：仅 `python:3.11-slim-bookworm` (198MB)

#### Dockerfile 修改记录
1. 注释掉 `git clone https://ghgo.xyz/...noVNC` → `RUN mkdir -p /opt/novnc`
2. apt-get 添加 `chromium` 包
3. `ENV PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1` + `ENV CHROME_PATH=/usr/bin/chromium`
4. 注释掉 `PLAYWRIGHT_BROWSERS_PATH`、`PLAYWRIGHT_DOWNLOAD_HOST`、`playwright install chromium`

---

## 4. 网络环境

| 目标 | 可达性 | 备注 |
|---|---|---|
| Azure OpenAI | ✅ HTTP 200 ~1s | 主要 LLM 服务 |
| 阿里云 PyPI 镜像 | ✅ HTTP 200 ~2s | pip 安装 |
| Docker Hub | ❌ 超时 | 依赖镜像加速器 |
| GitHub (直连) | ❌ 不通 | ghgo.xyz 代理也挂了 |
| 百度/搜狗 | ✅ | agent 搜索正常 |

### Docker 镜像加速器（已配置）
文件：`/etc/docker/daemon.json`
```json
{
  "registry-mirrors": [
    "https://docker.1ms.run",
    "https://docker.xuanyuan.me"
  ]
}
```

---

## 5. 已知问题

### 问题 1：Docker 构建失败 — ⚠️ 部分修复
- **noVNC**：✅ 注释掉 `git clone ghgo.xyz`，改为 `mkdir -p /opt/novnc`
- **Playwright Chromium 下载失败（中国网络）**：✅ 已绕过
  - **根因**：Playwright 1.50+ 改用 Chrome for Testing (CFT) 下载路径 `builds/cft/{browserVersion}/`，`cdn.playwright.dev` 302 跳转到被墙的 `storage.googleapis.com`；npmmirror 的 `builds/cft/` 目录为空，`PLAYWRIGHT_DOWNLOAD_HOST` 设为 npmmirror 也无效
  - **当前绕过**：`PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1` + apt 安装系统 `chromium`（有版本不匹配风险）
  - **根本解决方案**：`playwright install chrome`（从 `dl.google.com` 下载 Google Chrome deb 包，中国可达）+ 代码中用 `channel='chrome'`
- 构建未完整验证（可选，裸机已能运行）

### 问题 2：内存不足风险 ✅ 已解决
- 3.4GB 内存原无 Swap，WebUI 进程占 ~566MB
- **已修复**：添加 4GB Swap 文件，总可用 7.4GB
- 已写入 `/etc/fstab`，重启后自动挂载

### 问题 3：VNC 不可用（裸机模式）
- 裸机模式只有 Xvfb 虚拟屏幕，无法远程观看 agent 操作
- **修复方向**：安装 x11vnc + noVNC 或依赖 Docker 部署

### 问题 4：中文乱码 ✅ 无问题
- SDK 测试通过：百度搜索"今天北京天气" → 正确返回中文天气信息，零乱码
- 日志中中文输出正常（如 "聿凡领光通信有限公司"、"北京今天天气：晴"）
- Python 编码 UTF-8，locale en_US.UTF-8
- Dockerfile 已配置 CJK 字体
- **WebUI 界面中文**：需用户手动验证

### 问题 5：集成方式 — ✅ 决定直接使用 SDK
- **原计划**：创建独立 REST API 服务 `api_server.py` (FastAPI)
- **新决定 (2026-02-12)**：不再封装独立 API，改为在应用中**直接 `import browser_use` SDK**
- **理由**：
  - 应用是 Python，可以直接调用 SDK，无需 HTTP 中间层
  - 省去管理两个服务的复杂度（启动/重启/监控）
  - 节省内存（3.4GB 服务器不需要跑两个进程）
  - 零网络延迟（函数调用 vs HTTP）
- **`api_server.py` 状态**：已废弃，不再部署（文件保留作参考）

---

## 6. 常用操作命令

### 查看 WebUI 状态
```bash
ssh aliyun-dev "ps aux | grep webui | grep -v grep"
```

### 查看 WebUI 日志
```bash
# 最新 50 行
ssh aliyun-dev "tail -50 /tmp/webui.log"
# 实时跟踪
ssh aliyun-dev "tail -f /tmp/webui.log"
```

### 停止 WebUI
```bash
ssh aliyun-dev "pkill -f 'webui.py'; pkill -f xvfb-run; echo 'stopped'"
```

### 启动 WebUI
```bash
ssh aliyun-dev "cd /opt/web-ui && source .venv/bin/activate && nohup xvfb-run --auto-servernum python -u webui.py --ip 0.0.0.0 --port 7788 > /tmp/webui.log 2>&1 & echo started"
```

### 重启 WebUI
```bash
ssh aliyun-dev "pkill -f 'webui.py'; pkill -f xvfb-run; sleep 2; cd /opt/web-ui && source .venv/bin/activate && nohup xvfb-run --auto-servernum python -u webui.py --ip 0.0.0.0 --port 7788 > /tmp/webui.log 2>&1 & echo restarted"
```

### Docker 操作（需先修复 Dockerfile）
```bash
# 查看 Docker 状态
ssh aliyun-dev "docker ps -a && docker images"
# 重新构建
ssh aliyun-dev "cd /opt/web-ui && docker compose build --no-cache && docker compose up -d"
```

### 上传文件到服务器
```bash
# 上传单个文件
scp "C:\Users\chuiwenyao\Desktop\vibe Code\browse use on cursor\web-ui\<文件名>" aliyun-dev:/opt/web-ui/<目标路径>
# 上传目录
scp -r "C:\Users\chuiwenyao\Desktop\vibe Code\browse use on cursor\web-ui\src" aliyun-dev:/opt/web-ui/src
```

### 服务器资源监控
```bash
ssh aliyun-dev "free -h && echo '' && df -h / && echo '' && uptime"
```

---

## 7. Troubleshooting 推荐工作流

### 方法 A：VS Code Remote-SSH（首选）

让 VS Code 直接连到服务器，像本地开发一样操作。

1. VS Code 安装 **Remote - SSH** 扩展
2. `Ctrl+Shift+P` → `Remote-SSH: Connect to Host...` → 输入 `aliyun-dev`
3. 打开远程文件夹 `/opt/web-ui/`
4. 编辑、终端、调试、Copilot 全部在远程运行
5. 端口转发自动生效：`localhost:7788` 即可访问 WebUI

**优势**：不需要 scp，Copilot 直接读远程文件

### 方法 B：本地 SSH 命令（当前使用）

在本地 PowerShell 中 `ssh aliyun-dev "命令"` 操作。适合快速检查。

### 方法 C：Copilot Agent 模式

在 Copilot Chat 中让 AI 通过 `run_in_terminal` 执行 `ssh` 命令操作服务器。
- 可读取远程文件、运行诊断、修改后上传
- 适合不熟悉命令行的用户

---

## 8. 项目整体目标与计划

### 最终目标
在 Python 应用中**直接调用 browser-use SDK**，实现：任务描述 → browser-use 执行 → 返回结构化结果。应用与 browser-use 跑在同一进程中，部署在阿里云 ECS 上。

### 集成方式决策（2026-02-12）

| 方案 | 说明 | 结论 |
|---|---|---|
| ~~独立 REST API~~ | ~~FastAPI 封装 browser-use，HTTP 调用~~ | ❌ 已放弃 — 多一层无必要 |
| **直接用 SDK** | 应用中 `import browser_use`，函数调用 | ✅ **采用** |
| 官方 Cloud | `@sandbox()` + Browser Use Cloud 付费 | ❌ 不用 — 自建部署 |

### 分阶段计划

| 阶段 | 内容 | 状态 |
|---|---|---|
| **1. 诊断现状** | SSH 连接、环境检查、问题定位 | ✅ 完成 |
| **2a. 添加 Swap** | 创建 4GB Swap 文件防 OOM | ✅ 完成 (2026-02-12) |
| **2b. 修复 Docker** | Dockerfile 修复 noVNC + Playwright（可选） | ✅ 已修改 Dockerfile，待完整构建验证 |
| **3. 中文乱码** | 验证 WebUI 中文、修复编码问题 | ✅ SDK 测试无乱码 (2026-02-12) |
| **3b. API 版本** | o3 模型需要 `2024-12-01-preview` | ✅ 已修正 .env (2026-02-12) |
| ~~**4. REST API**~~ | ~~创建 FastAPI 服务 `api_server.py`~~ | ❌ 已放弃 (2026-02-12)，改用 SDK 直接集成 |
| **4. 升级 SDK** | 升级 browser-use 到 0.11.x，适配新 API | ⬜ 待做 |
| **5. 构建应用** | Python 应用中直接 `import browser_use`，调用 SDK | ⬜ 待做 |
| **6. 部署应用** | systemd 管理、Xvfb、生产配置 | ⬜ 待做 |
| **7. 生产加固** | 并发控制、超时、内存保护、监控 | ⬜ 待做 |

### 执行记录

#### 2026-02-12：添加 4GB Swap ✅
```bash
ssh aliyun-dev "fallocate -l 4G /swapfile && chmod 600 /swapfile && mkswap /swapfile && swapon /swapfile && echo '/swapfile none swap sw 0 0' >> /etc/fstab"
```
- **之前**：内存 3.4GB / Swap 0B → OOM 风险高
- **之后**：内存 3.4GB / Swap 4.0GB → 总可用 7.4GB
- 已写入 `/etc/fstab`，重启后自动挂载

#### 2026-02-12：修复 Docker 构建 — Dockerfile 修改 ✅
**问题 A：noVNC git clone 失败 (exit code 128)**
- 原因：`ghgo.xyz` GitHub 代理不通
- 修复：另一个 AI 已将 `git clone ghgo.xyz/...` 注释掉，改为 `RUN mkdir -p /opt/novnc`

**问题 B：Playwright Chromium 下载失败（中国网络）**
- **根因（源码级分析）**：Playwright 1.50+ 在 `registry/index.ts` 中使用 `cftUrl()` 函数，x64 Linux Chromium 下载路径从 `builds/chromium/{revision}/` 变为 `builds/cft/{browserVersion}/`
  - `cdn.playwright.dev/builds/cft/` → 302 跳转到 `storage.googleapis.com/chrome-for-testing-public/`（中国被墙）
  - npmmirror 的 `builds/cft/` 目录为空 → `PLAYWRIGHT_DOWNLOAD_HOST=npmmirror` 无效
  - 旧路径 `builds/chromium/{revision}/` 现在只用于 ARM64
- 错误：`NoSuchKey: binaries/playwright/145.0.7632.6/linux64/chrome-linux64.zip`
- **当前绕过方案**（Docker）：
  1. apt-get 添加 `chromium` 系统包
  2. `ENV PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1`
  3. `ENV CHROME_PATH=/usr/bin/chromium`
  4. 注释掉 `playwright install chromium` 和相关 ENV
- **根本解决方案**：`playwright install chrome`（从 `dl.google.com` 下载 Google Chrome deb 包，中国可达）+ 代码中用 `channel='chrome'`
- 完整构建尚未验证（裸机部署可用，Docker 为可选方案）

#### 2026-02-12：修正 Azure OpenAI API 版本 ✅
```bash
ssh aliyun-dev "sed -i 's/2024-05-01-preview/2024-12-01-preview/' /opt/web-ui/.env"
```
- **问题**：o3 模型返回 `400 BadRequest: Model o3 is enabled only for api versions 2024-12-01-preview and later`
- **修复**：`AZURE_OPENAI_API_VERSION=2024-05-01-preview` → `2024-12-01-preview`

#### 2026-02-12：中文编码测试 ✅ 通过
测试脚本：`/tmp/test_chinese.py`（用 browser-use SDK 直接调用）
```
任务：打开百度搜索"今天北京天气"，提取天气信息
结果：北京今天天气：晴；当前气温 -1℃，最高温度 11℃，最低温度 -2℃，
      体感温度 -4℃；湿度 51%；北风 2级；空气质量：良（AQI 57）。
完成：2 步，8193 tokens，中文零乱码
```
- 关键：浏览器复用了 `http://localhost:9242` 的已有 Chrome 实例
- `repr()` 输出确认：全是正常 Unicode 字符串，无 `\x` 乱码

#### 2026-02-12：创建 REST API 服务 → ❌ 已放弃
- 文件：`api_server.py`（本地保留作参考，不再部署）
- **放弃原因**：应用也是 Python，直接用 SDK 更简单，无需 HTTP 中间层
- **新方案**：在应用代码中直接 `from browser_use import Agent, Browser`

#### 2026-02-12：决定使用 SDK 直接集成 ✅
- **方案**：应用中直接 `import browser_use`，函数级调用
- **优势**：
  - 一个进程，一个服务，零 HTTP 开销
  - 内存占用更少（3.4GB 服务器关键优势）
  - 不需要管理两个服务的启动/重启
- **SDK 版本**：计划使用最新 browser-use 0.11.x（与废弃的 web-ui 0.1.48 解耦）
- **基本用法**：
```python
from browser_use import Agent, Browser, ChatAzureOpenAI

async def do_browser_task(task_description: str) -> str:
    browser = Browser(headless=True)
    llm = ChatAzureOpenAI(model="o3")
    agent = Agent(task=task_description, llm=llm, browser=browser)
    history = await agent.run()
    return history.final_result()
```

---

## 9. 关键文件路径

### 本地（Windows 开发机）
```
C:\Users\chuiwenyao\Desktop\vibe Code\browse use on cursor\
├── web-ui\                          # WebUI 源码
│   ├── Dockerfile                   # Docker 构建文件（已配置阿里云镜像源）
│   ├── docker-compose.yml           # Docker 编排
│   ├── requirements.txt             # Python 依赖
│   ├── webui.py                     # WebUI 入口
│   ├── .env.example                 # 环境变量模板
│   └── src\
│       ├── agent\browser_use\       # browser_use_agent.py - Agent 核心逻辑
│       ├── browser\                 # custom_browser.py - 浏览器启动配置
│       ├── controller\              # custom_controller.py
│       ├── utils\                   # config.py, llm_provider.py - LLM 配置
│       └── webui\components\        # 各 tab 组件，含 agent 启动逻辑
├── api_server.py                    # REST API 服务（已废弃，保留作参考）
├── fix_browser_args.py              # Docker 内浏览器参数修复脚本
├── fix_search_engine.py             # Docker 内搜索引擎修复脚本
└── 阿里云服务器信息.md               # 本文件
```

### 服务器（阿里云 120.26.87.185）
```
/opt/web-ui/                         # 项目根目录
├── .venv/                           # Python 虚拟环境 (3.12.3)
├── .env                             # 环境变量（含 Azure OpenAI Key）
├── api_server.py                    # REST API 服务（已废弃，不再使用）
├── Dockerfile                       # 服务器版 Dockerfile（已修复 noVNC + Playwright）
├── Dockerfile.bak2                  # Dockerfile 修改前备份
├── docker-compose.yml
├── webui.py
├── src/                             # 源代码（与本地 web-ui/src 对应）
└── tmp/                             # agent 临时文件、历史记录
```

---

## 10. 服务器 .env 关键配置（当前值）

```env
DEFAULT_LLM=azure_openai
AZURE_OPENAI_ENDPOINT=https://forbrowseuse-resource.cognitiveservices.azure.com/
AZURE_OPENAI_API_KEY=7X7N0n...（已配置）
AZURE_OPENAI_API_VERSION=2024-12-01-preview  # 原为 2024-05-01-preview，o3 要求 12-01 以上
BROWSER_PATH=/usr/bin/google-chrome-stable
USE_OWN_BROWSER=true
KEEP_BROWSER_OPEN=true
BROWSER_DEBUGGING_PORT=9222
VNC_PASSWORD=browseruse2026
RESOLUTION=1920x1080x24

# 企查查 MCP 配置
QCC_MCP_URL=https://mcp.qcc.com/basic/stream?key=Mk9jQJ...（已配置）
```

> **注意**：`USE_OWN_BROWSER=true` + `BROWSER_PATH=/usr/bin/google-chrome-stable` 表示裸机模式下使用系统 Chrome，但服务器上可能没有安装 google-chrome-stable，实际用的是 Playwright 自带的 Chromium。

---

## 11. 官方文档与社区调研（2026-02-12）

### 11.1 官方推荐的生产部署方式

**browser-use 官方 (v0.11.9)** 推荐使用 **`@sandbox()` 装饰器 + Browser-Use Cloud**：

```python
from browser_use import Browser, sandbox, ChatBrowserUse
from browser_use.agent.service import Agent

@sandbox()
async def my_task(browser: Browser):
    agent = Agent(task="Find the top HN post", browser=browser, llm=ChatBrowserUse())
    await agent.run()

asyncio.run(my_task())
```

- **官方立场**：强烈推广 [cloud.browser-use.com](https://cloud.browser-use.com) 付费服务
- **自部署支持**：官方文档没有提供自搭建 server 的生产指南
- **web-ui 已归档**：`browser-use/web-ui` 最后更新 6 个月前（2025-08），官方不再维护
- **我们的方案**：直接在 Python 应用中 `import browser_use` SDK，不需要额外 API 层
- **与 web-ui 的关系**：完全无关 — web-ui 基于 0.1.48 已废弃，我们用最新 0.11.x SDK

### 11.2 GitHub Issues 中的常见坑

来源：[browser-use/web-ui Issues](https://github.com/browser-use/web-ui/issues)，共 263 个 issues

#### 坑 1：Docker 构建失败 — `libgconf-2-4` 包不可用
- **Issues**: [#684](https://github.com/browser-use/web-ui/issues/684), [#680](https://github.com/browser-use/web-ui/issues/680)
- **原因**：Debian Trixie/Bookworm 已移除 `libgconf-2-4`
- **修复**：从 Dockerfile 的 `apt-get install` 中移除 `libgconf-2-4`
- **我们的状态**：✅ 已在当前 Dockerfile 中移除

#### 坑 2：字体错误 — `OSError: cannot open resource`
- **Issue**: [#115](https://github.com/browser-use/web-ui/issues/115)（17 条评论）
- **原因**：Docker 容器中缺少字体文件，browser-use 生成 GIF 历史记录时 PIL `ImageFont.truetype()` 报错
- **修复**：安装 `fontconfig fonts-dejavu fonts-dejavu-core fonts-dejavu-extra`
- **CJK 字体**：额外需要 `fonts-noto-cjk` 支持中文
- **我们的状态**：✅ 已在 Dockerfile 中添加全部字体

#### 坑 3：`[Errno 111] Connection refused`
- **Issue**: [#146](https://github.com/browser-use/web-ui/issues/146)（24 条评论，最常见问题）
- **原因**：Docker 容器内 `localhost` 指向容器自身，不是宿主机
- **影响场景**：
  - 使用 Ollama (本地 LLM) 时，容器内无法连 `localhost:11434`
  - 浏览器启动失败时，agent 连不到 Chromium
- **修复方案**：
  - Ollama：改用 `http://host.docker.internal:11434`
  - `docker-compose.yml` 添加 `extra_hosts: ["host.docker.internal:host-gateway"]`
  - 或使用 `network_mode: host`
- **我们的状态**：⚠️ 不影响（我们用 Azure OpenAI 远程 API，不用 Ollama）

#### 坑 4：noVNC 界面空白 / WebSocket 握手错误
- **Issues**: [#218](https://github.com/browser-use/web-ui/issues/218), [#626](https://github.com/browser-use/web-ui/issues/626)
- **原因**：Xvfb 未正常启动，或 x11vnc/noVNC 依赖链断裂
- **修复**：确保 supervisord 中 Xvfb 先启动 (priority=100)，x11vnc 依赖 Xvfb (priority=200)

#### 坑 5：Docker 镜像拉取失败
- **Issue**: [#614](https://github.com/browser-use/web-ui/issues/614)
- **原因**：`ghcr.io/browser-use/web-ui` 预编译镜像不可用（返回 denied）
- **修复**：必须自己 `docker compose build` 构建
- **我们的状态**：⚠️ 构建失败（GitHub 代理不通）

#### 坑 6：Playwright install 失败
- **Issue**: [#574](https://github.com/browser-use/web-ui/issues/574)
- **原因**：`playwright install --with-deps chromium` 在 Docker build 中失败
- **修复**：分开安装 `playwright install chromium`（不带 `--with-deps`），系统依赖由 Dockerfile 手动安装
- **我们的状态**：✅ Dockerfile 已使用分开安装方式

### 11.3 我们面临的特有问题（中国网络 + 阿里云）

| 问题 | 原因 | 解决方案 |
|---|---|---|
| **GitHub 不通** | GFW 屏蔽 | Dockerfile 中 noVNC 用 ghgo.xyz 代理，但代理也挂了 → **换用 gitee 镜像或直接下载 release 包** |
| **Docker Hub 超时** | GFW 屏蔽 | 已配镜像加速器，但不够稳定 → **考虑用阿里云容器镜像服务 ACR** |
| **PyPI 包下载慢** | 默认源在海外 | ✅ 已用阿里云 PyPI 镜像 |
| **npm/Node 包慢** | 默认源在海外 | ✅ 已用 npmmirror |
| **Playwright CFT 下载失败** | 1.50+ 改用 `builds/cft/` 路径，`cdn.playwright.dev` 302 跳转到被墙的 `storage.googleapis.com`；npmmirror `builds/cft/` 为空 | **`playwright install chrome`**（从 `dl.google.com` 下载，中国可达）+ `channel='chrome'` |
| **Google 不可访问** | GFW 屏蔽 | ✅ 已在 system prompt 中强制使用百度/搜狗 |
| **Azure OpenAI 可能限速** | 跨境网络 | 目前正常 (~1s)，但不稳定时考虑用阿里云 DashScope/Qwen 做备选 |

### 11.4 browser-use 版本演进说明

| 版本 | 变化 |
|---|---|
| **web-ui** (我们用的) | 基于 `browser-use==0.1.48`，Gradio 界面，**已停更 6 个月** |
| **browser-use 主库** | 当前 `v0.11.9`，API 变化大：`BrowserConfig` → `Browser` 直接传参，新增 `ChatBrowserUse` LLM |
| **生产方式** | 官方推 `@sandbox()` 云方案，无自部署 API 文档 |

> **已决定 (2026-02-12)**：使用最新 browser-use 0.11.x SDK，与 web-ui 彻底解耦。
> - web-ui 代码不再使用、不再维护
> - 应用中直接 `from browser_use import Agent, Browser, ChatAzureOpenAI`
> - Azure OpenAI 的 import 也从 `langchain_openai` 变为 browser-use 内置的 `ChatAzureOpenAI`

### 11.5 官方 browser-use 自部署要点（从文档提取）

#### Browser 配置关键参数
```python
from browser_use import Browser

browser = Browser(
    headless=True,           # 服务器必须 headless（或用 Xvfb）
    cdp_url="http://...",    # 可连接远程浏览器
    args=['--no-sandbox', '--disable-dev-shm-usage', '--lang=zh-CN'],
    channel='chromium',      # 或 'chrome'
    chromium_sandbox=False,  # Docker 中必须关闭
    window_size={'width': 1920, 'height': 1080},
    downloads_path='./downloads',
    user_agent='...',        # 可自定义 UA
    proxy=ProxySettings(...),  # 可配代理
)
```

#### Agent 关键参数
```python
from browser_use import Agent

agent = Agent(
    task="你的任务描述",
    llm=your_llm,
    browser=browser,
    use_vision=True,         # 是否使用视觉（截图）能力
)
history = await agent.run()  # 返回 AgentHistory
```

#### 远程浏览器连接
```python
# 可以通过 CDP URL 连接已运行的 Chrome 实例
browser = Browser(cdp_url="http://remote-server:9222")
```

### 11.6 社区实战经验总结

1. **内存**：browser-use + Chromium 在 Docker 中至少需要 **4GB 内存**，推荐 8GB
   - 我们只有 3.4GB 且无 Swap → 高优先级需添加 Swap
   
2. **shm_size**：Docker 中 Chromium 需要 `shm_size: 2gb`，否则 Chrome 崩溃
   - docker-compose.yml 已配置 ✅

3. **`--no-sandbox`**：Docker 中运行 Chromium **必须** 加此参数
   - 或给容器 `SYS_ADMIN` capability（已配置 ✅）

4. **`--disable-dev-shm-usage`**：避免 Chrome 使用 `/dev/shm`（Docker 中 shm 有限）
   - fix_browser_args.py 已添加此参数 ✅

5. **DeepSeek R1 注意**：使用 DeepSeek R1 模型时必须**关闭 Use Vision**，否则报错
   - 不影响我们（用 Azure OpenAI o3）

6. **Gradio 没有原生 API 认证**：WebUI 暴露后任何人都能用
   - WebUI 仅供手动测试用，生产环境不使用

### 11.7 Playwright 中国网络问题 — 源码级根因分析（2026-02-12）

#### 发现过程
通过阅读 Playwright 源码 `packages/playwright-core/src/server/registry/index.ts`，定位到浏览器下载逻辑。

#### 根因
Playwright **1.50+** 对 x64 Linux 的 Chromium 下载路径做了重大变更：

| 版本 | 下载路径格式 | CDN |
|---|---|---|
| < 1.50 | `builds/chromium/{revision}/chromium-linux.zip` | npmmirror 有镜像 ✅ |
| ≥ 1.50 (x64) | `builds/cft/{browserVersion}/chrome-linux64.zip` | npmmirror **目录为空** ❌ |
| ≥ 1.50 (arm64) | `builds/chromium/{revision}/chromium-linux-arm64.zip` | 仍走旧路径 |

关键代码：
```typescript
// registry/index.ts
private _cftUrl(browserVersion: string, suffix: string): DownloadURL {
  return {
    url: `https://cdn.playwright.dev/builds/cft/${browserVersion}/${suffix}`,
  };
}
```

`cdn.playwright.dev/builds/cft/` → **302 重定向** → `storage.googleapis.com/chrome-for-testing-public/`（中国被 GFW 屏蔽）

#### PLAYWRIGHT_DOWNLOAD_HOST 为何无效
- 设置 `PLAYWRIGHT_DOWNLOAD_HOST=https://cdn.npmmirror.com/binaries` 后，URL 变为：
  `https://cdn.npmmirror.com/binaries/playwright/builds/cft/{version}/...`
- 但 npmmirror 只镜像了 `builds/chromium/` 目录，**`builds/cft/` 目录为空** → 404

#### CDN 镜像常量
```typescript
const PLAYWRIGHT_CDN_MIRRORS = [
  'https://playwright.download.prss.microsoft.com/dbazure/download/playwright/builds',
  'https://cdn.playwright.dev/builds',
];
```
两个都指向海外 CDN，中国不可达或不稳定。

#### 根本解决方案：`playwright install chrome`

`playwright install chrome` 命令下载的是 **Google Chrome 稳定版**（非 Chromium），下载源为：
```
https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
```
- `dl.google.com` 在中国大陆**可以访问**（Google 的部分 CDN 未被屏蔽）
- 安装后使用 `channel='chrome'` 参数即可

```python
# Python 代码中使用
from playwright.sync_api import sync_playwright
with sync_playwright() as p:
    browser = p.chromium.launch(channel='chrome', headless=True)
```

```python
# browser-use 中使用
from browser_use import BrowserConfig
config = BrowserConfig(headless=True, channel='chrome')
```

#### 方案对比

| 方案 | 可行性 | 优点 | 缺点 |
|---|---|---|---|
| `playwright install chromium` | ❌ 中国不可用 | 官方默认 | CDN 被墙 |
| `PLAYWRIGHT_DOWNLOAD_HOST=npmmirror` | ❌ 1.50+ 不可用 | 曾经好用 | `builds/cft/` 为空 |
| `apt install chromium` | ⚠️ 可用但有风险 | 简单 | 版本可能与 Playwright 不匹配 |
| **`playwright install chrome`** | ✅ **推荐** | `dl.google.com` 可达，版本兼容 | 是 Google Chrome 非开源 Chromium |
| 手动下载 + 指定路径 | ⚠️ 可用 | 灵活 | 维护成本高 |

---

## 12. 下一步执行计划（2026-02-12 更新）

### 已完成 ✅
- 添加 4GB Swap — 防 OOM
- 修复 Azure API 版本 — o3 模型正常
- 中文编码验证 — SDK 测试通过
- Docker 部分修复 — Dockerfile 已改（可选，非必需）
- 确定集成方式 — **直接用 SDK，不封装独立 API**

### 第一优先：升级 browser-use SDK 到 0.11.x
服务器上当前环境基于 web-ui 的 `browser-use==0.1.48`，需要升级：
```bash
ssh aliyun-dev "cd /opt/web-ui && source .venv/bin/activate && pip install --upgrade browser-use"
```
注意 0.11.x 的 API 变化：
- `BrowserConfig` → `Browser()` 直接传参
- 新增 `ChatAzureOpenAI`（browser-use 内置，不再依赖 `langchain_openai`）
- `BrowserProfile` 替代老的 `BrowserContextConfig`

### 第二优先：构建 Python 应用
在应用中直接调用 SDK，核心代码：
```python
from browser_use import Agent, Browser, ChatAzureOpenAI

async def do_browser_task(task: str) -> str:
    """执行浏览器自动化任务，返回结果文本"""
    browser = Browser(headless=True)
    llm = ChatAzureOpenAI(model="o3")
    agent = Agent(
        task=task,
        llm=llm,
        browser=browser,
        extend_system_message="搜索时使用百度，不要使用Google。所有输出使用中文。",
    )
    history = await agent.run(max_steps=20)
    return history.final_result()
```

### 第三优先：部署应用
- 使用 systemd 管理应用进程（替代 nohup）
- Xvfb 提供虚拟显示（headless 浏览器需要）
- 环境变量从 `.env` 加载

### 第四优先：生产加固
- 并发控制（asyncio.Semaphore，3.4GB 内存最多 1-2 个同时任务）
- 任务超时（5 分钟自动终止）
- 浏览器生命周期管理（每任务结束后清理，防内存泄漏）
- 监控和告警（进程存活、内存使用率）

---

## 12. 政策搜索踩坑记录与优化建议

> 记录日期：2026-02-12
> 基于"上海聿凡领光通信有限公司"调研任务的实际运行经验

### 12.1 已知踩坑总结

| # | 站点/场景 | 具体问题 | 影响 |
|---|----------|---------|------|
| 1 | **企查查** (qichacha.com) | 返回 405，直接拦截无头浏览器 | 无法获取公司详情 |
| 2 | **天眼查** (tianyancha.com) | 弹登录墙 + 反爬检测 | 同上 |
| 3 | **爱企查** (aiqicha.com) | 百度系验证码（滑块/图形），自动化无法通过 | 点进去就触发 captcha |
| 4 | **搜狗微信** (weixin.sogou.com) | 访问几次后触发验证码/反爬；检测 headless 特征 | WeChat 文章搜索基本不可用 |
| 5 | **百度 site:mp.weixin.qq.com** | 搜索结果中微信文章的 URL 实际是百度跳转链接，`find_elements` 提取出的 href 不是真实公众号链接 | Agent 陷入循环提取 |
| 6 | **Agent 步数浪费** | Agent 在被拦截的站点上反复重试（刷新、换方式进入），消耗大量步数 | 30 步只找到 1 条政策 |
| 7 | **JSON 尾部脏数据** | `final_result()` 返回的字符串末尾附带 judge verdict 文本，导致 `model_validate_json()` 失败 | 结构化解析报错 |
| 8 | **政府网站结构各异** | 不同区/市级政府网站 DOM 不统一，PDF 下载按钮位置和命名不一致 | Agent 未必能找到 PDF 链接 |

### 12.2 当前最大问题：政策找的太少

**根因分析：**

1. **搜索关键词单一** — 当前 prompt 只让 Agent 搜一次"光通信 产业扶持政策"，如果这一次搜索结果页没有好结果就结束了
2. **步数被浪费** — Agent 在爱企查上浪费了 ~5 步尝试获取公司信息（被 captcha 挡住），在搜狗微信上浪费了 ~8 步（反爬），真正用于搜索政策的有效步数 < 10
3. **政策维度单一** — 只搜了"光通信"维度，没有搜"小微企业"、"科技创新"、"浦东新区专项"等其他维度
4. **缺少分层搜索** — 没有区分国家级、上海市级、浦东新区级三个层级的政策

### 12.3 优化建议

#### 建议一：拆分任务（推荐 ⭐⭐⭐）

把一个大任务拆成多个小的、独立的搜索任务，每个只做一件事，步数可以更集中：

```
任务1（5步）：百度搜索获取公司基本信息（从搜索摘要提取，不进企查查）
任务2（8步）：搜索"浦东新区 光通信 产业政策 site:gov.cn"
任务3（8步）：搜索"上海市 小微企业 扶持 补贴 2025 site:gov.cn"
任务4（8步）：搜索"浦东新区 科技创新 资金 奖励 site:gov.cn"
任务5（8步）：搜索"上海 集成电路 通信 专项资金 site:gov.cn"
```

好处：每个任务步数充足，不会因一个站点被拦截而浪费全部步数。

#### 建议二：多关键词覆盖（推荐 ⭐⭐⭐）

基于公司画像（光通信、小微企业、浦东新区）生成多组搜索关键词：

| 维度 | 搜索关键词示例 |
|------|-------------|
| 行业 | `浦东新区 光通信 产业扶持`, `上海 信息通信 专项资金` |
| 规模 | `上海 小微企业 补贴政策`, `浦东新区 中小企业 创新资金` |
| 科技 | `浦东新区 高新技术企业 认定 奖励`, `上海 科技型中小企业 扶持` |
| 综合 | `浦东新区 企业扶持政策汇总 2025`, `上海市 产业政策 一览` |
| 专项 | `浦东新区 集成电路 通信 操作细则`, `张江 光电子 产业` |

#### 建议三：直接访问已知政府政策聚合页面（推荐 ⭐⭐）

不依赖搜索引擎，直接让 Agent 访问已知的政策聚合网站：

- **上海市企业服务云**: https://www.ssme.sh.gov.cn — 有政策匹配功能
- **浦东新区政府网站政策频道**: https://www.pudong.gov.cn/zwgk/ — 政策公开
- **上海市经信委**: https://jjxxw.sh.gov.cn — 信息通信产业主管部门
- **上海科委**: https://stcsm.sh.gov.cn — 科技扶持政策
- **国家工信部**: https://www.miit.gov.cn — 通信产业国家级政策
- **上海市人民政府**: https://www.shanghai.gov.cn/nw42437/ — 政策文件库
- **浦东新区科经委**: 直接搜索其官网的通知公告

#### 建议四：优化 Prompt 结构（推荐 ⭐⭐）

在 task prompt 中：
- **硬编码跳过名单**：明确列出 `qichacha.com, tianyancha.com, aiqicha.com, weixin.sogou.com` 不要访问
- **限定步数分配**：给获取公司信息最多 3 步，剩余步数全部用于政策搜索
- **使用 `site:gov.cn`**：百度搜索加 `site:gov.cn` 限定政府网站结果
- **增加 max_steps**：当前 30 步不够，可以提高到 50（会增加耗时和 token 消耗）

#### 建议五：后处理增强（推荐 ⭐）

- Agent 返回的 URL 列表后，用第二轮 Agent 逐个打开政策页面，提取 PDF 链接
- 或者用 `requests` + `BeautifulSoup` 直接爬取政策页面（更快、更可控）
- 对 `final_result()` 做正则清洗，提取第一个合法 JSON 块：
  ```python
  import re
  match = re.search(r'\{.*\}', final_text, re.DOTALL)
  if match:
      parsed = json.loads(match.group())
  ```

#### 建议六：替代微信公众号搜索方案（推荐 ⭐⭐）

搜狗微信搜索基本不可用（反爬太严），替代方案：
- **百度搜索** `"上海 光通信 政策" 微信公众号` — 有时百度会索引微信文章快照
- **今日头条/百家号** — 政策解读类文章较多，反爬不如搜狗严格
- **直接跳过微信** — 政府官网是第一手来源，公众号只是转载，优先级可以降低

### 12.4 JSON 解析修复方案

`final_result()` 返回示例（注意尾部多余文本）：
```
{"company_name": "上海聿凡领光通信有限公司", ...}\n\nI have completed the task...
```

修复代码：
```python
if output_model and final_text:
    # 清洗：提取第一个完整 JSON 对象
    import re
    json_match = re.search(r'\{[\s\S]*\}', final_text)
    if json_match:
        clean_json = json_match.group()
        try:
            parsed = output_model.model_validate_json(clean_json)
            result["structured"] = parsed.model_dump()
            result["result"] = parsed.model_dump()
        except Exception as e:
            result["parse_error"] = str(e)
    else:
        result["parse_error"] = "No JSON object found in output"
```

### 12.5 推荐下一步行动

| 优先级 | 行动 | 预期效果 |
|-------|------|---------|
| P0 | 修复 JSON 解析（正则提取） | 结构化输出正常工作 |
| P0 | 拆分任务：一个任务只搜一个政策维度 | 每个维度 5-8 条政策 |
| P1 | 多关键词：行业+规模+科技+综合 4 维度搜索 | 覆盖面从 1 个维度 → 4+ 个维度 |
| P1 | 直接访问政府聚合页面 | 绕过搜索引擎不确定性 |
| P2 | 提高 max_steps 到 50 | 更多探索空间（但耗时增加） |
| P2 | 二次爬取：对 URL 列表用 requests 提取 PDF | 更可靠地拿到 PDF |
| P3 | 替代微信搜索方案 | 不再被搜狗反爬困住 |
---

## 13. 部署记录

### 2026-02-14：v0.16 搜索时效性优化部署

**部署内容**：搜索时效性全链路优化（详见 CHANGELOG.md v0.16）

**部署步骤与注意事项**：

#### 1. 文件上传

```bash
# 上传改动的 Python 文件 + 前端 + CHANGELOG
$base = "C:\Users\chuiwenyao\Desktop\vibe Code\browse use on cursor"
scp "$base\models.py" "$base\web_search_worker.py" "$base\orchestrator.py" "$base\server.py" "$base\index.html" "$base\CHANGELOG.md" aliyun-dev:/opt/browser-sdk/

# 上传 prompts 目录下的文件（注意：prompts 是子目录）
scp "$base\prompts\expert_system_prompt.md" aliyun-dev:/opt/browser-sdk/prompts/
```

#### 2. 重启 Python 后端

```bash
# 先停
ssh aliyun-dev "pkill -f 'server.py' 2>/dev/null || true"

# 再启（注意：复杂的 && 链在 PowerShell → SSH 中容易因引号问题失败）
ssh aliyun-dev "cd /opt/browser-sdk && . .venv/bin/activate && nohup python -u server.py >> /tmp/server.log 2>&1 & echo 'PID:' \$!"

# 验证
ssh aliyun-dev "sleep 2; ps aux | grep -E 'server\.py' | grep -v grep"
ssh aliyun-dev "tail -5 /tmp/server.log"
```

#### 3. 更新前端静态页面（⚠️ 容易遗漏）

index.html 不是由 Python 服务，而是由 **nginx 作为静态文件** serve 的。上传到 `/opt/browser-sdk/` 后，还需要复制到 nginx 的静态目录：

```bash
ssh aliyun-dev "cp /opt/browser-sdk/index.html /var/www/html/policy.html && nginx -t && nginx -s reload"
```

**踩坑**：nginx 配置中 `/policy` 路由指向 `/var/www/html/policy.html`，而不是 `/opt/browser-sdk/index.html`。忘记这一步会导致前端不更新。

#### 4. PowerShell SSH 引号问题

在 PowerShell 中通过 SSH 执行多条 bash 命令时，引号嵌套容易出错：
- ❌ `ssh aliyun-dev "cd /opt/browser-sdk; pkill -f 'server.py'; sleep 1; . .venv/bin/activate; nohup python -u server.py > /tmp/server.log 2>&1 &"` — 有时 exit code 1
- ✅ 拆成多条单独的 SSH 命令更可靠

#### 部署验证清单

```bash
# 1. 后端运行中？
ssh aliyun-dev "ps aux | grep -E 'server\.py' | grep -v grep"

# 2. 后端启动正常？
ssh aliyun-dev "tail -5 /tmp/server.log"
# 应看到 "Uvicorn running on http://0.0.0.0:8000"

# 3. 前端版本号正确？
ssh aliyun-dev "curl -s http://localhost/policy | grep -o 'v0\.[0-9]*'"
# 应输出 v0.16

# 4. API 可达？
ssh aliyun-dev "curl -s http://localhost:8000/api/mock-companies | head -1"
```